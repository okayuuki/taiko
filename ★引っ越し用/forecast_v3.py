#äºˆæ¸¬ç”¨

#! ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®import
import os
import pandas as pd
import warnings
import numpy as np
import pandas as pd
#%matplotlib inline#Jupyter Notebook å°‚ç”¨ã®ãƒã‚¸ãƒƒã‚¯ã‚³ãƒãƒ³ãƒ‰ã€‚ãƒ¡ãƒ³ãƒ†ç”¨ã§åˆ©ç”¨
import matplotlib.pyplot as plt
import shap
import seaborn as sns
import matplotlib as mpl
from dateutil.relativedelta import relativedelta
from IPython.display import display, clear_output
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from matplotlib.gridspec import GridSpec
from datetime import datetime
from datetime import timedelta
from PIL import Image
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, max_error, mean_absolute_error
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, date, time
import pickle
from sklearn.preprocessing import StandardScaler
import streamlit.components.v1 as components
import base64

#! è‡ªä½œãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®import
from read_v3 import read_data, process_Activedata, read_syozailt_by_using_archive_data, read_activedata_by_using_archive_data,read_zaiko_by_using_archive_data, calculate_supplier_truck_arrival_types2

from functions_v3 import process_shiresakibin_flag

#! ãƒªãƒŸãƒƒãƒˆè¨ˆç®—
def show_forecast( unique_product, start_datetime, selected_zaiko, past_hours, type):

    #start_date = '2024-05-01-00'
    #end_date = '2024-08-31-00'

    start_date = start_datetime.strftime('%Y-%m-%d-%H')
    end_datetime = start_datetime + relativedelta(months=1)
    end_date = end_datetime.strftime('%Y-%m-%d-%H')

    selected_datetime = start_datetime

    #! å“ç•ªã€æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    product = unique_product.split('_')[0]
    seibishitsu = unique_product.split('_')[1]

    #! ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    prediction_hours = 12#ä½•æ™‚é–“å…ˆã¾ã§äºˆæ¸¬ã™ã‚‹ã®ã‹
    #past_hours = 5
    lookback_hours = past_hours+2

    # ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
    st.header('äºˆæ¸¬çµæœ')

    #!----------------------------------------------------------------------- 
    #! è‡ªå‹•ãƒ©ãƒƒã‚¯ã®åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†
    #!-----------------------------------------------------------------------
    # todo å¼•æ•°é–¢ä¿‚ãªãå…¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã—ã¦ã‚‹
    zaiko_df = read_zaiko_by_using_archive_data(selected_datetime.strftime('%Y-%m-%d-%H'), selected_datetime.strftime('%Y-%m-%d-%H'))
    # todo
    #! å“ç•ªåˆ—ã‚’æ˜‡é †ã«ã‚½ãƒ¼ãƒˆ
    zaiko_df = zaiko_df.sort_values(by='å“ç•ª', ascending=True)
    #! ç„¡åŠ¹ãªå€¤ã‚’ NaN ã«å¤‰æ›
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = pd.to_numeric(zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'], errors='coerce')
    #! å“ç•ªã”ã¨ã«æ¬ æå€¤ï¼ˆNaNï¼‰ã‚’åŸ‹ã‚ã‚‹(å‰æ–¹åŸ‹ã‚å¾Œæ–¹åŸ‹ã‚)
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df.groupby('å“ç•ª')['æ‹ ç‚¹æ‰€ç•ªåœ°'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))
    #! ãã‚Œã§ã‚‚ç½®æ›ã§ããªã„ã‚‚ã®ã¯NaN ã‚’ 0 ã§åŸ‹ã‚ã‚‹
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'].fillna(0).astype(int).astype(str)
    #! strå‹ã«å¤‰æ›
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'].astype(int).astype(str)
    #! å—å…¥å ´æ‰€æƒ…å ±æº–å‚™
    file_path = 'temp/ãƒã‚¹ã‚¿ãƒ¼_å“ç•ª&ä»•å…¥å…ˆå&ä»•å…¥å…ˆå·¥å ´å.csv'
    syozaikyotenchi_data = pd.read_csv(file_path, encoding='shift_jis')
    #! ç©ºç™½æ–‡å­—åˆ—ã‚„éæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’NaNã«å¤‰æ›
    syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'] = pd.to_numeric(syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'], errors='coerce')
    #! strå‹ã«å¤‰æ›
    syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'] = syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'].fillna(0).astype(int).astype(str)
    #! å—å…¥å ´æ‰€è¿½åŠ 
    zaiko_df = pd.merge(zaiko_df, syozaikyotenchi_data[['å“ç•ª','æ‹ ç‚¹æ‰€ç•ªåœ°','å—å…¥å ´æ‰€']], on=['å“ç•ª', 'æ‹ ç‚¹æ‰€ç•ªåœ°'], how='left')
    #! æ—¥ä»˜åˆ—ã‚’ä½œæˆ
    zaiko_df['æ—¥ä»˜'] = zaiko_df['æ—¥æ™‚'].dt.date
    #! å“ç•ª_å—å…¥ç•ªå·ä½œæˆ
    zaiko_df['å“ç•ª_å—å…¥å ´æ‰€'] = zaiko_df['å“ç•ª'].astype(str) + "_" + zaiko_df['å—å…¥å ´æ‰€'].astype(str)
    zaiko_df = zaiko_df[(zaiko_df['å“ç•ª'] == product) & (zaiko_df['å—å…¥å ´æ‰€'] == seibishitsu)]
    # ç‰¹å®šã®æ—¥æ™‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    zaiko_df = zaiko_df[zaiko_df['æ—¥æ™‚'] == start_datetime]
    # æ—¥æ™‚ã‚’å†åº¦datetimeå‹ã«å¤‰æ›ï¼ˆå¿µã®ãŸã‚ï¼‰
    zaiko_df['æ—¥æ™‚'] = pd.to_datetime(zaiko_df['æ—¥æ™‚'])
    zaiko_extracted = zaiko_df[['æ—¥æ™‚', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰']]
    #st.dataframe(zaiko_extracted)

    #!-----------------------------------------------------------------------
    #! æ‰€åœ¨ç®¡ç†ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®ãƒ‡ãƒ¼ã‚¿
    #!-----------------------------------------------------------------------
    #file_path = 'ä¸­é–“æˆæœç‰©/æ‰€åœ¨ç®¡ç†MBãƒ†ã‚™ãƒ¼ã‚¿_çµ±åˆæ¸ˆ&ç‰¹å®šæ—¥æ™‚æŠ½å‡ºæ¸ˆ.csv'
    Timestamp_df = read_syozailt_by_using_archive_data(start_date, end_date)
    # 'æ›´æ–°æ—¥æ™‚'åˆ—ã«ç„¡åŠ¹ãªæ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹è¡Œã‚’å‰Šé™¤ã™ã‚‹
    data_cleaned = Timestamp_df.dropna(subset=['æ¤œåæ—¥æ™‚'])
    #st.dataframe(data_cleaned.head(50000))
    # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    data_cleaned = data_cleaned[(data_cleaned['å“ç•ª'] == product) & (data_cleaned['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] == seibishitsu)]
    # æ™‚é–“ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€å„æ™‚é–“ã§ã®ã‹ã‚“ã°ã‚“æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹
    data_cleaned['æ—¥æ™‚'] = data_cleaned['æ¤œåæ—¥æ™‚'].dt.floor('H')  # æ™‚é–“å˜ä½ã«ä¸¸ã‚ã‚‹
    hourly_kanban_count = data_cleaned.groupby('æ—¥æ™‚').size().reset_index(name='ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°')
    #st.dataframe(hourly_kanban_count)

    # æ™‚é–“ã®ç¯„å›²ã‚’æ±ºå®šã—ã€æ¬ ææ™‚é–“å¸¯ã‚’è£œå®Œã™ã‚‹
    full_time_range = pd.date_range(start=hourly_kanban_count['æ—¥æ™‚'].min(),end=hourly_kanban_count['æ—¥æ™‚'].max(),freq='H')

    # å…¨ã¦ã®æ™‚é–“ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã€æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹
    hourly_kanban_count_full = pd.DataFrame(full_time_range, columns=['æ—¥æ™‚']).merge(hourly_kanban_count, on='æ—¥æ™‚', how='left').fillna(0)

    # ã‹ã‚“ã°ã‚“æ•°ã‚’æ•´æ•°ã«æˆ»ã™
    hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'].astype(int)

    # 'äºˆæ¸¬å…¥åº«æ™‚é–“'åˆ—ã¨ã—ã¦ã€5æ™‚é–“å‰ã®ã‹ã‚“ã°ã‚“æ•°ã‚’è¿½åŠ ã™ã‚‹
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'].shift(past_hours)

    # æ¬ æå€¤ï¼ˆæœ€åˆã®5æ™‚é–“åˆ†ï¼‰ã‚’0ã§åŸ‹ã‚ã‚‹
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].fillna(0).astype(int)
    #st.dataframe(hourly_kanban_count_full)

    #!-----------------------------------------------------------------------
    #! Activedataã®å‡¦ç†
    #!-----------------------------------------------------------------------
    activedata = read_activedata_by_using_archive_data(start_date, end_date, 0)
    # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    activedata = activedata[(activedata['å“ç•ª'] == product) & (activedata['å—å…¥å ´æ‰€'] == seibishitsu)]
    #st.dataframe(activedata)
    #! ç¨¼åƒæ™‚é–“ã§å‰²ã‚‹å‡¦ç† (ä¼‘æ†©æ™‚é–“ã®è€ƒæ…®ãŒå¿…è¦ã‹ï¼Ÿ)
    activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] = activedata['æ—¥é‡æ•°']/activedata['åå®¹æ•°']
    activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / 16.5
    activedata['æ—¥ä»˜'] = pd.to_datetime(activedata['æ—¥ä»˜'])#ã“ã‚Œã—ãªã„ã¨æ¬¡ã®.resample('H')ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹
    # æ—¥ä»˜ã‚’åŸºæº–ã«1æ™‚é–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    activedata = activedata.set_index('æ—¥ä»˜').resample('H').ffill().reset_index()
    # 'æ—¥ä»˜' ã‚’datetimeå‹ã«å¤‰æ›
    activedata['æ—¥ä»˜'] = pd.to_datetime(activedata['æ—¥ä»˜'])
    activedata = activedata.rename(columns={'æ—¥ä»˜': 'æ—¥æ™‚'})

    # å¿…è¦ãªåˆ—ã¨ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ•´å‚™
    activedata['æ—¥æ™‚'] = pd.to_datetime(activedata['æ—¥æ™‚'])
    activedata = activedata.sort_values('æ—¥æ™‚').reset_index(drop=True)

    # å‡¦ç†å¯¾è±¡åˆ—ã‚’æ±ºå®š
    target_column = 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'

    # å¹´æœˆæƒ…å ±ã‚’è¿½åŠ 
    activedata['å¹´'] = activedata['æ—¥æ™‚'].dt.year
    activedata['æœˆ'] = activedata['æ—¥æ™‚'].dt.month

    # æ–°ã—ã„åˆ—ã€Œæœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰ã€ã‚’åˆæœŸåŒ–
    activedata['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] = None

    # å¹´ãƒ»æœˆã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦å‡¦ç†
    for (year, month), group in activedata.groupby(['å¹´', 'æœˆ']):
        for idx, row in group.iterrows():
            current_time = row['æ—¥æ™‚']
            # ç¾åœ¨æ™‚åˆ»ä»¥é™ã€åŒã˜æœˆå†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
            subset = group[group['æ—¥æ™‚'] >= current_time]
            # å¯¾è±¡ã®ã€Œæ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰ã€ã®æœ€å¤§å€¤ã‚’å–å¾—
            max_value = subset[target_column].max()
            # å€¤ã‚’ã‚»ãƒƒãƒˆ
            activedata.loc[idx, 'æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] = max_value

    if type == 1:
        activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = activedata['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰']/(16.5)

    #st.dataframe(activedata)

    # 'æ—¥ä»˜' ã¨ 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
    activedata_extracted = activedata[['æ—¥æ™‚', 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“']]
    #st.dataframe(activedata_extracted)

    # åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
    start_time = zaiko_extracted.iloc[0]['æ—¥æ™‚']
    # é–‹å§‹æ™‚åˆ»ã‹ã‚‰20æ™‚é–“å¾Œã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    end_time = start_time + pd.Timedelta(hours=prediction_hours)
    # ç¨¼åƒæœ‰ç„¡è¨­å®š-------------------------------------------------------------------
    # æ—¥æ™‚ãƒªã‚¹ãƒˆã‚’1æ™‚é–“ã”ã¨ã«ä½œæˆ
    date_range = pd.date_range(start=start_time, end=end_time, freq='H')
    # DataFrame ã‚’ä½œæˆã—ã€ç¨¼åƒãƒ•ãƒ©ã‚°åˆ—ã‚’ 0 ã§åˆæœŸåŒ–
    kado_df = pd.DataFrame({
        'æ—¥æ™‚': date_range,
        'ç¨¼åƒãƒ•ãƒ©ã‚°': 0
    })
    for idx, row in kado_df.iterrows():
        hour = row['æ—¥æ™‚'].hour  # æ™‚é–“ã ã‘å–å¾—
        if hour in [12, 17, 18, 19, 20, 21, 2, 6, 7]:
            kado_df.at[idx, 'ç¨¼åƒãƒ•ãƒ©ã‚°'] = 0
        else:
            kado_df.at[idx, 'ç¨¼åƒãƒ•ãƒ©ã‚°'] = 1

    #------------------------------------------------------------------------------------
    #
    #-----------------------------------------------------------------------------------

    # ã‚°ãƒ«ãƒ¼ãƒ—Aã¨ã‚°ãƒ«ãƒ¼ãƒ—Bã®æ™‚é–“å¸¯
    group_a_hours = [17, 18, 19, 20, 21]
    group_b_hours = [6, 7]

    # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«ãƒ•ã‚£ãƒ«ã‚¿
    filtered_kado_a = kado_df[kado_df['æ—¥æ™‚'].dt.hour.isin(group_a_hours)]
    filtered_kado_b = kado_df[kado_df['æ—¥æ™‚'].dt.hour.isin(group_b_hours)]

    # å¹´æœˆæ—¥ã ã‘å–ã‚Šå‡ºã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–
    dates_group_a = filtered_kado_a['æ—¥æ™‚'].dt.date.unique()
    dates_group_b = filtered_kado_b['æ—¥æ™‚'].dt.date.unique()

    # hiru_time = None
    # yoru_time = None
    # if len(dates_group_a) != 0:
    #     hiru_time = filtered_kado_a['æ—¥æ™‚'].dt.date.unique()[0]
    # if len((dates_group_a)) !=0:
    #     yoru_time = filtered_kado_b['æ—¥æ™‚'].dt.date.unique()[0]


    # if hiru_time != None:

    # å‡ºåŠ›
    #st.write("ã€Group Aã€‘[17, 18, 19, 20, 21] ã®æ™‚é–“å¸¯ã‚’å«ã‚€æ—¥ä»˜ä¸€è¦§")
    #st.write(dates_group_a)

    #ãã®æ—¥ã®æ®‹æ¥­æ™‚é–“ã‚’ã¨ã‚‹
    #æ™‚é–“ã«å¿œã˜ã¦ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’æ›´æ–°

    #st.write("\nã€Group Bã€‘[6, 7] ã®æ™‚é–“å¸¯ã‚’å«ã‚€æ—¥ä»˜ä¸€è¦§")
    #st.write(dates_group_b)

    #ãã®æ—¥ã®æ®‹æ¥­æ™‚é–“ã‚’ã¨ã‚‹
    #æ™‚é–“ã«å¿œã˜ã¦ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’æ›´æ–°
    
    #ç¨¼åƒæœ‰ç„¡è¨­å®š---------------------------------------------------------------------
    filtered_activedata = activedata_extracted[(activedata_extracted['æ—¥æ™‚'] >= start_time) & (activedata_extracted['æ—¥æ™‚'] < end_time)]
    #st.write(start_time,end_time)
    #st.dataframe(filtered_activedata)

    # å„æ™‚é–“å¾Œã®æ¶ˆè²»é‡ãŠã‚ˆã³å…¥åº«é‡ã‚’è€ƒæ…®ã—ãŸåœ¨åº«æ•°ã‚’è¨ˆç®—
    inventory_after_adjustments = []
    # ç¾åœ¨ã®åœ¨åº«æ•°ã‚’åˆæœŸå€¤ã¨ã—ã¦è¨­å®š
    current_inventory = selected_zaiko#zaiko_extracted.iloc[0]['åœ¨åº«æ•°ï¼ˆç®±ï¼‰']

    # 3ã¤ã®åˆ—ã‚’ä½œæˆ
    col1, col2 = st.columns(2)
    col1.metric(label="é¸æŠã•ã‚ŒãŸæ—¥æ™‚", value=str(start_datetime))#, delta="1 mph")
    col2.metric(label="å…¥åŠ›ã•ã‚ŒãŸçµ„ç«‹ãƒ©ã‚¤ãƒ³ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰", value=int(current_inventory))

    # æ™‚é–“ã”ã¨ã®åœ¨åº«æ•°ã‚’æ›´æ–°ã—ãªãŒã‚‰ãƒªã‚¹ãƒˆã«è¿½åŠ 
    for i, row in filtered_activedata.iterrows():
        kanban_row = hourly_kanban_count_full[hourly_kanban_count_full['æ—¥æ™‚'] == row['æ—¥æ™‚']]
        incoming_kanban = kanban_row['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].values[0] if not kanban_row.empty else 0
        inventory_after_adjustments.append({
            'æ—¥æ™‚': row['æ—¥æ™‚'],
            'åœ¨åº«æ•°ï¼ˆç®±ï¼‰': current_inventory
        })
        # æœ€åˆã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã¯æ¶ˆè²»ã‚’å¼•ã‹ãªã„ãŒã€ä»¥é™ã¯æ¶ˆè²»é‡ã¨å…¥åº«é‡ã‚’èª¿æ•´
        if i != 0:
            # è©²å½“æ—¥æ™‚ã®ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’å–å¾—
            kado_flag = kado_df.loc[kado_df['æ—¥æ™‚'] == row['æ—¥æ™‚'], 'ç¨¼åƒãƒ•ãƒ©ã‚°'].values[0]
            #st.write(kado_flag)
            if kado_flag == 1:
                current_inventory = current_inventory - row['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“']  # æ¶ˆè²»é‡ã‚’å¼•ã
            current_inventory = current_inventory + incoming_kanban  # å…¥åº«é‡ã‚’è¶³ã™
            

    # è¨ˆç®—çµæœã‚’DataFrameã«å¤‰æ›
    inventory_df_adjusted = pd.DataFrame(inventory_after_adjustments)
    #st.dataframe(inventory_df_adjusted)

    # æœ€åˆã®æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨ãã‚Œä»¥é™ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    actual_data = inventory_df_adjusted.iloc[0:1]  # æœ€åˆã®1æ™‚é–“åˆ†ã¯å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
    forecast_data = inventory_df_adjusted.iloc[1:]  # ãã‚Œä»¥é™ã¯äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿

    # æ™‚é–“è»¸ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã€å…¨æ™‚é–“ã®ç¯„å›²ã‚’ä½œæˆ
    #full_time_range = pd.date_range(start=actual_data['æ—¥æ™‚'].min(), end=forecast_data['æ—¥æ™‚'].max(), freq='H')

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãã‚Œãã‚Œã“ã®æ™‚é–“è»¸ã«åˆã‚ã›ã¦å†æ§‹ç¯‰ã—ã€æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹
    #actual_data = actual_data.set_index('æ—¥æ™‚').reindex(full_time_range).reset_index().rename(columns={'index': 'æ—¥æ™‚'})
    #forecast_data = forecast_data.set_index('æ—¥æ™‚').reindex(full_time_range).reset_index().rename(columns={'index': 'æ—¥æ™‚'})

    # æ¬ æå€¤ã¯ãã‚Œãã‚Œ0ã«ç½®ãæ›ãˆã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    #actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].fillna(0, inplace=True)
    #forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].fillna(0, inplace=True)

    # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
    fig = go.Figure()

    # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’é’è‰²ã§æç”»
    fig.add_trace(go.Bar(
        x=actual_data['æ—¥æ™‚'], 
        y=actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
        name='å®Ÿç¸¾', 
        marker_color='blue', 
        opacity=0.3
    ))

    # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã§è¿½åŠ æç”»
    fig.add_trace(go.Bar(
        x=forecast_data['æ—¥æ™‚'], 
        y=forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
        name='äºˆæ¸¬', 
        marker_color='orange', 
        opacity=0.3
    ))

    # xè»¸ã‚’1æ™‚é–“ã”ã¨ã«è¡¨ç¤ºã™ã‚‹è¨­å®š
    fig.update_layout(
        title='äºˆæ¸¬çµæœ',  # ã“ã“ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
        xaxis_title='æ—¥æ™‚',  # xè»¸ã‚¿ã‚¤ãƒˆãƒ«
        yaxis_title='åœ¨åº«æ•°ï¼ˆç®±ï¼‰',  # yè»¸ã‚¿ã‚¤ãƒˆãƒ«
        xaxis=dict(
            tickformat="%Y-%m-%d %H:%M",  # æ—¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®š
            dtick=3600000  # 1æ™‚é–“ã”ã¨ã«è¡¨ç¤º (3600000ãƒŸãƒªç§’ = 1æ™‚é–“)
        ),
        barmode='group'  # è¤‡æ•°ã®ãƒãƒ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    )

    # ã‚°ãƒ©ãƒ•ã‚’Streamlitã§è¡¨ç¤º
    st.plotly_chart(fig)

    # 5æ™‚é–“å‰ã®æ—¥æ™‚ã‚’è¨ˆç®—
    hours_before = start_time - pd.Timedelta(hours=lookback_hours)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«çµæœã‚’è¡¨ç¤ºã™ã‚‹
    hourly_kanban_count_full = hourly_kanban_count_full[(hourly_kanban_count_full['æ—¥æ™‚'] >= hours_before) & (hourly_kanban_count_full['æ—¥æ™‚'] < end_time)]

    # æ–°ã—ã„åˆ—ã€Œå‚™è€ƒã€ã‚’è¿½åŠ ã—ã€start_timeã«åŸºã¥ã„ã¦ã€Œéå»ã€ã€Œæœªæ¥ã€ã¨è¡¨ç¤º
    hourly_kanban_count_full['â€»æ³¨é‡ˆ                                                                               '] = hourly_kanban_count_full['æ—¥æ™‚'].apply(
        lambda x: 'ã‚ãªãŸã¯ã“ã®æ™‚é–“ã‚’é¸æŠã—ã¾ã—ãŸ' if x == start_time else ('éå»' if x < start_time else 'æœªæ¥')
    )

    # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    def highlight_start_time(row):
        return ['background-color: yellow' if row['æ—¥æ™‚'] == start_time else '' for _ in row]
    
    st.code(f"ğŸ“ è¨ˆç®—å¼ï¼šæœªæ¥ã®åœ¨åº«æ•° = åœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

    # æ³¨é‡ˆã‚’è¿½åŠ ï¼ˆä¾‹ã¨ã—ã¦start_timeã‚’è¡¨ç¤ºï¼‰
    st.markdown(f"")
    st.markdown(f"")
    st.markdown(f"**ä¸‹ã®è¡¨ã§äºˆæ¸¬ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™ã€‚**")
    #st.code(f"è¨ˆç®—å¼ï¼šåœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

    # 'hourly_kanban_count_full' ã¨ 'inventory_df_adjusted' ã‚’ 'æ—¥æ™‚' ã‚’ã‚­ãƒ¼ã«çµåˆ
    merged_df = pd.merge(hourly_kanban_count_full, inventory_df_adjusted, on='æ—¥æ™‚', how='outer')
    activedata_extracted = activedata_extracted[(activedata_extracted['æ—¥æ™‚'] >= hours_before) & (activedata_extracted['æ—¥æ™‚'] < end_time)]
    merged_df = pd.merge(merged_df, activedata_extracted, on='æ—¥æ™‚', how='outer')

    # å¿…è¦ã«å¿œã˜ã¦NaNã‚’0ã«ç½®ãæ›ãˆã‚‹ï¼ˆåœ¨åº«æ•°ã‚„ã‹ã‚“ã°ã‚“æ•°ã«é–¢ã—ã¦ï¼‰
    merged_df.fillna(0, inplace=True)

    # Streamlitã§è¡¨ç¤º
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ—ã®é †ç•ªã‚’æŒ‡å®š
    new_column_order = ['æ—¥æ™‚', 'ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°', 'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°', 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰','â€»æ³¨é‡ˆ                                                                               ']
    # åˆ—ã®é †ç•ªã‚’å¤‰æ›´
    merged_df = merged_df[new_column_order]

    # æ¡ä»¶ã«è©²å½“ã™ã‚‹è¡Œã®åœ¨åº«æ•°ã‚’ "-" ã«ã™ã‚‹
    merged_df.loc[
        (merged_df['æ—¥æ™‚'] >= hours_before) & 
        (merged_df['æ—¥æ™‚'] < start_time), 
        'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'
    ] = "-"

    # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦è¡¨ç¤º
    st.dataframe(merged_df.style.apply(highlight_start_time, axis=1))

# ãƒªãƒŸãƒƒãƒˆè¨ˆç®—
# def show_forecast2( unique_product, start_datetime, selected_zaiko):

#     start_date = '2024-05-01-00'
#     end_date = '2024-08-31-00'

#     #! å“ç•ªã€æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
#     product = unique_product.split('_')[0]
#     seibishitsu = unique_product.split('_')[1]

#     #! ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
#     prediction_hours = 24#ä½•æ™‚é–“å…ˆã¾ã§äºˆæ¸¬ã™ã‚‹ã®ã‹
#     past_hours = 5
#     lookback_hours = past_hours+2

#     # ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
#     st.header('äºˆæ¸¬çµæœ')

#     #!----------------------------------------------------------------------- 
#     #! è‡ªå‹•ãƒ©ãƒƒã‚¯ã®åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†
#     #!-----------------------------------------------------------------------
#     zaiko_df = read_zaiko_by_using_archive_data(start_date, end_date)
#     # å“ç•ªåˆ—ã®ç©ºç™½ã‚’å‰Šé™¤
#     zaiko_df['å“ç•ª'] = zaiko_df['å“ç•ª'].str.strip()
#     # 'è¨ˆæ¸¬æ—¥æ™‚'ã‚’datetimeå‹ã«å¤‰æ›
#     #zaiko_df['è¨ˆæ¸¬æ—¥æ™‚'] = pd.to_datetime(zaiko_df['è¨ˆæ¸¬æ—¥æ™‚'], errors='coerce')
#     # åˆ—å 'è¨ˆæ¸¬æ—¥æ™‚' ã‚’ 'æ—¥æ™‚' ã«å¤‰æ›´
#     #zaiko_df = zaiko_df.rename(columns={'è¨ˆæ¸¬æ—¥æ™‚': 'æ—¥æ™‚'})
#     # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
#     zaiko_df = zaiko_df[zaiko_df['å“ç•ª'] == product]
#     # ç‰¹å®šã®æ—¥æ™‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
#     zaiko_df = zaiko_df[zaiko_df['æ—¥æ™‚'] == start_datetime]
#     # æ—¥æ™‚ã‚’å†åº¦datetimeå‹ã«å¤‰æ›ï¼ˆå¿µã®ãŸã‚ï¼‰
#     zaiko_df['æ—¥æ™‚'] = pd.to_datetime(zaiko_df['æ—¥æ™‚'])
#     # 'æ—¥æ™‚' ã¨ 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
#     zaiko_extracted = zaiko_df[['æ—¥æ™‚', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰']]

#     #!-----------------------------------------------------------------------
#     #! æ‰€åœ¨ç®¡ç†ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®ãƒ‡ãƒ¼ã‚¿
#     #!-----------------------------------------------------------------------
#     #file_path = 'ä¸­é–“æˆæœç‰©/æ‰€åœ¨ç®¡ç†MBãƒ†ã‚™ãƒ¼ã‚¿_çµ±åˆæ¸ˆ&ç‰¹å®šæ—¥æ™‚æŠ½å‡ºæ¸ˆ.csv'
#     Timestamp_df = read_syozailt_by_using_archive_data(start_date, end_date)
#     # 'æ›´æ–°æ—¥æ™‚'åˆ—ã«ç„¡åŠ¹ãªæ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹è¡Œã‚’å‰Šé™¤ã™ã‚‹
#     data_cleaned = Timestamp_df.dropna(subset=['æ¤œåæ—¥æ™‚'])
#     #st.dataframe(data_cleaned.head(50000))
#     # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
#     data_cleaned = data_cleaned[(data_cleaned['å“ç•ª'] == product) & (data_cleaned['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] == seibishitsu)]
#     # æ™‚é–“ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€å„æ™‚é–“ã§ã®ã‹ã‚“ã°ã‚“æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹
#     data_cleaned['æ—¥æ™‚'] = data_cleaned['æ¤œåæ—¥æ™‚'].dt.floor('H')  # æ™‚é–“å˜ä½ã«ä¸¸ã‚ã‚‹
#     hourly_kanban_count = data_cleaned.groupby('æ—¥æ™‚').size().reset_index(name='ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°')
#     #st.dataframe(hourly_kanban_count)

#     # æ™‚é–“ã®ç¯„å›²ã‚’æ±ºå®šã—ã€æ¬ ææ™‚é–“å¸¯ã‚’è£œå®Œã™ã‚‹
#     full_time_range = pd.date_range(start=hourly_kanban_count['æ—¥æ™‚'].min(),end=hourly_kanban_count['æ—¥æ™‚'].max(),freq='H')

#     # å…¨ã¦ã®æ™‚é–“ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã€æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹
#     hourly_kanban_count_full = pd.DataFrame(full_time_range, columns=['æ—¥æ™‚']).merge(hourly_kanban_count, on='æ—¥æ™‚', how='left').fillna(0)

#     # ã‹ã‚“ã°ã‚“æ•°ã‚’æ•´æ•°ã«æˆ»ã™
#     hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'].astype(int)

#     # 'äºˆæ¸¬å…¥åº«æ™‚é–“'åˆ—ã¨ã—ã¦ã€5æ™‚é–“å‰ã®ã‹ã‚“ã°ã‚“æ•°ã‚’è¿½åŠ ã™ã‚‹
#     hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'].shift(past_hours)

#     # æ¬ æå€¤ï¼ˆæœ€åˆã®5æ™‚é–“åˆ†ï¼‰ã‚’0ã§åŸ‹ã‚ã‚‹
#     hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].fillna(0).astype(int)

#     #!-----------------------------------------------------------------------
#     #! Activedataã®å‡¦ç†
#     #!-----------------------------------------------------------------------
#     activedata = read_activedata_by_using_archive_data(start_date, end_date, 0)
#     # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
#     activedata = activedata[activedata['å“ç•ª'] == product]
#     #st.dataframe(activedata)
#     #! ç¨¼åƒæ™‚é–“ã§å‰²ã‚‹å‡¦ç† (ä¼‘æ†©æ™‚é–“ã®è€ƒæ…®ãŒå¿…è¦ã‹ï¼Ÿ)
#     activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] = activedata['æ—¥é‡æ•°']/activedata['åå®¹æ•°']
#     activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / 16.5
#     activedata['æ—¥ä»˜'] = pd.to_datetime(activedata['æ—¥ä»˜'])#ã“ã‚Œã—ãªã„ã¨æ¬¡ã®.resample('H')ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹
#     # æ—¥ä»˜ã‚’åŸºæº–ã«1æ™‚é–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
#     activedata = activedata.set_index('æ—¥ä»˜').resample('H').ffill().reset_index()
#     # 'æ—¥ä»˜' ã‚’datetimeå‹ã«å¤‰æ›
#     activedata['æ—¥ä»˜'] = pd.to_datetime(activedata['æ—¥ä»˜'])
#     activedata = activedata.rename(columns={'æ—¥ä»˜': 'æ—¥æ™‚'})
#     # 'æ—¥ä»˜' ã¨ 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
#     activedata_extracted = activedata[['æ—¥æ™‚', 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“']]

#     # åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
#     start_time = zaiko_extracted.iloc[0]['æ—¥æ™‚']
#     # é–‹å§‹æ™‚åˆ»ã‹ã‚‰20æ™‚é–“å¾Œã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
#     end_time = start_time + pd.Timedelta(hours=prediction_hours)
#     filtered_activedata = activedata_extracted[(activedata_extracted['æ—¥æ™‚'] >= start_time) & (activedata_extracted['æ—¥æ™‚'] < end_time)]

#     # å„æ™‚é–“å¾Œã®æ¶ˆè²»é‡ãŠã‚ˆã³å…¥åº«é‡ã‚’è€ƒæ…®ã—ãŸåœ¨åº«æ•°ã‚’è¨ˆç®—
#     inventory_after_adjustments = []
#     # ç¾åœ¨ã®åœ¨åº«æ•°ã‚’åˆæœŸå€¤ã¨ã—ã¦è¨­å®š
#     current_inventory = selected_zaiko#zaiko_extracted.iloc[0]['åœ¨åº«æ•°ï¼ˆç®±ï¼‰']

#     # 3ã¤ã®åˆ—ã‚’ä½œæˆ
#     col1, col2 = st.columns(2)
#     col1.metric(label="é¸æŠã•ã‚ŒãŸæ—¥æ™‚", value=str(start_datetime))#, delta="1 mph")
#     col2.metric(label="å…¥åŠ›ã•ã‚ŒãŸçµ„ç«‹ãƒ©ã‚¤ãƒ³ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰", value=int(current_inventory))

#     # æ™‚é–“ã”ã¨ã®åœ¨åº«æ•°ã‚’æ›´æ–°ã—ãªãŒã‚‰ãƒªã‚¹ãƒˆã«è¿½åŠ 
#     for i, row in filtered_activedata.iterrows():
#         kanban_row = hourly_kanban_count_full[hourly_kanban_count_full['æ—¥æ™‚'] == row['æ—¥æ™‚']]
#         incoming_kanban = kanban_row['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].values[0] if not kanban_row.empty else 0
#         inventory_after_adjustments.append({
#             'æ—¥æ™‚': row['æ—¥æ™‚'],
#             'åœ¨åº«æ•°ï¼ˆç®±ï¼‰': current_inventory
#         })
#         # æœ€åˆã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã¯æ¶ˆè²»ã‚’å¼•ã‹ãªã„ãŒã€ä»¥é™ã¯æ¶ˆè²»é‡ã¨å…¥åº«é‡ã‚’èª¿æ•´
#         if i != 0:
#             current_inventory = current_inventory - row['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“']  # æ¶ˆè²»é‡ã‚’å¼•ã
#             current_inventory = current_inventory + incoming_kanban  # å…¥åº«é‡ã‚’è¶³ã™
            

#     # è¨ˆç®—çµæœã‚’DataFrameã«å¤‰æ›
#     inventory_df_adjusted = pd.DataFrame(inventory_after_adjustments)

#     # æœ€åˆã®æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨ãã‚Œä»¥é™ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
#     actual_data = inventory_df_adjusted.iloc[0:1]  # æœ€åˆã®1æ™‚é–“åˆ†ã¯å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
#     forecast_data = inventory_df_adjusted.iloc[1:]  # ãã‚Œä»¥é™ã¯äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿

#     # æ™‚é–“è»¸ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã€å…¨æ™‚é–“ã®ç¯„å›²ã‚’ä½œæˆ
#     #full_time_range = pd.date_range(start=actual_data['æ—¥æ™‚'].min(), end=forecast_data['æ—¥æ™‚'].max(), freq='H')

#     # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãã‚Œãã‚Œã“ã®æ™‚é–“è»¸ã«åˆã‚ã›ã¦å†æ§‹ç¯‰ã—ã€æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹
#     #actual_data = actual_data.set_index('æ—¥æ™‚').reindex(full_time_range).reset_index().rename(columns={'index': 'æ—¥æ™‚'})
#     #forecast_data = forecast_data.set_index('æ—¥æ™‚').reindex(full_time_range).reset_index().rename(columns={'index': 'æ—¥æ™‚'})

#     # æ¬ æå€¤ã¯ãã‚Œãã‚Œ0ã«ç½®ãæ›ãˆã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
#     #actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].fillna(0, inplace=True)
#     #forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].fillna(0, inplace=True)

#     # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
#     fig = go.Figure()

#     # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’é’è‰²ã§æç”»
#     fig.add_trace(go.Bar(
#         x=actual_data['æ—¥æ™‚'], 
#         y=actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
#         name='å®Ÿç¸¾', 
#         marker_color='blue', 
#         opacity=0.3
#     ))

#     # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã§è¿½åŠ æç”»
#     fig.add_trace(go.Bar(
#         x=forecast_data['æ—¥æ™‚'], 
#         y=forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
#         name='äºˆæ¸¬', 
#         marker_color='orange', 
#         opacity=0.3
#     ))

#     # xè»¸ã‚’1æ™‚é–“ã”ã¨ã«è¡¨ç¤ºã™ã‚‹è¨­å®š
#     fig.update_layout(
#         title='äºˆæ¸¬çµæœ',  # ã“ã“ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
#         xaxis_title='æ—¥æ™‚',  # xè»¸ã‚¿ã‚¤ãƒˆãƒ«
#         yaxis_title='åœ¨åº«æ•°ï¼ˆç®±ï¼‰',  # yè»¸ã‚¿ã‚¤ãƒˆãƒ«
#         xaxis=dict(
#             tickformat="%Y-%m-%d %H:%M",  # æ—¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®š
#             dtick=3600000  # 1æ™‚é–“ã”ã¨ã«è¡¨ç¤º (3600000ãƒŸãƒªç§’ = 1æ™‚é–“)
#         ),
#         barmode='group'  # è¤‡æ•°ã®ãƒãƒ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
#     )

#     # ã‚°ãƒ©ãƒ•ã‚’Streamlitã§è¡¨ç¤º
#     st.plotly_chart(fig)

#     # 5æ™‚é–“å‰ã®æ—¥æ™‚ã‚’è¨ˆç®—
#     hours_before = start_time - pd.Timedelta(hours=lookback_hours)

#     # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«çµæœã‚’è¡¨ç¤ºã™ã‚‹
#     hourly_kanban_count_full = hourly_kanban_count_full[(hourly_kanban_count_full['æ—¥æ™‚'] >= hours_before) & (hourly_kanban_count_full['æ—¥æ™‚'] < end_time)]

#     # æ–°ã—ã„åˆ—ã€Œå‚™è€ƒã€ã‚’è¿½åŠ ã—ã€start_timeã«åŸºã¥ã„ã¦ã€Œéå»ã€ã€Œæœªæ¥ã€ã¨è¡¨ç¤º
#     hourly_kanban_count_full['â€»æ³¨é‡ˆ                                                                               '] = hourly_kanban_count_full['æ—¥æ™‚'].apply(
#         lambda x: 'ã‚ãªãŸã¯ã“ã®æ™‚é–“ã‚’é¸æŠã—ã¾ã—ãŸ' if x == start_time else ('éå»' if x < start_time else 'æœªæ¥')
#     )

#     # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
#     def highlight_start_time(row):
#         return ['background-color: yellow' if row['æ—¥æ™‚'] == start_time else '' for _ in row]
    
#     st.code(f"ğŸ“ è¨ˆç®—å¼ï¼šæœªæ¥ã®åœ¨åº«æ•° = åœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

#     # æ³¨é‡ˆã‚’è¿½åŠ ï¼ˆä¾‹ã¨ã—ã¦start_timeã‚’è¡¨ç¤ºï¼‰
#     st.markdown(f"")
#     st.markdown(f"")
#     st.markdown(f"**ä¸‹ã®è¡¨ã§äºˆæ¸¬ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™ã€‚**")
#     #st.code(f"è¨ˆç®—å¼ï¼šåœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

#     # 'hourly_kanban_count_full' ã¨ 'inventory_df_adjusted' ã‚’ 'æ—¥æ™‚' ã‚’ã‚­ãƒ¼ã«çµåˆ
#     merged_df = pd.merge(hourly_kanban_count_full, inventory_df_adjusted, on='æ—¥æ™‚', how='outer')
#     activedata_extracted = activedata_extracted[(activedata_extracted['æ—¥æ™‚'] >= hours_before) & (activedata_extracted['æ—¥æ™‚'] < end_time)]
#     merged_df = pd.merge(merged_df, activedata_extracted, on='æ—¥æ™‚', how='outer')

#     # å¿…è¦ã«å¿œã˜ã¦NaNã‚’0ã«ç½®ãæ›ãˆã‚‹ï¼ˆåœ¨åº«æ•°ã‚„ã‹ã‚“ã°ã‚“æ•°ã«é–¢ã—ã¦ï¼‰
#     merged_df.fillna(0, inplace=True)

#     # Streamlitã§è¡¨ç¤º
#     # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ—ã®é †ç•ªã‚’æŒ‡å®š
#     new_column_order = ['æ—¥æ™‚', 'ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°', 'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°', 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰','â€»æ³¨é‡ˆ                                                                               ']
#     # åˆ—ã®é †ç•ªã‚’å¤‰æ›´
#     merged_df = merged_df[new_column_order]

#     # æ¡ä»¶ã«è©²å½“ã™ã‚‹è¡Œã®åœ¨åº«æ•°ã‚’ "-" ã«ã™ã‚‹
#     merged_df.loc[
#         (merged_df['æ—¥æ™‚'] >= hours_before) & 
#         (merged_df['æ—¥æ™‚'] < start_time), 
#         'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'
#     ] = "-"

#     # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦è¡¨ç¤º
#     st.dataframe(merged_df.style.apply(highlight_start_time, axis=1))

#! åœ¨åº«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
def show_zaiko_simulation( selected_datetime, change_rate):

    #! æ—¥é‡ç®±æ•°ã‚’æ™‚é–“å˜ä½ã«ã™ã‚‹ãŸã‚ã«
    #todo ç¨¼åƒæ™‚é–“ãªã©ã‚’è€ƒãˆã‚‹ãªã‚‰ã€16.5ã§å‰²ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã ãŒã€ãã®å ´åˆã¯ã©ã®æ™‚é–“å¸¯ãŒç¨¼åƒæ™‚é–“åˆ†ã‹ã‚‹å¿…è¦ãŒã‚ã‚‹
    kado_time = 25
    selected_datetime_end = selected_datetime + timedelta(hours=kado_time-1)

    #! é¸æŠæƒ…å ±è¡¨ç¤º
    col1, col2 = st.columns(2)
    col1.metric(label="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹æ™‚é–“", value=selected_datetime.strftime("%Y-%m-%d %H:%M"))
    col2.metric(label="ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚é–“", value=selected_datetime_end.strftime("%Y-%m-%d %H:%M"))
    #col2.metric(label="é¸æŠå¤‰å‹•ç‡", value=change_rate)

    # 1æ™‚é–“ã”ã¨ã®æ™‚é–“åˆ—ï¼ˆ24æ™‚é–“åˆ†ï¼‰ã‚’ä½œæˆ
    time_series = pd.date_range(start=selected_datetime, periods=24, freq="H")
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    time_df = pd.DataFrame({"æ—¥æ™‚": time_series})
    #st.dataframe(time_df)

    #! è‡ªå‹•ãƒ©ãƒƒã‚¯ã®åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    # todo å¼•æ•°é–¢ä¿‚ãªãå…¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã—ã¦ã‚‹
    zaiko_df = read_zaiko_by_using_archive_data(selected_datetime.strftime('%Y-%m-%d-%H'), selected_datetime.strftime('%Y-%m-%d-%H'))
    # todo
    #! å“ç•ªåˆ—ã‚’æ˜‡é †ã«ã‚½ãƒ¼ãƒˆ
    zaiko_df = zaiko_df.sort_values(by='å“ç•ª', ascending=True)
    #! ç„¡åŠ¹ãªå€¤ã‚’ NaN ã«å¤‰æ›
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = pd.to_numeric(zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'], errors='coerce')
    #! å“ç•ªã”ã¨ã«æ¬ æå€¤ï¼ˆNaNï¼‰ã‚’åŸ‹ã‚ã‚‹(å‰æ–¹åŸ‹ã‚å¾Œæ–¹åŸ‹ã‚)
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df.groupby('å“ç•ª')['æ‹ ç‚¹æ‰€ç•ªåœ°'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))
    #! ãã‚Œã§ã‚‚ç½®æ›ã§ããªã„ã‚‚ã®ã¯NaN ã‚’ 0 ã§åŸ‹ã‚ã‚‹
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'].fillna(0).astype(int).astype(str)
    #! strå‹ã«å¤‰æ›
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'].astype(int).astype(str)
    #! å—å…¥å ´æ‰€æƒ…å ±æº–å‚™
    file_path = 'temp/ãƒã‚¹ã‚¿ãƒ¼_å“ç•ª&ä»•å…¥å…ˆå&ä»•å…¥å…ˆå·¥å ´å.csv'
    syozaikyotenchi_data = pd.read_csv(file_path, encoding='shift_jis')
    #! ç©ºç™½æ–‡å­—åˆ—ã‚„éæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’NaNã«å¤‰æ›
    syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'] = pd.to_numeric(syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'], errors='coerce')
    #! strå‹ã«å¤‰æ›
    syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'] = syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'].fillna(0).astype(int).astype(str)
    #! å—å…¥å ´æ‰€è¿½åŠ 
    zaiko_df = pd.merge(zaiko_df, syozaikyotenchi_data[['å“ç•ª','æ‹ ç‚¹æ‰€ç•ªåœ°','å—å…¥å ´æ‰€']], on=['å“ç•ª', 'æ‹ ç‚¹æ‰€ç•ªåœ°'], how='left')
    #! æ—¥ä»˜åˆ—ã‚’ä½œæˆ
    zaiko_df['æ—¥ä»˜'] = zaiko_df['æ—¥æ™‚'].dt.date
    #! å“ç•ª_å—å…¥ç•ªå·ä½œæˆ
    zaiko_df['å“ç•ª_å—å…¥å ´æ‰€'] = zaiko_df['å“ç•ª'].astype(str) + "_" + zaiko_df['å—å…¥å ´æ‰€'].astype(str)
    # productåˆ—ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—
    #unique_hinbans = zaiko_df['å“ç•ª_å—å…¥å ´æ‰€'].unique()
    #st.dataframe(zaiko_df.head(10000))

    # 24æ™‚é–“å¾Œ
    start_datetime = selected_datetime - timedelta(hours=6)
    end_datetime = selected_datetime + timedelta(days=1)
    #st.write(start_datetime,end_datetime)
    # todo
    Timestamp_df = read_syozailt_by_using_archive_data(start_datetime.strftime('%Y-%m-%d-%H'), end_datetime.strftime('%Y-%m-%d-%H'))
    # todo
    Timestamp_df['ä»•å…¥å…ˆå·¥å ´å'] = Timestamp_df['ä»•å…¥å…ˆå·¥å ´å'].apply(lambda x: '< NULL >' if pd.isna(x) else x)
    Timestamp_df = Timestamp_df.rename(columns={'ä»•å…¥å…ˆå·¥å ´å': 'ç™ºé€å ´æ‰€å'})# ã‚³ãƒ©ãƒ åå¤‰æ›´

    #! Activedataã®çµ±åˆ
    # todo
    flag_DB_active = 0
    #todo æ—¥å˜ä½ã®ãŸã‚ã€00ã«ã—ãªã„ã¨ã€ãã®æ—¥ã®ç´å…¥æ—¥ãŒå…¥ã‚‰ãªã„
    #start_date = datetime.strptime(start_datetime, '%Y-%m-%d-%H')
    start_date = start_datetime.replace(hour=0, minute=0, second=0)
    start_date = pd.to_datetime(start_date) - pd.Timedelta(days=1)
    end_date = pd.to_datetime(end_datetime) + pd.Timedelta(days=1)
    active_df = read_activedata_by_using_archive_data(start_date, end_date, flag_DB_active)
    # todo
    file_path = 'temp/activedata.csv'#ã‚¹ãƒ†ãƒƒãƒ—ï¼‘,2ã§ä½µç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€å¤‰æ•°ã§ã¯ãªãä¸€æ™‚ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã«æ ¼ç´ã—ã¦ä½¿ç”¨
    Activedata = pd.read_csv(file_path, encoding='shift_jis')
    # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
    Activedata['æ—¥ä»˜'] = pd.to_datetime(Activedata['æ—¥ä»˜'], errors='coerce')
    Activedata['å“ç•ª_å—å…¥å ´æ‰€'] = Activedata['å“ç•ª'].astype(str) + "_" + Activedata['å—å…¥å ´æ‰€'].astype(str)
    Activedata['æ—¥é‡ç®±æ•°'] = Activedata['æ—¥é‡æ•°']/Activedata['åå®¹æ•°']
    Activedata['å‡ºåº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = Activedata['æ—¥é‡ç®±æ•°']/kado_time
    # productåˆ—ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—
    unique_hinbans = Activedata['å“ç•ª_å—å…¥å ´æ‰€'].unique()
    #st.dataframe(Activedata)

    # testç”¨
    unique_hinbans = Activedata['å“ç•ª_å—å…¥å ´æ‰€'].unique()[:20]
    
    # ç©ºã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    hinban_list = []
    data_list = []

    #! ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå“ç•ªã®çµ„ã¿åˆã‚ã›ã®æ•°ã ã‘å‡¦ç†ã‚’è¡Œã†
    for unique_hinban in unique_hinbans:

        # æœ€åˆã® _ ã§ 2 ã¤ã«åˆ†å‰²
        part_number, seibishitsu = unique_hinban.split("_", 1)
        #st.write(part_number, seibishitsu)

        # testç”¨
        #part_number = "9036340085"
        #seibishitsu = "1Y"

        #! ---------------------------åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™------------------------------
        #! å…¨ãƒ‡ãƒ¼ã‚¿ã€€â‡’ã€€å“ç•ªã€å—å…¥å ´æ‰€æŠ½å‡ºã€€â‡’ã€€selected_datetimeã®ã¿æŠ½å‡º
        #! ------------------------------------------------------------------------
        filtered_zaiko_df = zaiko_df[(zaiko_df['å“ç•ª'] == part_number) & (zaiko_df['å—å…¥å ´æ‰€'] == seibishitsu)]
        # æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹è¡Œã‚’å–å¾—
        filtered_zaiko_df = filtered_zaiko_df[filtered_zaiko_df["æ—¥æ™‚"] == selected_datetime]
        #! åœ¨åº«ãƒ‡ãƒ¼ã‚¿ãªã„ãªã‚‰ãã®å“ç•ªã¯ã‚¹ã‚­ãƒƒãƒ—
        if len(filtered_zaiko_df) == 0:
            continue
        # å®Ÿè¡Œçµæœã®ç¢ºèª
        #st.dataframe(filtered_zaiko_df)

        #! -----------------------------Activedataã®æº–å‚™----------------------------
        #! å…¨ãƒ‡ãƒ¼ã‚¿ â‡’ å“ç•ªã€æ•´å‚™å®¤æŠ½å‡º â‡’ æŒ‡å®šæœŸé–“æŠ½å‡º
        #! -------------------------------------------------------------------------
        #! åŒå“ç•ªã€åŒæ•´å‚™å®¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        filtered_Activedata = Activedata[(Activedata['å“ç•ª'] == part_number) & (Activedata['æ•´å‚™å®¤'] == seibishitsu)]
        #st.dataframe(filtered_Activedata)
        # todoï¼ˆãƒ€ãƒ–ã‚Šæ¶ˆã™ã€è¨­è¨ˆå€¤é•ã†ãªã©ã§ãƒ€ãƒ–ã‚ŠãŒã‚ã‚‹ï¼‰
        before_rows = len(filtered_Activedata)# é©ç”¨å‰ã®è¡Œæ•°ã‚’è¨˜éŒ²
        filtered_Activedata = filtered_Activedata.drop_duplicates(subset=["æ—¥ä»˜"], keep="first")  # æœ€åˆã®è¡Œã‚’æ¡ç”¨
        after_rows = len(filtered_Activedata)# é©ç”¨å¾Œã®è¡Œæ•°ã‚’è¨˜éŒ²
        # ã‚‚ã—è¡Œæ•°ãŒå¤‰ã‚ã£ãŸã‚‰ã€å‰Šé™¤ãŒæ©Ÿèƒ½ã—ãŸã¨åˆ¤å®šã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›
        # if before_rows != after_rows:
        #     st.write(f"{part_number}, {seibishitsu}é‡è¤‡å‰Šé™¤ãŒé©ç”¨ã•ã‚Œã¾ã—ãŸ: {before_rows - after_rows} è¡ŒãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚")
        # todo
        #! 1æ™‚é–“ã”ã¨ã«å¤‰æ›
        filtered_Activedata = filtered_Activedata.set_index('æ—¥ä»˜').resample('H').ffill().reset_index()
        filtered_Activedata = filtered_Activedata.reset_index(drop=True)
        filtered_Activedata = filtered_Activedata.rename(columns={'æ—¥ä»˜': 'æ—¥æ™‚'})
        filtered_Activedata['æ—¥æ™‚'] = pd.to_datetime(filtered_Activedata['æ—¥æ™‚'])
        #st.dataframe(filtered_Activedata)
        #! æ˜¼å‹¤å¤œå‹¤ã®è€ƒæ…®é–¢æ•°
        def adjust_datetime(x):
            if 0 <= x.hour < 8:
                # æ—¥ä»˜ã‚’å‰æ—¥ã«å¤‰æ›´ã—ã€æ™‚é–“ã¯ãã®ã¾ã¾
                return x + pd.Timedelta(days=1)
            else:
                # ãã®ã¾ã¾ã®æ—¥ä»˜ã‚’è¿”ã™
                return x
        #! æ˜¼å‹¤å¤œå‹¤ã®è€ƒæ…®
        filtered_Activedata['æ—¥æ™‚'] = filtered_Activedata['æ—¥æ™‚'].apply(adjust_datetime)
        #! æŒ‡å®šæœŸé–“ã®ã¿æŠ½å‡º
        filtered_Activedata = filtered_Activedata[filtered_Activedata['æ—¥æ™‚'].isin(time_df['æ—¥æ™‚'])].copy()
        #! Activeãƒ‡ãƒ¼ã‚¿ãªã„ãªã‚‰ãã®å“ç•ªã¯ã‚¹ã‚­ãƒƒãƒ—
        if len(filtered_Activedata) == 0:
            continue
        #st.write(part_number, seibishitsu, len(filtered_Activedata))
        #st.dataframe(filtered_Activedata)

        #! ---------------------------Activeã¨åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ----------------------
        basedata = pd.merge(filtered_Activedata[['æ—¥æ™‚','å“ç•ª_å—å…¥å ´æ‰€','å“å','æ—¥é‡æ•°','åå®¹æ•°','è¨­è¨ˆå€¤MIN','è¨­è¨ˆå€¤MAX','æ—¥é‡ç®±æ•°','å‡ºåº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰']], filtered_zaiko_df[['æ—¥æ™‚', 'å“ç•ª_å—å…¥å ´æ‰€', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰']], on=['å“ç•ª_å—å…¥å ´æ‰€', 'æ—¥æ™‚'], how='left')#! è‡ªå‹•ãƒ©ãƒƒã‚¯åœ¨åº«çµåˆ
        # å®Ÿè¡Œçµæœã®ç¢ºèª
        #st.dataframe(basedata)

        #! ---------------------------ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ã®è¨ˆç®—----------------------
        #! ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã®è¨ˆç®—é–¢æ•°
        def calculate_scheduled_nouyu_kanban(df, start_date, end_date):
            """
            æŒ‡å®šæœŸé–“å†…ã®ç´å…¥ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€ç´å…¥äºˆå®šæ—¥æ™‚ã”ã¨ã«é›†è¨ˆã™ã‚‹é–¢æ•°ã€‚

            Args:
                df (pd.DataFrame): ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
                start_date (str): æŠ½å‡ºé–‹å§‹æ—¥ï¼ˆä¾‹ï¼š'2024/3/5'ï¼‰ã€‚
                end_date (str): æŠ½å‡ºçµ‚äº†æ—¥ã€‚

            Returns:
                pd.DataFrame: ç´å…¥äºˆå®šæ—¥æ™‚ã”ã¨ã®é›†è¨ˆçµæœã‚’æ ¼ç´ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
            """
            # æ—¥ä»˜ã‚’datetimeå½¢å¼ã«å¤‰æ›
            #todo æ—¥å˜ä½ã®ãŸã‚ã€00ã«ã—ãªã„ã¨ã€ãã®æ—¥ã®ç´å…¥æ—¥ãŒå…¥ã‚‰ãªã„
            start_date = datetime.strptime(start_date, '%Y-%m-%d-%H')
            start_date = start_date.replace(hour=0, minute=0, second=0)
            start_date = pd.to_datetime(start_date)
            end_date = pd.to_datetime(end_date) + pd.Timedelta(days=1)
            #st.write(start_date,end_date)

            # â‘  "ç´å…¥æ—¥"åˆ—ãŒæœŸé–“å†…ã«è©²å½“ã™ã‚‹è¡Œã‚’æŠ½å‡º
            filtered_df = df[(pd.to_datetime(df['ç´å…¥æ—¥']) >= start_date) & (pd.to_datetime(df['ç´å…¥æ—¥']) < end_date)]
            #st.dataframe(filtered_df)

            if len(filtered_df) != 0:

                #st.header("å®šåˆ»ä¾¿ç¢ºèª")
                #st.dataframe(filtered_df)

                # â‘¡ æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å‡¦ç†
                # â‘¡-1 "ç´å…¥ä¾¿"åˆ—ã‹ã‚‰æ•°å€¤ã‚’å–å¾—
                filtered_df['B'] = filtered_df['ç´å…¥ä¾¿'].astype(int)

                # â‘¡-2 "Bä¾¿_å®šåˆ»"åˆ—ã®å€¤ã‚’å–å¾—ã—ã¦æ–°ã—ã„åˆ—"ç´å…¥äºˆå®šæ™‚é–“"ã«æ ¼ç´
                filtered_df['ç´å…¥äºˆå®šæ™‚é–“'] = filtered_df.apply(lambda row: row[f"{row['B']}ä¾¿_å®šåˆ»"] if f"{row['B']}ä¾¿_å®šåˆ»" in df.columns else None, axis=1)

                # â‘¡-3 "ç´å…¥äºˆå®šæ™‚é–“"åˆ—ãŒ0æ™‚ï½8æ™‚ã®å ´åˆã«"ç´å…¥æ—¥_è£œæ­£"åˆ—ã‚’1æ—¥å¾Œã«è¨­å®š
                filtered_df['ç´å…¥äºˆå®šæ™‚é–“'] = pd.to_datetime(filtered_df['ç´å…¥äºˆå®šæ™‚é–“'], format='%H:%M:%S', errors='coerce').dt.time
                #st.dataframe(filtered_df)
                #todo å¤œå‹¤ä¾¿ã¯+1ãŒå¿…è¦ï¼ï¼ï¼ï¼
                #todo ä»Šã®è¨ˆç®—ã§ã„ã„ã‹ä¸æ˜ï¼ï¼\
                filtered_df['ç´å…¥æ—¥_è£œæ­£'] = filtered_df.apply(lambda row: (pd.to_datetime(row['ç´å…¥æ—¥']) + pd.Timedelta(days=1)).strftime('%Y-%m-%d')
                                                            if row['ç´å…¥äºˆå®šæ™‚é–“'] and 0 <= row['ç´å…¥äºˆå®šæ™‚é–“'].hour < 6 else row['ç´å…¥æ—¥'], axis=1)

                # â‘¡-4 "ç´å…¥æ—¥_è£œæ­£"åˆ—ã¨"ç´å…¥äºˆå®šæ™‚é–“"åˆ—ã‚’çµ±åˆã—"ç´å…¥äºˆå®šæ—¥æ™‚"åˆ—ã‚’ä½œæˆ
                filtered_df['ç´å…¥äºˆå®šæ—¥æ™‚'] = pd.to_datetime(filtered_df['ç´å…¥æ—¥_è£œæ­£']) + pd.to_timedelta(filtered_df['ç´å…¥äºˆå®šæ™‚é–“'].astype(str))

                #st.write(len(filtered_df))

                # â‘¡-5 "ç´å…¥äºˆå®šæ—¥æ™‚"åˆ—ã§é›†è¨ˆã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ ¼ç´
                nonyu_yotei_df = filtered_df.groupby('ç´å…¥äºˆå®šæ—¥æ™‚').agg(
                    ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°=('ç´å…¥äºˆå®šæ—¥æ™‚', 'size'),
                    ç´å…¥äºˆå®šä¾¿ä¸€è¦§=('ç´å…¥ä¾¿', lambda x: list(x)),
                    ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“ä¸€è¦§=('ã‹ã‚“ã°ã‚“ã‚·ãƒªã‚¢ãƒ«', lambda x: list(x)),
                    ç´å…¥äºˆå®šä¾¿=('ç´å…¥ä¾¿', lambda x: list(set(x))[0] if len(set(x)) == 1 else list(set(x)))  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªç´å…¥ä¾¿ã‚’ã‚¹ã‚«ãƒ©ãƒ¼ã«å¤‰æ›
                ).reset_index()
                
                nonyu_yotei_df['ç´å…¥äºˆå®šæ—¥æ™‚_raw'] = nonyu_yotei_df['ç´å…¥äºˆå®šæ—¥æ™‚']
                # "ç´å…¥äºˆå®šæ—¥æ™‚"åˆ—ã®åˆ†ä»¥é™ã‚’0ã«è¨­å®š
                nonyu_yotei_df['ç´å…¥äºˆå®šæ—¥æ™‚'] = nonyu_yotei_df['ç´å…¥äºˆå®šæ—¥æ™‚'].apply(lambda x: x.replace(minute=0, second=0) if pd.notna(x) else x)

                nonyu_yotei_df = nonyu_yotei_df.rename(columns={'ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°': 'ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'})# ã‚³ãƒ©ãƒ åå¤‰æ›´
                nonyu_yotei_df = nonyu_yotei_df.rename(columns={'ç´å…¥äºˆå®šæ—¥æ™‚': 'æ—¥æ™‚'})# ã‚³ãƒ©ãƒ åå¤‰æ›´

                #todo æ¤œåæ—¥æ™‚2æ™‚56åˆ†ã ã¨ã€2æ™‚ã«ãªã‚‹ãªã€‚
                kensyu_df = filtered_df.groupby('æ¤œåæ—¥æ™‚').agg(
                    æ¤œåã‹ã‚“ã°ã‚“æ•°=('æ¤œåæ—¥æ™‚', 'size'),
                    æ¤œåã‹ã‚“ã°ã‚“ä¸€è¦§=('ã‹ã‚“ã°ã‚“ã‚·ãƒªã‚¢ãƒ«', lambda x: list(x))
                ).reset_index()

                kensyu_df['æ¤œåæ—¥æ™‚_raw'] = kensyu_df['æ¤œåæ—¥æ™‚']
                kensyu_df['æ¤œåæ—¥æ™‚'] = kensyu_df['æ¤œåæ—¥æ™‚'].apply(lambda x: x.replace(minute=0, second=0) if pd.notna(x) else x)
                kensyu_df = kensyu_df.rename(columns={'æ¤œåæ—¥æ™‚': 'æ—¥æ™‚'})# ã‚³ãƒ©ãƒ åå¤‰æ›´

            else:
                nonyu_yotei_df = pd.DataFrame(columns=["æ—¥æ™‚", "ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰", "ç´å…¥äºˆå®šä¾¿ä¸€è¦§",
                                                       "ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“ä¸€è¦§","ç´å…¥äºˆå®šä¾¿","ç´å…¥äºˆå®šæ—¥æ™‚_raw"])
                kensyu_df = pd.DataFrame(columns=["æ—¥æ™‚", "æ¤œåæ—¥æ™‚_raw", "æ¤œåã‹ã‚“ã°ã‚“æ•°",
                                                       "æ¤œåã‹ã‚“ã°ã‚“ä¸€è¦§"])

            return nonyu_yotei_df, kensyu_df
        
        #! æ‰€åœ¨ç®¡ç†MBã®ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿
        #! åŒå“ç•ªã€åŒæ•´å‚™å®¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        filtered_Timestamp_df = Timestamp_df[(Timestamp_df['å“ç•ª'] == part_number) & (Timestamp_df['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] == seibishitsu)]
        #! ä»•å…¥å…ˆåã€ä»•å…¥å…ˆå·¥å ´åæŠ½å‡º
        unique_shiresaki = filtered_Timestamp_df['ä»•å…¥å…ˆå'].unique()[0]
        unique_shiresaki_kojo = filtered_Timestamp_df['ç™ºé€å ´æ‰€å'].unique()[0]
        #st.write(unique_shiresaki,unique_shiresaki_kojo)
        #st.dataframe(filtered_Timestamp_df)
        #! ä»•å…¥å…ˆä¾¿æƒ…å ±æŠ½å‡º
        arrival_times_df = calculate_supplier_truck_arrival_types2()
        #! ä¸€è‡´ã™ã‚‹ä»•å…¥ã‚Œå…ˆãƒ•ãƒ©ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ã‚¨ãƒ©ãƒ¼ã‚’å‡ºã™
        #! 3ã¤ã®åˆ—ï¼ˆä»•å…¥å…ˆåã€ç™ºé€å ´æ‰€åã€æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ï¼‰ã§æ¡ä»¶ã‚’æº€ãŸã™è¡Œã‚’arrival_times_dfã‹ã‚‰æŠ½å‡ºã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ matched_arrival_times_dfã‚’ä½œæˆ
        # æ¡ä»¶ã¯ã€lagged_featuresã¨åŒã˜ä»•å…¥å…ˆåã€ç™ºé€å ´æ‰€åã€æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ã‚’æŒã¤ã‚‚ã®
        matched_arrival_times_df = arrival_times_df[
            (arrival_times_df['ä»•å…¥å…ˆå'].isin([unique_shiresaki])) &
            (arrival_times_df['ç™ºé€å ´æ‰€å'].isin([unique_shiresaki_kojo])) &
            (arrival_times_df['å—å…¥'].isin([seibishitsu]))
        ]
        matched_arrival_times_df = matched_arrival_times_df.rename(columns={'å—å…¥': 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'})# ã‚³ãƒ©ãƒ åå¤‰æ›´
        #st.dataframe(matched_arrival_times_df)
        # çµ±åˆã™ã‚‹åˆ—ã®é¸åˆ¥
        columns_to_extract_t = ['ã‹ã‚“ã°ã‚“ã‚·ãƒªã‚¢ãƒ«','å“å','ç´å…¥æ—¥', 'ç´å…¥ä¾¿','æ¤œåæ—¥æ™‚','ä»•å…¥å…ˆå', 'ç™ºé€å ´æ‰€å', 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰']
        columns_to_extract_l = matched_arrival_times_df.filter(regex='ä¾¿_å®šåˆ»').columns.tolist() + ['ä»•å…¥å…ˆå', 'ç™ºé€å ´æ‰€å', 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰','ç´å…¥å…ˆ']
        # çµ±åˆ
        filtered_Timestamp_df = pd.merge(filtered_Timestamp_df[columns_to_extract_t], matched_arrival_times_df[columns_to_extract_l], on=['ä»•å…¥å…ˆå', 'ç™ºé€å ´æ‰€å', 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'], how='left')
        #st.dataframe(filtered_Timestamp_df)
        #! ç´å…¥ã‚¿ã‚¤ãƒ—æŠ½å‡º
        unique_nonyu_type = filtered_Timestamp_df['ç´å…¥å…ˆ'].unique()[0]
        #st.write(unique_nonyu_type)
        #! ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã®è¨ˆç®—
        #st.write(start_datetime,end_datetime)
        nonyu_yotei_df, kensyu_df = calculate_scheduled_nouyu_kanban(filtered_Timestamp_df, start_datetime.strftime('%Y-%m-%d-%H'), end_datetime.strftime('%Y-%m-%d-%H'))
        #st.dataframe(nonyu_yotei_df)
        #st.write(part_number, seibishitsu, nonyu_yotei_df["ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"].mean(), filtered_Activedata['æ—¥é‡ç®±æ•°'].mean()/filtered_Activedata['ã‚µã‚¤ã‚¯ãƒ«å›æ•°'].mean(), before_rows - after_rows)

        # 1æ™‚é–“ã”ã¨ã®æ™‚é–“åˆ—ï¼ˆ24æ™‚é–“åˆ†ï¼‰ã‚’ä½œæˆ
        time_series = pd.date_range(start=start_datetime, periods=24+5, freq="H")
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
        nonyu_data_df = pd.DataFrame({"æ—¥æ™‚": time_series})
        #st.dataframe(nonyu_data_df)

        #! æ—¥æ™‚ã§ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
        nonyu_data_df = pd.merge(nonyu_data_df, nonyu_yotei_df, on='æ—¥æ™‚', how='left')
        nonyu_data_df = pd.merge(nonyu_data_df, kensyu_df, on='æ—¥æ™‚', how='left')
        #! ã™ã¹ã¦ã®Noneå€¤ã‚’0ã«ç½®ãæ›ãˆ
        # basedataã«çµ±åˆã™ã‚‹éš›ã€nonyu_yotei_dfã«å­˜åœ¨ã—ãªã„æ—¥æ™‚ã¯Noneã«ãªã‚‹ãŸã‚
        nonyu_data_df = nonyu_data_df.fillna(0)
        #st.dataframe(nonyu_data_df)

        if unique_nonyu_type == "è¥¿å°¾æ±":
            nonyu_lt = 5
        else:
            nonyu_lt = 1

        # nonyu_ltæ™‚é–“å¾Œã«ã‚·ãƒ•ãƒˆ
        # æ˜‡é †ã«ä¸¦ã³æ›¿ãˆ
        nonyu_data_df = nonyu_data_df.sort_values(by="æ—¥æ™‚")
        nonyu_data_df["å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"] = nonyu_data_df["ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"].shift(nonyu_lt)
        #st.dataframe(nonyu_data_df)

        #! ---------------------------------------ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ--------------------------------------------------------
        #! æ—¥æ™‚ã§ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
        basedata = basedata.sort_values(by="æ—¥æ™‚")
        basedata = basedata.fillna(0)
        basedata = pd.merge(basedata, nonyu_data_df, on='æ—¥æ™‚', how='left')
        #st.dataframe(basedata)

        #! åœ¨åº«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        # åœ¨åº«æ•°ã‚’è¨ˆç®—ï¼ˆç´¯ç©è¨ˆç®—ï¼‰
        basedata["åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤"]=basedata["åœ¨åº«æ•°ï¼ˆç®±ï¼‰"]
        for i in range(1, len(basedata)):
            basedata.loc[i, "åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤"] = (
                basedata.loc[i - 1, "åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤"]  # 1ã¤ä¸Šã®è¡Œã®åœ¨åº«æ•°
                + basedata.loc[i, "å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"]  # ç´å…¥åˆ†ã‚’åŠ ç®—
                - basedata.loc[i, "å‡ºåº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"]  # å‡ºåº«åˆ†ã‚’æ¸›ç®—
            )
        #st.dataframe(basedata)

        #! åˆ¤å®š
        basedata["ä¸‹é™å‰²ã‚Œ"] = (basedata["åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤"] < basedata["è¨­è¨ˆå€¤MIN"]).astype(int)
        basedata["ä¸Šé™è¶Šãˆ"] = (basedata["åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤"] > basedata["è¨­è¨ˆå€¤MAX"]).astype(int)
        basedata["åœ¨åº«0"] = (basedata["åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤"] < 0).astype(int)

        #! å„é …ç›®ã®åˆè¨ˆã‚’è¨ˆç®—
        total_lower_limit = basedata["ä¸‹é™å‰²ã‚Œ"].sum()
        total_upper_exceed = basedata["ä¸Šé™è¶Šãˆ"].sum()
        total_stock_zero = basedata["åœ¨åº«0"].sum()
        # æ¡ä»¶åˆ†å²ã§OK/NGã«å¤‰æ›
        total_lower_limit = "NG" if total_lower_limit > 0 else "OK"
        total_upper_exceed = "NG" if total_upper_exceed > 0 else "OK"
        total_stock_zero = "NG" if total_stock_zero > 0 else "OK"

        #st.dataframe(basedata)

        # ---- å¿…è¦ãªåˆ—ã‚’æŠ½å‡º ----
        basedata_filtered = basedata[["æ—¥æ™‚", "åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤", "è¨­è¨ˆå€¤MIN", "è¨­è¨ˆå€¤MAX"]]

        # Matplotlibã§ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(basedata_filtered["æ—¥æ™‚"], basedata_filtered["åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤"], label="åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤", marker="o")
        ax.fill_between(basedata_filtered["æ—¥æ™‚"], basedata_filtered["è¨­è¨ˆå€¤MIN"], basedata_filtered["è¨­è¨ˆå€¤MAX"], 
                        color="lightgray", alpha=0.5, label="è¨­è¨ˆå€¤ç¯„å›² (MIN-MAX)")
        #ã“ã‚Œã¯ã„ã‚‰ãªã„ã‹ã‚‚
        #ax.axhline(y=basedata_filtered["è¨­è¨ˆå€¤MIN"].iloc[0], color="blue", linestyle="--", label="è¨­è¨ˆå€¤MIN")
        #ax.axhline(y=basedata_filtered["è¨­è¨ˆå€¤MAX"].iloc[0], color="red", linestyle="--", label="è¨­è¨ˆå€¤MAX")

        # ---- ã‚°ãƒ©ãƒ•ã®è£…é£¾ ----
        ax.set_title("åœ¨åº«æ•°ã¨è¨­è¨ˆå€¤ã®æ¯”è¼ƒ", fontsize=14)
        ax.set_xlabel("æ—¥æ™‚", fontsize=12)
        ax.set_ylabel("åœ¨åº«æ•°", fontsize=12)
        ax.legend()
        ax.grid(True)
        plt.xticks(rotation=45)

        # ç”»é¢ã«è¡¨ç¤º
        #st.pyplot(fig)

        # æ—¥æ™‚åˆ—ã‚’datetimeå‹ã«å¤‰æ›
        basedata_filtered['æ—¥æ™‚'] = pd.to_datetime(basedata_filtered['æ—¥æ™‚'])

        # ä¸€ç•ªå¤ã„æ™‚åˆ»ã‚’åŸºæº–æ™‚åˆ»ï¼ˆç¾åœ¨æ™‚åˆ»ï¼‰ã¨ã™ã‚‹
        base_time = basedata_filtered['æ—¥æ™‚'].min()

        # åŸºæº–æ™‚åˆ»ã‹ã‚‰ã®çµŒéæ™‚é–“ (æ™‚é–“å˜ä½) ã‚’è¨ˆç®—
        basedata_filtered['çµŒéæ™‚é–“(æ™‚é–“)'] = (basedata_filtered['æ—¥æ™‚'] - base_time).dt.total_seconds() / 3600

        # è¨­è¨ˆå€¤MINã‚’å‰²ã‚‹æœ€åˆã®æ™‚é–“
        time_min = basedata_filtered.loc[basedata_filtered['åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤'] < basedata_filtered['è¨­è¨ˆå€¤MIN'], 'çµŒéæ™‚é–“(æ™‚é–“)'].min()

        # è¨­è¨ˆå€¤MAXã‚’å‰²ã‚‹æœ€åˆã®æ™‚é–“
        time_max = basedata_filtered.loc[basedata_filtered['åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤'] > basedata_filtered['è¨­è¨ˆå€¤MAX'], 'çµŒéæ™‚é–“(æ™‚é–“)'].min()

        # åœ¨åº«ãŒ0ã‚ˆã‚Šå°ã•ããªã‚‹æœ€åˆã®æ™‚é–“
        time_zero = basedata_filtered.loc[basedata_filtered['åœ¨åº«æ•°ï¼ˆç®±ï¼‰_äºˆæ¸¬å€¤'] < 0, 'çµŒéæ™‚é–“(æ™‚é–“)'].min()

        # st.dataframe(basedata_filtered)
        # st.write(time_min,time_max,time_zero)

        # ---- PNGãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ ----
        save_dir = "temp/åœ¨åº«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
        os.makedirs(save_dir, exist_ok=True)
        output_file = f"{save_dir}/{unique_hinban}.png"
        fig.savefig(output_file, format="png", dpi=300, bbox_inches="tight")

        #! å¿…è¦ãƒ‡ãƒ¼ã‚¿ã ã‘æº–å‚™
        hinban_list.append(output_file)
        unique_hinmei = filtered_Timestamp_df['å“å'].unique()[0]
        data_list.append({"å“ç•ª_æ•´å‚™å®¤": unique_hinban, "å“å": unique_hinmei,
                           "ä»•å…¥å…ˆå": unique_shiresaki, "ç™ºé€å·¥å ´å": unique_shiresaki_kojo,
                           "ä¸‹é™å‰²ã‚Œ":total_lower_limit,"ä¸Šé™è¶Šãˆ":total_upper_exceed,"æ¬ å“":total_stock_zero,
                           "ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“":time_min,"ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“":time_max,"æ¬ å“ã¾ã§ã®æ™‚é–“":time_zero})

    # ãƒ­ãƒ¼ã‚«ãƒ«ã® PNG ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
    def img_to_base64(file_path):
        with open(file_path, "rb") as f:
            data = f.read()
        # Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦æ–‡å­—åˆ—ã«å¤‰æ›
        return base64.b64encode(data).decode("utf-8")

    # DataFrame ã«å¤‰æ›
    df_A = pd.DataFrame(data_list)
    # ç”»åƒã‚’ Base64 å¤‰æ›
    base64_images = [img_to_base64(p) for p in hinban_list]
    # DataFrame ã«å¤‰æ›
    df_B = pd.DataFrame(base64_images, columns=["ç”»åƒbase64"])

    #edited_df = st.data_editor(df_A, num_rows="dynamic")

    # DataFrame ã‚’çµ±åˆï¼ˆæ¨ªæ–¹å‘ã«çµåˆï¼‰
    data = pd.concat([df_A, df_B], axis=1)

    df = pd.DataFrame(data)

    #st.dataframe(df)

    #import csv

    st.divider()

    # æœ€å¾Œã®åˆ—ã‚’é™¤ã
    df_excluded_last = df.iloc[:, :-1]

    # CSVæ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆShift_JISã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰
    csv_data = df_excluded_last.to_csv(index=False, encoding='cp932')#, quoting=csv.QUOTE_ALL)

    # CSVã‚’ãƒã‚¤ãƒŠãƒªã«å¤‰æ› â†’ Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    b64_encoded = base64.b64encode(csv_data.encode('cp932')).decode()

    # data URI ã‚¹ã‚­ãƒ¼ãƒ ã®æ–‡å­—åˆ—ã‚’ä½œæˆ
    # Shift_JIS ã§è§£é‡ˆã•ã‚Œã‚‹ã‚ˆã† charset=shift_jis ã‚‚ä»˜ä¸
    csv_uri = f"data:text/csv;charset=shift_jis;base64,{b64_encoded}"

    # ã‚«ã‚¹ã‚¿ãƒ HTMLãƒœã‚¿ãƒ³ï¼ˆä¾‹ï¼‰
    custom_button = f"""
        <a download="åœ¨åº«äºˆæ¸¬çµæœ.csv" href="{csv_uri}">
            <button style="
                background-color: #4CAF50;
                border: none;
                color: white;
                padding: 12px 24px;
                text-align: center;
                text-decoration: none;
                display: inline-block;
                font-size: 16px;
                border-radius: 8px;
                cursor: pointer;
            ">
            ğŸ“¥ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
            </button>
        </a>
    """

    st.markdown(custom_button, unsafe_allow_html=True)

    def style_ok_ng(value):
        """OK/NGæ–‡å­—åˆ—ã‚’è‰²ä»˜ããƒãƒƒã‚¸HTMLã«å¤‰æ›"""
        if value == "OK":
            return """<span class="badge-ok">OK</span>"""
        elif value == "NG":
            return """<span class="badge-ng">NG</span>"""
        else:
            return str(value)

    #HTML çµ„ã¿ç«‹ã¦
    html_code = """
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <title>DataTables with Default Filters and Sorting</title>

        <!-- â–¼ DataTablesç”¨CSS (CDN) â–¼ -->
        <link rel="stylesheet" type="text/css"
            href="https://cdn.datatables.net/1.13.4/css/jquery.dataTables.css"/>
        <script type="text/javascript"
                src="https://cdn.jsdelivr.net/npm/jquery@3.6.4/dist/jquery.min.js"></script>
        <script type="text/javascript"
                src="https://cdn.datatables.net/1.13.4/js/jquery.dataTables.js"></script>

        <style>
        /* ãƒ†ãƒ¼ãƒ–ãƒ«ã®åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ« */
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #ccc;
            padding: 8px;
            text-align: center;
        }

        /* OK/NGãƒãƒƒã‚¸ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        .badge-ok {
            display: inline-block;
            padding: 5px 10px;
            color: #fff;
            background-color: #00aaff;
            border-radius: 5px;
        }
        .badge-ng {
            display: inline-block;
            padding: 5px 10px;
            color: #fff;
            background-color: #ff4444;
            border-radius: 5px;
        }

        /* ãƒˆã‚°ãƒ«ãƒœã‚¿ãƒ³ */
        .toggle-button {
            padding: 8px 16px;
            font-size: 16px;
            background-color: #008CBA;
            color: white;
            border: none;
            border-radius: 6px;
            cursor: pointer;
        }
        .toggle-button:hover {
            background-color: #006F9A;
        }

        /* ãƒˆã‚°ãƒ«è¡¨ç¤ºéƒ¨åˆ†ï¼ˆç”»åƒï¼‰ã¯åˆæœŸéè¡¨ç¤º */
        .hidden-content {
            display: none;
            margin-top: 8px;
        }

        /* ã‚½ãƒ¼ãƒˆã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        .filter-select {
            margin: 10px 0;
            padding: 6px 12px;
            font-size: 14px;
            border-radius: 4px;
            border: 1px solid #ccc;
        }
        </style>

        <script>
        $(document).ready(function() {
            // DataTables ã®åˆæœŸåŒ–
            var table = $('#myTable').DataTable({
                paging: true,
                searching: true,
                ordering: true,
                pageLength: 10,
                lengthMenu: [10, 20, 30],
                order: [[5, 'asc']],  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã€Œæ¬ å“ã¾ã§ã®æ™‚é–“ã€ã‚’é™é †ã«ã‚½ãƒ¼ãƒˆ
                columnDefs: [
                    {
                        targets: [7, 9, 5], // æ•°å€¤åˆ—ï¼ˆä¸‹é™å‰²ã‚Œã€ä¸Šé™è¶Šãˆã€æ¬ å“ã¾ã§ã®æ™‚é–“ï¼‰
                        render: function(data, type, row) {
                            if (type === 'sort' || type === 'type') {
                                // NaN ã‚’ -Infinity ã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆå¯èƒ½ã«
                                return data === null || data === '' ? Infinity : parseFloat(data);
                            }
                            return data; // è¡¨ç¤ºæ™‚ã¯ãã®ã¾ã¾
                        }
                    }
                ]
            });

            // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
            table.column(4).search('NG').draw();  // æ¬ å“åˆ—ã‚’ NG ã§ãƒ•ã‚£ãƒ«ã‚¿
            table.column(6).search('NG').draw();  // ä¸‹é™å‰²ã‚Œåˆ—ã‚’ NG ã§ãƒ•ã‚£ãƒ«ã‚¿
            table.column(8).search('').draw();   // ä¸Šé™è¶Šãˆåˆ—ã¯ãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼ˆã™ã¹ã¦ï¼‰

            // åˆ—å˜ä½ãƒ•ã‚£ãƒ«ã‚¿ã®å‡¦ç†
            function doFilter() {
                var valKekin = $('#filter_kekin').val();
                var valKagen = $('#filter_kagen').val();
                var valJougen = $('#filter_jougen').val();
                table.column(4).search(valKekin).draw();
                table.column(6).search(valKagen).draw();
                table.column(8).search(valJougen).draw();
            }

            // ãƒ•ã‚£ãƒ«ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ doFilter ã‚’å®Ÿè¡Œ
            $('#filter_kekin').on('change', doFilter);
            $('#filter_kagen').on('change', doFilter);
            $('#filter_jougen').on('change', doFilter);

            // ã‚½ãƒ¼ãƒˆæ¡ä»¶ã®å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆ
            $('#sort-order').on('change', function() {
                var columnIndex = $(this).val();  // ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®å€¤ã‚’å–å¾—
                table.order([columnIndex, 'asc']).draw();  // æŒ‡å®šåˆ—ã§é™é †ã‚½ãƒ¼ãƒˆ
            });
        });

        // ãƒˆã‚°ãƒ«æ©Ÿèƒ½ã®å®Ÿè£…
        function toggleImage(id) {
            var elem = document.getElementById(id);
            if (elem.style.display === 'none' || elem.style.display === '') {
                elem.style.display = 'block';
            } else {
                elem.style.display = 'none';
            }
        }
        </script>
    </head>
    <body>
        <!-- â–¼ åˆ—å˜ä½ãƒ•ã‚£ãƒ«ã‚¿UI: æ¬ å“, ä¸‹é™å‰²ã‚Œ, ä¸Šé™è¶Šãˆ â–¼ -->
        <div class="filter-boxes">
            <label>æ¬ å“:
                <select id="filter_kekin" class="filter-select">
                    <option value="">(ã™ã¹ã¦)</option>
                    <option value="OK">OKã®ã¿</option>
                    <option value="NG" selected>NGã®ã¿</option>
                </select>
            </label>

            <label>ä¸‹é™å‰²ã‚Œ:
                <select id="filter_kagen" class="filter-select">
                    <option value="">(ã™ã¹ã¦)</option>
                    <option value="OK">OKã®ã¿</option>
                    <option value="NG" selected>NGã®ã¿</option>
                </select>
            </label>

            <label>ä¸Šé™è¶Šãˆ:
                <select id="filter_jougen" class="filter-select">
                    <option value="" selected>(ã™ã¹ã¦)</option>
                    <option value="OK">OKã®ã¿</option>
                    <option value="NG">NGã®ã¿</option>
                </select>
            </label>
        </div>

        <!-- â–¼ ã‚½ãƒ¼ãƒˆç”¨ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’è¿½åŠ  -->
        <div>
            <label for="sort-order">ä¸¦ã³æ›¿ãˆæ¡ä»¶:</label>
            <select id="sort-order" class="filter-select">
                <option value="6">ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“ï¼ˆå¤§ãã„é †ï¼‰</option>
                <option value="8">ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“ï¼ˆå¤§ãã„é †ï¼‰</option>
                <option value="4" selected>æ¬ å“ã¾ã§ã®æ™‚é–“ï¼ˆå¤§ãã„é †ï¼‰</option>
            </select>
        </div>

        <!-- â–¼ DataTables å¯¾å¿œãƒ†ãƒ¼ãƒ–ãƒ« -->
        <table id="myTable" class="display">
            <thead>
                <tr>
                    <th>å“ç•ª_æ•´å‚™å®¤</th>
                    <th>å“å</th>
                    <th>ä»•å…¥å…ˆå</th>
                    <th>ä»•å…¥å…ˆå·¥å ´å</th>
                    <th>æ¬ å“</th>
                    <th>æ¬ å“ã¾ã§ã®æ™‚é–“</th>
                    <th>ä¸‹é™å‰²ã‚Œ</th>
                    <th>ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“</th>
                    <th>ä¸Šé™è¶Šãˆ</th>
                    <th>ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“</th>
                    <th>ã‚°ãƒ©ãƒ•</th>
                </tr>
            </thead>
            <tbody>
    """

    # DataFrame ã®è¡Œã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦ HTML ã«å¤‰æ›
    # for i, row in df.iterrows():
    #     html_code += f"""
    #     <tr>
    #         <td>{row['å“ç•ª_æ•´å‚™å®¤']}</td>
    #         <td>{row['å“å']}</td>
    #         <td>{row['ä»•å…¥å…ˆå']}</td>
    #         <td>{row['ç™ºé€å·¥å ´å']}</td>
    #         <td>{row['ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“']}</td>
    #         <td>{row['ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“']}</td>
    #         <td>{row['æ¬ å“ã¾ã§ã®æ™‚é–“']}</td>
    #         <td>{style_ok_ng(row['æ¬ å“'])}</td>
    #         <td>{style_ok_ng(row['ä¸‹é™å‰²ã‚Œ'])}</td>
    #         <td>{style_ok_ng(row['ä¸Šé™è¶Šãˆ'])}</td>
    #         <td>
    #             <button class="toggle-button" onclick="toggleImage('hidden-content-{i}')">è¡¨ç¤º</button>
    #             <div id="hidden-content-{i}" class="hidden-content">
    #                 <img src="data:image/png;base64,{row['ç”»åƒbase64']}" style="max-width: 200px;">
    #             </div>
    #         </td>
    #     </tr>
    #     """
    for i, row in df.iterrows():
        html_code += f"""
        <tr>
            <td>{row['å“ç•ª_æ•´å‚™å®¤']}</td>
            <td>{row['å“å']}</td>
            <td>{row['ä»•å…¥å…ˆå']}</td>
            <td>{row['ç™ºé€å·¥å ´å']}</td>
            <td>{style_ok_ng(row['æ¬ å“'])}</td>
            <td>{row['æ¬ å“ã¾ã§ã®æ™‚é–“']}</td>
            <td>{style_ok_ng(row['ä¸‹é™å‰²ã‚Œ'])}</td>
             <td>{row['ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“']}</td>
            <td>{style_ok_ng(row['ä¸Šé™è¶Šãˆ'])}</td>
            <td>{row['ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“']}</td>
            <td>
                <button class="toggle-button" onclick="toggleImage('hidden-content-{i}')">è¡¨ç¤º</button>
                <div id="hidden-content-{i}" class="hidden-content">
                    <img src="data:image/png;base64,{row['ç”»åƒbase64']}" style="max-width: 200px;">
                </div>
            </td>
        </tr>
        """

    html_code += """
            </tbody>
        </table>
    </body>
    </html>
    """

    # 4) Streamlit ã§è¡¨ç¤º
    components.html(html_code, height=1000, scrolling=True)

    #st.dataframe(df)

    return df_excluded_last


#! åœ¨åº«äºˆæ¸¬
def show_forecast2( unique_product, start_datetime, selected_zaiko):

    start_date = '2024-05-01-00'
    end_date = '2024-08-31-00'

    #! å“ç•ªã€æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    product = unique_product.split('_')[0]
    seibishitsu = unique_product.split('_')[1]

    #! ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    prediction_hours = 24#ä½•æ™‚é–“å…ˆã¾ã§äºˆæ¸¬ã™ã‚‹ã®ã‹
    past_hours = 5
    lookback_hours = past_hours+2

    # ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
    st.header('äºˆæ¸¬çµæœ')

    #!----------------------------------------------------------------------- 
    #! è‡ªå‹•ãƒ©ãƒƒã‚¯ã®åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†
    #!-----------------------------------------------------------------------
    zaiko_df = read_zaiko_by_using_archive_data(start_date, end_date)
    # å“ç•ªåˆ—ã®ç©ºç™½ã‚’å‰Šé™¤
    zaiko_df['å“ç•ª'] = zaiko_df['å“ç•ª'].str.strip()
    # 'è¨ˆæ¸¬æ—¥æ™‚'ã‚’datetimeå‹ã«å¤‰æ›
    #zaiko_df['è¨ˆæ¸¬æ—¥æ™‚'] = pd.to_datetime(zaiko_df['è¨ˆæ¸¬æ—¥æ™‚'], errors='coerce')
    # åˆ—å 'è¨ˆæ¸¬æ—¥æ™‚' ã‚’ 'æ—¥æ™‚' ã«å¤‰æ›´
    #zaiko_df = zaiko_df.rename(columns={'è¨ˆæ¸¬æ—¥æ™‚': 'æ—¥æ™‚'})
    # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    zaiko_df = zaiko_df[zaiko_df['å“ç•ª'] == product]
    # ç‰¹å®šã®æ—¥æ™‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    zaiko_df = zaiko_df[zaiko_df['æ—¥æ™‚'] == start_datetime]
    # æ—¥æ™‚ã‚’å†åº¦datetimeå‹ã«å¤‰æ›ï¼ˆå¿µã®ãŸã‚ï¼‰
    zaiko_df['æ—¥æ™‚'] = pd.to_datetime(zaiko_df['æ—¥æ™‚'])
    # 'æ—¥æ™‚' ã¨ 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
    zaiko_extracted = zaiko_df[['æ—¥æ™‚', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰']]

    #!-----------------------------------------------------------------------
    #! æ‰€åœ¨ç®¡ç†ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®ãƒ‡ãƒ¼ã‚¿
    #!-----------------------------------------------------------------------
    #file_path = 'ä¸­é–“æˆæœç‰©/æ‰€åœ¨ç®¡ç†MBãƒ†ã‚™ãƒ¼ã‚¿_çµ±åˆæ¸ˆ&ç‰¹å®šæ—¥æ™‚æŠ½å‡ºæ¸ˆ.csv'
    Timestamp_df = read_syozailt_by_using_archive_data(start_date, end_date)
    # 'æ›´æ–°æ—¥æ™‚'åˆ—ã«ç„¡åŠ¹ãªæ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹è¡Œã‚’å‰Šé™¤ã™ã‚‹
    data_cleaned = Timestamp_df.dropna(subset=['æ¤œåæ—¥æ™‚'])
    st.dataframe(data_cleaned.head(50000))
    # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    data_cleaned = data_cleaned[(data_cleaned['å“ç•ª'] == product) & (data_cleaned['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] == seibishitsu)]
    # æ™‚é–“ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€å„æ™‚é–“ã§ã®ã‹ã‚“ã°ã‚“æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹
    data_cleaned['æ—¥æ™‚'] = data_cleaned['æ¤œåæ—¥æ™‚'].dt.floor('H')  # æ™‚é–“å˜ä½ã«ä¸¸ã‚ã‚‹
    hourly_kanban_count = data_cleaned.groupby('æ—¥æ™‚').size().reset_index(name='ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°')
    #st.dataframe(hourly_kanban_count)

    # æ™‚é–“ã®ç¯„å›²ã‚’æ±ºå®šã—ã€æ¬ ææ™‚é–“å¸¯ã‚’è£œå®Œã™ã‚‹
    full_time_range = pd.date_range(start=hourly_kanban_count['æ—¥æ™‚'].min(),end=hourly_kanban_count['æ—¥æ™‚'].max(),freq='H')

    # å…¨ã¦ã®æ™‚é–“ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã€æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹
    hourly_kanban_count_full = pd.DataFrame(full_time_range, columns=['æ—¥æ™‚']).merge(hourly_kanban_count, on='æ—¥æ™‚', how='left').fillna(0)

    # ã‹ã‚“ã°ã‚“æ•°ã‚’æ•´æ•°ã«æˆ»ã™
    hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'].astype(int)

    # 'äºˆæ¸¬å…¥åº«æ™‚é–“'åˆ—ã¨ã—ã¦ã€5æ™‚é–“å‰ã®ã‹ã‚“ã°ã‚“æ•°ã‚’è¿½åŠ ã™ã‚‹
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'].shift(past_hours)

    # æ¬ æå€¤ï¼ˆæœ€åˆã®5æ™‚é–“åˆ†ï¼‰ã‚’0ã§åŸ‹ã‚ã‚‹
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].fillna(0).astype(int)

    #!-----------------------------------------------------------------------
    #! Activedataã®å‡¦ç†
    #!-----------------------------------------------------------------------
    activedata = read_activedata_by_using_archive_data(start_date, end_date, 0)
    # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    activedata = activedata[activedata['å“ç•ª'] == product]
    #st.dataframe(activedata)
    #! ç¨¼åƒæ™‚é–“ã§å‰²ã‚‹å‡¦ç† (ä¼‘æ†©æ™‚é–“ã®è€ƒæ…®ãŒå¿…è¦ã‹ï¼Ÿ)
    activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] = activedata['æ—¥é‡æ•°']/activedata['åå®¹æ•°']
    activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / 16.5
    activedata['æ—¥ä»˜'] = pd.to_datetime(activedata['æ—¥ä»˜'])#ã“ã‚Œã—ãªã„ã¨æ¬¡ã®.resample('H')ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹
    # æ—¥ä»˜ã‚’åŸºæº–ã«1æ™‚é–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    activedata = activedata.set_index('æ—¥ä»˜').resample('H').ffill().reset_index()
    # 'æ—¥ä»˜' ã‚’datetimeå‹ã«å¤‰æ›
    activedata['æ—¥ä»˜'] = pd.to_datetime(activedata['æ—¥ä»˜'])
    activedata = activedata.rename(columns={'æ—¥ä»˜': 'æ—¥æ™‚'})
    # 'æ—¥ä»˜' ã¨ 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
    activedata_extracted = activedata[['æ—¥æ™‚', 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“']]

    # åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
    start_time = zaiko_extracted.iloc[0]['æ—¥æ™‚']
    # é–‹å§‹æ™‚åˆ»ã‹ã‚‰20æ™‚é–“å¾Œã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    end_time = start_time + pd.Timedelta(hours=prediction_hours)
    filtered_activedata = activedata_extracted[(activedata_extracted['æ—¥æ™‚'] >= start_time) & (activedata_extracted['æ—¥æ™‚'] < end_time)]

    # å„æ™‚é–“å¾Œã®æ¶ˆè²»é‡ãŠã‚ˆã³å…¥åº«é‡ã‚’è€ƒæ…®ã—ãŸåœ¨åº«æ•°ã‚’è¨ˆç®—
    inventory_after_adjustments = []
    # ç¾åœ¨ã®åœ¨åº«æ•°ã‚’åˆæœŸå€¤ã¨ã—ã¦è¨­å®š
    current_inventory = zaiko_extracted.iloc[0]['åœ¨åº«æ•°ï¼ˆç®±ï¼‰']

    # 3ã¤ã®åˆ—ã‚’ä½œæˆ
    col1, col2 = st.columns(2)
    col1.metric(label="é¸æŠã•ã‚ŒãŸæ—¥æ™‚", value=str(start_datetime))#, delta="1 mph")
    col2.metric(label="å…¥åŠ›ã•ã‚ŒãŸçµ„ç«‹ãƒ©ã‚¤ãƒ³ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰", value=int(current_inventory))

    # æ™‚é–“ã”ã¨ã®åœ¨åº«æ•°ã‚’æ›´æ–°ã—ãªãŒã‚‰ãƒªã‚¹ãƒˆã«è¿½åŠ 
    for i, row in filtered_activedata.iterrows():
        kanban_row = hourly_kanban_count_full[hourly_kanban_count_full['æ—¥æ™‚'] == row['æ—¥æ™‚']]
        incoming_kanban = kanban_row['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].values[0] if not kanban_row.empty else 0
        inventory_after_adjustments.append({
            'æ—¥æ™‚': row['æ—¥æ™‚'],
            'åœ¨åº«æ•°ï¼ˆç®±ï¼‰': current_inventory
        })
        # æœ€åˆã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã¯æ¶ˆè²»ã‚’å¼•ã‹ãªã„ãŒã€ä»¥é™ã¯æ¶ˆè²»é‡ã¨å…¥åº«é‡ã‚’èª¿æ•´
        if i != 0:
            current_inventory = current_inventory - row['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“']  # æ¶ˆè²»é‡ã‚’å¼•ã
            current_inventory = current_inventory + incoming_kanban  # å…¥åº«é‡ã‚’è¶³ã™
            

    # è¨ˆç®—çµæœã‚’DataFrameã«å¤‰æ›
    inventory_df_adjusted = pd.DataFrame(inventory_after_adjustments)

    # æœ€åˆã®æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨ãã‚Œä»¥é™ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    actual_data = inventory_df_adjusted.iloc[0:1]  # æœ€åˆã®1æ™‚é–“åˆ†ã¯å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
    forecast_data = inventory_df_adjusted.iloc[1:]  # ãã‚Œä»¥é™ã¯äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿

    # æ™‚é–“è»¸ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã€å…¨æ™‚é–“ã®ç¯„å›²ã‚’ä½œæˆ
    #full_time_range = pd.date_range(start=actual_data['æ—¥æ™‚'].min(), end=forecast_data['æ—¥æ™‚'].max(), freq='H')

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãã‚Œãã‚Œã“ã®æ™‚é–“è»¸ã«åˆã‚ã›ã¦å†æ§‹ç¯‰ã—ã€æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹
    #actual_data = actual_data.set_index('æ—¥æ™‚').reindex(full_time_range).reset_index().rename(columns={'index': 'æ—¥æ™‚'})
    #forecast_data = forecast_data.set_index('æ—¥æ™‚').reindex(full_time_range).reset_index().rename(columns={'index': 'æ—¥æ™‚'})

    # æ¬ æå€¤ã¯ãã‚Œãã‚Œ0ã«ç½®ãæ›ãˆã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    #actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].fillna(0, inplace=True)
    #forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].fillna(0, inplace=True)

    # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
    fig = go.Figure()

    # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’é’è‰²ã§æç”»
    fig.add_trace(go.Bar(
        x=actual_data['æ—¥æ™‚'], 
        y=actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
        name='å®Ÿç¸¾', 
        marker_color='blue', 
        opacity=0.3
    ))

    # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã§è¿½åŠ æç”»
    fig.add_trace(go.Bar(
        x=forecast_data['æ—¥æ™‚'], 
        y=forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
        name='äºˆæ¸¬', 
        marker_color='orange', 
        opacity=0.3
    ))

    # xè»¸ã‚’1æ™‚é–“ã”ã¨ã«è¡¨ç¤ºã™ã‚‹è¨­å®š
    fig.update_layout(
        title='äºˆæ¸¬çµæœ',  # ã“ã“ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
        xaxis_title='æ—¥æ™‚',  # xè»¸ã‚¿ã‚¤ãƒˆãƒ«
        yaxis_title='åœ¨åº«æ•°ï¼ˆç®±ï¼‰',  # yè»¸ã‚¿ã‚¤ãƒˆãƒ«
        xaxis=dict(
            tickformat="%Y-%m-%d %H:%M",  # æ—¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®š
            dtick=3600000  # 1æ™‚é–“ã”ã¨ã«è¡¨ç¤º (3600000ãƒŸãƒªç§’ = 1æ™‚é–“)
        ),
        barmode='group'  # è¤‡æ•°ã®ãƒãƒ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    )

    # ã‚°ãƒ©ãƒ•ã‚’Streamlitã§è¡¨ç¤º
    st.plotly_chart(fig)

    # 5æ™‚é–“å‰ã®æ—¥æ™‚ã‚’è¨ˆç®—
    hours_before = start_time - pd.Timedelta(hours=lookback_hours)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«çµæœã‚’è¡¨ç¤ºã™ã‚‹
    hourly_kanban_count_full = hourly_kanban_count_full[(hourly_kanban_count_full['æ—¥æ™‚'] >= hours_before) & (hourly_kanban_count_full['æ—¥æ™‚'] < end_time)]

    # æ–°ã—ã„åˆ—ã€Œå‚™è€ƒã€ã‚’è¿½åŠ ã—ã€start_timeã«åŸºã¥ã„ã¦ã€Œéå»ã€ã€Œæœªæ¥ã€ã¨è¡¨ç¤º
    hourly_kanban_count_full['â€»æ³¨é‡ˆ                                                                               '] = hourly_kanban_count_full['æ—¥æ™‚'].apply(
        lambda x: 'ã‚ãªãŸã¯ã“ã®æ™‚é–“ã‚’é¸æŠã—ã¾ã—ãŸ' if x == start_time else ('éå»' if x < start_time else 'æœªæ¥')
    )

    # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    def highlight_start_time(row):
        return ['background-color: yellow' if row['æ—¥æ™‚'] == start_time else '' for _ in row]
    
    st.code(f"ğŸ“ è¨ˆç®—å¼ï¼šæœªæ¥ã®åœ¨åº«æ•° = åœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

    # æ³¨é‡ˆã‚’è¿½åŠ ï¼ˆä¾‹ã¨ã—ã¦start_timeã‚’è¡¨ç¤ºï¼‰
    st.markdown(f"")
    st.markdown(f"")
    st.markdown(f"**ä¸‹ã®è¡¨ã§äºˆæ¸¬ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™ã€‚**")
    #st.code(f"è¨ˆç®—å¼ï¼šåœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

    # 'hourly_kanban_count_full' ã¨ 'inventory_df_adjusted' ã‚’ 'æ—¥æ™‚' ã‚’ã‚­ãƒ¼ã«çµåˆ
    merged_df = pd.merge(hourly_kanban_count_full, inventory_df_adjusted, on='æ—¥æ™‚', how='outer')
    activedata_extracted = activedata_extracted[(activedata_extracted['æ—¥æ™‚'] >= hours_before) & (activedata_extracted['æ—¥æ™‚'] < end_time)]
    merged_df = pd.merge(merged_df, activedata_extracted, on='æ—¥æ™‚', how='outer')

    # å¿…è¦ã«å¿œã˜ã¦NaNã‚’0ã«ç½®ãæ›ãˆã‚‹ï¼ˆåœ¨åº«æ•°ã‚„ã‹ã‚“ã°ã‚“æ•°ã«é–¢ã—ã¦ï¼‰
    merged_df.fillna(0, inplace=True)

    # Streamlitã§è¡¨ç¤º
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ—ã®é †ç•ªã‚’æŒ‡å®š
    new_column_order = ['æ—¥æ™‚', 'ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°', 'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°', 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰','â€»æ³¨é‡ˆ                                                                               ']
    # åˆ—ã®é †ç•ªã‚’å¤‰æ›´
    merged_df = merged_df[new_column_order]

    # æ¡ä»¶ã«è©²å½“ã™ã‚‹è¡Œã®åœ¨åº«æ•°ã‚’ "-" ã«ã™ã‚‹
    merged_df.loc[
        (merged_df['æ—¥æ™‚'] >= hours_before) & 
        (merged_df['æ—¥æ™‚'] < start_time), 
        'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'
    ] = "-"

    # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦è¡¨ç¤º
    st.dataframe(merged_df.style.apply(highlight_start_time, axis=1))








