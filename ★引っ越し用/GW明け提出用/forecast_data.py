# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®import
import streamlit as st
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import base64
from joblib import Parallel, delayed
import time

# è‡ªä½œé–¢æ•°ã®èª­ã¿è¾¼ã¿
from get_data import compute_hourly_buhin_zaiko_data_by_hinban, \
    compute_hourly_specific_checkpoint_kanbansu_data_by_hinban, \
        compute_hourly_tehai_data_by_hinban, \
            get_kado_schedule_from_172_20_113_185, \
                get_hinban_master,\
                    get_hinban_info_detail,\
                        compute_hourly_buhin_zaiko_data_by_all_hinban, \
                            compute_hourly_specific_checkpoint_kanbansu_data_by_all_hinban

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
plt.rcParams['font.family'] = 'MS Gothic'  # Windows

# å„ç¨®è¨­å®šç”¨ãƒ•ã‚¡ã‚¤ãƒ«
CONFIG_PATH = '../../configs/settings.json'

# MARK:ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†å…±é€šé–¢æ•°
def run_simulation(
    zaiko_extracted,
    hourly_kanban_count_full,
    filtered_tehai_data,
    kado_df,
    start_datetime_for_calc,
    end_datetime_for_calc,
    start_datetime_for_show,
    column_name,
    mode,
    out_parameter,
    selected_zaiko_hako = None,
    selected_zaiko_buhin = None
):

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
    def calculate_inventory_adjustments(hourly_kanban_count_full, 
                                  filtered_tehai_data, kado_df, start_datetime_for_calc, 
                                  start_datetime_for_show, end_datetime_for_calc, 
                                  current_inventory_hako_or_buhin, out_parameter, column_name,incoming_column,
                                  daily_consumption_column, max_daily_consumption_column,
                                  min_baseline_column,max_baseline_column,unit_type):

        """
        å„æ™‚é–“å¾Œã®æ¶ˆè²»äºˆå®šæ•°ãŠã‚ˆã³å…¥åº«äºˆå®šæ•°ã‚’è€ƒæ…®ã—ãŸåœ¨åº«æ•°ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
        
        Parameters:
        -----------
        hourly_kanban_count_full : pandas.DataFrame
            INæƒ…å ±ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        filtered_tehai_data : pandas.DataFrame
            OUTæƒ…å ±ãƒ‡ãƒ¼ã‚¿
        kado_df : pandas.DataFrame
            ç¨¼åƒãƒ•ãƒ©ã‚°ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        start_datetime_for_calc : datetime
            è¨ˆç®—é–‹å§‹æ—¥æ™‚
        start_datetime_for_show : datetime
            è¡¨ç¤ºé–‹å§‹æ—¥æ™‚
        end_datetime_for_calc : datetime
            è¨ˆç®—çµ‚äº†æ—¥æ™‚
        current_inventory_hako_or_buhin : float
            ç¾åœ¨ã®åœ¨åº«æ•°ï¼ˆç®± or éƒ¨å“ï¼‰
        out_parameter : str
            å‡ºåŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ"æ—¥é‡ã‚’æ¡ç”¨ã™ã‚‹" or "æ—¥é‡MAXã‚’æ¡ç”¨ã™ã‚‹"ï¼‰
        column_name : str
            åˆ—å
        incoming_column : str
            'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°' or 'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'
        daily_consumption_column : str
            "æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“" or æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“
        max_daily_consumption_column : str
            "æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“" or "æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“"
        min_baseline_column : str
            ä¸‹é™åŸºæº–ç·šã®åˆ—å
        max_baseline_column : str
            ä¸Šé™åŸºæº–ç·šã®åˆ—å
        unit_type : str
            "ç®±æ›ç®—" or "éƒ¨å“æ›ç®—"
            
        Returns:
        --------
        pandas.DataFrame
            çµåˆã•ã‚ŒãŸæœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """

        # è¨ˆç®—å˜ä½ã«å¿œã˜ã¦åœ¨åº«æ•°ã®åå‰ã‚’å¤‰æ›´
        if unit_type == "ç®±æ›ç®—":
            zaiko_name = 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'
        elif unit_type == "éƒ¨å“æ›ç®—":
            zaiko_name = 'åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'

        # å„æ™‚é–“å¾Œã®æ¶ˆè²»äºˆå®šæ•°ãŠã‚ˆã³å…¥åº«äºˆå®šæ•°ã‚’è€ƒæ…®ã—ãŸäºˆæ¸¬åœ¨åº«ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆã‚’åˆæœŸåŒ–
        inventory_after_adjustments = []
        
        count = 0
        # æ™‚é–“ã”ã¨ã®åœ¨åº«æ•°ã‚’æ›´æ–°ã—ãªãŒã‚‰ãƒªã‚¹ãƒˆã«è¿½åŠ 
        for i, row in filtered_tehai_data.iterrows():
            kanban_row = hourly_kanban_count_full[hourly_kanban_count_full['æ—¥æ™‚'] == row['æ—¥æ™‚']]
            filtered_kado_df = kado_df[kado_df['æ—¥æ™‚'] == row['æ—¥æ™‚']]
            kado_row = filtered_kado_df['ç¨¼åƒãƒ•ãƒ©ã‚°'].values[0]
            incoming_kanban = kanban_row[incoming_column].values[0] if not kanban_row.empty else 0

            # é¸æŠæ™‚é–“ã‹ã‚‰åœ¨åº«å¢—æ¸›ã®è¨ˆç®—ã‚’è¡Œã†
            if row['æ—¥æ™‚'] >= start_datetime_for_calc:
                inventory_after_adjustments.append({
                    'æ—¥æ™‚': row['æ—¥æ™‚'],
                    zaiko_name: current_inventory_hako_or_buhin,
                    'è¨­è¨ˆå€¤MIN': row[min_baseline_column],
                    'è¨­è¨ˆå€¤MAX': row[max_baseline_column]
                })

                # æœ€åˆã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã¯æ¶ˆè²»ã‚’å¼•ã‹ãªã„ãŒã€ä»¥é™ã¯æ¶ˆè²»é‡ã¨å…¥åº«é‡ã‚’èª¿æ•´
                if count != 0:
                    # ç¨¼åƒãƒ•ãƒ©ã‚°ãŒ0ã§ãªã„å ´åˆã®ã¿æ¸›ç®—
                    if kado_row != 0:
                        if out_parameter == "æ—¥é‡ã‚’æ¡ç”¨ã™ã‚‹":
                            current_inventory_hako_or_buhin = current_inventory_hako_or_buhin - row[daily_consumption_column]
                        elif out_parameter == "æ—¥é‡MAXã‚’æ¡ç”¨ã™ã‚‹":
                            current_inventory_hako_or_buhin = current_inventory_hako_or_buhin - row[max_daily_consumption_column]
                    current_inventory_hako_or_buhin = current_inventory_hako_or_buhin + incoming_kanban

                count = count + 1

        # è¨ˆç®—çµæœã‚’DataFrameã«å¤‰æ›
        inventory_df_adjusted = pd.DataFrame(inventory_after_adjustments)

        # ç´å…¥æ™‚é–“ã®ç¯„å›²ã‚’èª¿æ•´
        start_datetime_for_nonyu = start_datetime_for_show.strftime('%Y-%m-%d %H:%M:%S')
        end_datetime_for_nonyu = end_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
        hourly_kanban_count_filtered = hourly_kanban_count_full[
            (hourly_kanban_count_full['æ—¥æ™‚'] >= start_datetime_for_nonyu) & 
            (hourly_kanban_count_full['æ—¥æ™‚'] <= end_datetime_for_nonyu)
        ]

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®çµåˆ
        merged_df = pd.merge(hourly_kanban_count_filtered, inventory_df_adjusted, on='æ—¥æ™‚', how='outer')
        merged_df = pd.merge(merged_df, filtered_tehai_data, on='æ—¥æ™‚', how='outer')
        merged_df = pd.merge(merged_df, kado_df, on='æ—¥æ™‚', how='outer')

        # åˆ—ã®é †ç•ªã‚’å¤‰æ›´
        new_column_order = ['æ—¥æ™‚','ç¨¼åƒãƒ•ãƒ©ã‚°', column_name, incoming_column, 
                        daily_consumption_column, zaiko_name]
        merged_df = merged_df[new_column_order]

        # å®Ÿè¡Œçµæœã®ç¢ºèª
        #st.dataframe(inventory_df_adjusted)
        #st.dataframe(merged_df)

        return inventory_df_adjusted, merged_df

    
    # ç¾åœ¨ã®åœ¨åº«æ•°ã‚’åˆæœŸå€¤ã¨ã—ã¦è¨­å®š
    if mode == "åœ¨åº«äºˆæ¸¬":
        current_inventory_hako = zaiko_extracted.iloc[0]['åœ¨åº«æ•°ï¼ˆç®±ï¼‰']
        current_inventory_buhin = zaiko_extracted.iloc[0]['ç¾åœ¨åœ¨åº«ï¼ˆå°ï¼‰']
    elif mode == "ãƒªãƒŸãƒƒãƒˆè¨ˆç®—":
        current_inventory_hako = selected_zaiko_hako
        current_inventory_buhin = selected_zaiko_buhin

    # ç®±æ›ç®—ã§è¨ˆç®—ã™ã‚‹
    daily_consumption_column = 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'
    max_daily_consumption_column = 'æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'
    min_baseline_column = 'è¨­è¨ˆå€¤MIN'
    max_baseline_column = 'è¨­è¨ˆå€¤MAX'
    unit_type = 'ç®±æ›ç®—'
    incoming_column = 'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'
    current_inventory_hako_or_buhin = current_inventory_hako
    inventory_df_adjusted_hako, merged_df_hako = calculate_inventory_adjustments(hourly_kanban_count_full, 
                                            filtered_tehai_data, kado_df, start_datetime_for_calc, 
                                            start_datetime_for_show, end_datetime_for_calc, 
                                            current_inventory_hako_or_buhin, out_parameter, column_name,incoming_column,
                                            daily_consumption_column, max_daily_consumption_column,
                                            min_baseline_column,max_baseline_column,unit_type)

    # st.write("ç®±çµæœã®ç¢ºèª")
    # st.dataframe(inventory_df_adjusted_hako)
    # st.dataframe(merged_df_hako)
    
    # éƒ¨å“æ›ç®—ã§è¨ˆç®—ã™ã‚‹
    filtered_tehai_data['è¨­è¨ˆå€¤MINï¼ˆéƒ¨å“æ•°ï¼‰'] = filtered_tehai_data['è¨­è¨ˆå€¤MIN']*filtered_tehai_data['åå®¹æ•°']
    filtered_tehai_data['è¨­è¨ˆå€¤MAXï¼ˆéƒ¨å“æ•°ï¼‰'] = filtered_tehai_data['è¨­è¨ˆå€¤MAX']*filtered_tehai_data['åå®¹æ•°']
    daily_consumption_column = 'æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“'
    max_daily_consumption_column = 'æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“'
    min_baseline_column = 'è¨­è¨ˆå€¤MINï¼ˆéƒ¨å“æ•°ï¼‰'
    max_baseline_column = 'è¨­è¨ˆå€¤MAXï¼ˆéƒ¨å“æ•°ï¼‰'
    unit_type = 'éƒ¨å“æ›ç®—'
    hourly_kanban_count_full = pd.merge(hourly_kanban_count_full, filtered_tehai_data[['æ—¥æ™‚','åå®¹æ•°']], on='æ—¥æ™‚', how='left')
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'] = hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°']*hourly_kanban_count_full['åå®¹æ•°']
    incoming_column = 'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'
    current_inventory_hako_or_buhin = current_inventory_buhin
    inventory_df_adjusted_buhin, merged_df_buhin = calculate_inventory_adjustments(hourly_kanban_count_full, 
                                            filtered_tehai_data, kado_df, start_datetime_for_calc, 
                                            start_datetime_for_show, end_datetime_for_calc, 
                                            current_inventory_hako_or_buhin, out_parameter, column_name,incoming_column,
                                            daily_consumption_column, max_daily_consumption_column,
                                            min_baseline_column,max_baseline_column,unit_type)

    
    # ç®±ï¼‹éƒ¨å“æ›ç®—ã§è¨ˆç®—ã™ã‚‹
    syuyosu_value = filtered_tehai_data[filtered_tehai_data['æ—¥æ™‚'] == start_datetime_for_calc]['åå®¹æ•°'].iloc[0]
    current_inventory_hako_or_buhin = current_inventory_hako*syuyosu_value + current_inventory_buhin
    inventory_df_adjusted_hako_and_buhin, merged_df_hako_and_buhin = calculate_inventory_adjustments(hourly_kanban_count_full, 
                                            filtered_tehai_data, kado_df, start_datetime_for_calc, 
                                            start_datetime_for_show, end_datetime_for_calc, 
                                            current_inventory_hako_or_buhin, out_parameter, column_name,incoming_column,
                                            daily_consumption_column, max_daily_consumption_column,
                                            min_baseline_column,max_baseline_column,unit_type)

    
    
    # st.write("éƒ¨å“çµæœã®ç¢ºèª")
    # st.dataframe(inventory_df_adjusted_buhin)
    # st.dataframe(merged_df_buhin)

    return inventory_df_adjusted_hako, merged_df_hako, inventory_df_adjusted_buhin, merged_df_buhin, inventory_df_adjusted_hako_and_buhin, merged_df_hako_and_buhin

# MARK: ã€æ–¹æ³•ï¼‘ã€‘ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«å¿…è¦ãªå¤‰æ•°ã‚’æº–å‚™ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†å…±é€šé–¢æ•°
#! ä»Šã¯åœ¨åº«ãƒªãƒŸãƒƒãƒˆå°‚ç”¨
def setup_and_run_simulation(
    hinban_info,
    kojo,
    flag_useDataBase,
    start_datetime_for_calc, # é–‹å§‹æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
    end_datetime_for_calc, # çµ‚äº†æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
    start_datetime_for_show,# çµæœã‚’è¦‹ã›ã‚‹é–‹å§‹æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
    target_column,
    mode,
    out_parameter,
    selected_zaiko_hako=None,
    selected_zaiko_buhin=None
):
    # # åœ¨åº«
    # # æ–‡å­—å‹ã«æˆ»ã™
    # #! 15åˆ†å˜ä½ãªã®ã§å¤‰æ›
    # start_datetime_for_zaiko = start_datetime_for_calc.replace(minute=0, second=0).strftime('%Y-%m-%d %H:%M:%S')
    # end_datetime_for_zaiko = start_datetime_for_calc.replace(minute=0, second=0).strftime('%Y-%m-%d %H:%M:%S')
    # # æŒ‡æ‘˜æœŸé–“ã§èª­ã¿è¾¼ã‚€
    # zaiko_df = compute_hourly_buhin_zaiko_data_by_hinban(hinban_info,
    #  start_datetime_for_zaiko, end_datetime_for_zaiko,flag_useDataBase, kojo)
    # # å¿…è¦ãªåˆ—ã®ã¿æŠ½å‡º
    # zaiko_extracted = zaiko_df[['æ—¥æ™‚', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰','ç¾åœ¨åœ¨åº«ï¼ˆå°ï¼‰']]
    # #! 15åˆ†å˜ä½ã®æ™‚åˆ»ã«ä¿®æ­£
    # zaiko_extracted.loc[zaiko_extracted.index[0], 'æ—¥æ™‚'] = start_datetime_for_calc
    # # å®Ÿè¡Œçµæœã®ç¢ºèª
    # #st.dataframe(zaiko_extracted)

    # # INæº–å‚™
    # #todo æ™‚é–“é…ã‚Œã‚ã‚‹ã‹ã‚‰å‰ã®æ™‚é–“ã‚’é–‹å§‹ã¨ã™ã‚‹
    # #todo æ›´æ–°æ—¥æ™‚ã§å–ã£ã¦ã„ã‚‹ã‹ã‚‰å¹…ã‚’è¦‹ã‚‹å¿…è¦ã‚ã‚‹
    # #! è¿‘ã„æ™‚åˆ»ã§æ›´æ–°ã•ã‚ŒãŸã‚‚ã®ã¯å¾Œã‚ã®æ™‚åˆ»ã§æ›´æ–°ã•ã‚Œã‚‹ã‹ã‚‰å‰å¾Œä¸¡æ–¹ã§è¦‹ã‚‹å¿…è¦ãŒã‚ã‚‹
    # start_datetime_for_input = start_datetime_for_calc - timedelta(hours=24*10)
    # end_datetime_for_input = end_datetime_for_calc + timedelta(hours=24*10)
    # # æ–‡å­—å‹ã«æˆ»ã™
    # start_datetime_for_input = start_datetime_for_input.strftime('%Y-%m-%d %H:%M:%S')
    # end_datetime_for_input = end_datetime_for_input.strftime('%Y-%m-%d %H:%M:%S')
    # # æŒ‡å®šæœŸé–“ã§èª­ã¿è¾¼ã‚€
    # time_granularity = '15min'
    # _ , hourly_kanban_count = compute_hourly_specific_checkpoint_kanbansu_data_by_hinban(hinban_info, target_column,
    #  start_datetime_for_input, end_datetime_for_input, time_granularity, flag_useDataBase, kojo)
    # # å®Ÿè¡Œçµæœã®ç¢ºèª
    # #st.dataframe(hourly_kanban_count)

    # # OUT
    # # æ–‡å­—å‹ã«æˆ»ã™
    # start_datetime_for_output = start_datetime_for_show.strftime('%Y-%m-%d %H:%M:%S')
    # end_datetime_for_output = end_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
    # #ã€€æŒ‡å®šæœŸé–“ã§èª­ã¿è¾¼ã‚€
    # time_granularity = '15min'
    # tehai_data = compute_hourly_tehai_data_by_hinban(hinban_info, start_datetime_for_output, end_datetime_for_output, time_granularity,
    #  flag_useDataBase, kojo)
    # tehai_data['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = tehai_data['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / (16.5*4)
    # tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / (16.5*4)
    # tehai_data['æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“'] = tehai_data['æ—¥é‡æ•°'] / (16.5*4)
    # tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“'] = tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°'] / (16.5*4)
    # # 'æ—¥ä»˜' ã¨ 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
    # filtered_tehai_data = tehai_data[['æ—¥æ™‚','åå®¹æ•°','æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“','æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“','æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“','æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“','ç´å…¥LT(H)','è¨­è¨ˆå€¤MIN','è¨­è¨ˆå€¤MAX']]
    # # å®Ÿè¡Œçµæœã®ç¢ºèª
    # #st.dataframe(filtered_tehai_data)

    # # ç¨¼åƒãƒ•ãƒ©ã‚°
    # # ç¨¼åƒãƒ•ãƒ©ã‚°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    # start_datetime_for_kado = start_datetime_for_show.strftime('%Y-%m-%d %H:%M:%S')
    # end_datetime_for_kado = end_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
    # kado_df = get_kado_schedule_from_172_20_113_185(start_datetime_for_kado, end_datetime_for_kado, day_col='è¨ˆç”»(æ˜¼)', night_col='è¨ˆç”»(å¤œ)',time_granularity='15min')
    # #st.dataframe(kado_df)

    #ã€€ä¸¦åˆ—å‡¦ç†ï¼ˆãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ï¼‰
    def run_parallel_processing(process_number, hinban_info, target_column,  start_datetime_for_calc, end_datetime_for_calc, flag_useDataBase, kojo):

        if process_number == 0:

            # åœ¨åº«
            # æ–‡å­—å‹ã«æˆ»ã™
            #! 15åˆ†å˜ä½ãªã®ã§å¤‰æ›
            start_datetime_for_zaiko = start_datetime_for_calc.replace(minute=0, second=0).strftime('%Y-%m-%d %H:%M:%S')
            end_datetime_for_zaiko = start_datetime_for_calc.replace(minute=0, second=0).strftime('%Y-%m-%d %H:%M:%S')
            # æŒ‡æ‘˜æœŸé–“ã§èª­ã¿è¾¼ã‚€
            zaiko_df = compute_hourly_buhin_zaiko_data_by_hinban(hinban_info,
            start_datetime_for_zaiko, end_datetime_for_zaiko,flag_useDataBase, kojo)
            # å¿…è¦ãªåˆ—ã®ã¿æŠ½å‡º
            zaiko_extracted = zaiko_df[['æ—¥æ™‚', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰','ç¾åœ¨åœ¨åº«ï¼ˆå°ï¼‰']]
            #! 15åˆ†å˜ä½ã®æ™‚åˆ»ã«ä¿®æ­£
            zaiko_extracted.loc[zaiko_extracted.index[0], 'æ—¥æ™‚'] = start_datetime_for_calc
            # å®Ÿè¡Œçµæœã®ç¢ºèª
            #st.dataframe(zaiko_extracted)

            # INæº–å‚™
            #todo æ™‚é–“é…ã‚Œã‚ã‚‹ã‹ã‚‰å‰ã®æ™‚é–“ã‚’é–‹å§‹ã¨ã™ã‚‹
            #todo æ›´æ–°æ—¥æ™‚ã§å–ã£ã¦ã„ã‚‹ã‹ã‚‰å¹…ã‚’è¦‹ã‚‹å¿…è¦ã‚ã‚‹
            #! è¿‘ã„æ™‚åˆ»ã§æ›´æ–°ã•ã‚ŒãŸã‚‚ã®ã¯å¾Œã‚ã®æ™‚åˆ»ã§æ›´æ–°ã•ã‚Œã‚‹ã‹ã‚‰å‰å¾Œä¸¡æ–¹ã§è¦‹ã‚‹å¿…è¦ãŒã‚ã‚‹
            start_datetime_for_input = start_datetime_for_calc - timedelta(hours=24*10)
            end_datetime_for_input = end_datetime_for_calc + timedelta(hours=24*10)
            # æ–‡å­—å‹ã«æˆ»ã™
            start_datetime_for_input = start_datetime_for_input.strftime('%Y-%m-%d %H:%M:%S')
            end_datetime_for_input = end_datetime_for_input.strftime('%Y-%m-%d %H:%M:%S')
            # æŒ‡å®šæœŸé–“ã§èª­ã¿è¾¼ã‚€
            time_granularity = '15min'
            _ , hourly_kanban_count = compute_hourly_specific_checkpoint_kanbansu_data_by_hinban(hinban_info, target_column,
            start_datetime_for_input, end_datetime_for_input, time_granularity, flag_useDataBase, kojo)
            # å®Ÿè¡Œçµæœã®ç¢ºèª
            #st.dataframe(hourly_kanban_count)

            return (zaiko_extracted, hourly_kanban_count)

        elif process_number == 1:

            # OUT
            # æ–‡å­—å‹ã«æˆ»ã™
            start_datetime_for_output = start_datetime_for_show.strftime('%Y-%m-%d %H:%M:%S')
            end_datetime_for_output = end_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
            #ã€€æŒ‡å®šæœŸé–“ã§èª­ã¿è¾¼ã‚€
            time_granularity = '15min'
            tehai_data = compute_hourly_tehai_data_by_hinban(hinban_info, start_datetime_for_output, end_datetime_for_output, time_granularity,
            flag_useDataBase, kojo)
            #st.dataframe(tehai_data)
            tehai_data['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = tehai_data['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / (16.5*4)
            tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / (16.5*4)
            tehai_data['æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“'] = tehai_data['æ—¥é‡æ•°'] / (16.5*4)
            tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“'] = tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°'] / (16.5*4)
            # 'æ—¥ä»˜' ã¨ 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
            filtered_tehai_data = tehai_data[['æ—¥æ™‚','åå®¹æ•°','æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“','æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“','æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“','æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“','ç´å…¥LT(H)','è¨­è¨ˆå€¤MIN','è¨­è¨ˆå€¤MAX']]
            # å®Ÿè¡Œçµæœã®ç¢ºèª
            #st.dataframe(filtered_tehai_data)

            return filtered_tehai_data

        elif process_number == 2: 

            # ç¨¼åƒãƒ•ãƒ©ã‚°
            # ç¨¼åƒãƒ•ãƒ©ã‚°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            start_datetime_for_kado = start_datetime_for_show.strftime('%Y-%m-%d %H:%M:%S')
            end_datetime_for_kado = end_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
            kado_df = get_kado_schedule_from_172_20_113_185(start_datetime_for_kado, end_datetime_for_kado, day_col='è¨ˆç”»(æ˜¼)', night_col='è¨ˆç”»(å¤œ)',time_granularity='15min')
            #st.dataframe(kado_df)

            return kado_df

    n_jobs = 3

    # # ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ
    # results_parallel = Parallel(n_jobs=n_jobs)(
    #     delayed(run_parallel_processing)(process_number, hinban_info, target_column,  start_datetime_for_calc, end_datetime_for_calc, flag_useDataBase, kojo) for process_number in range(3)
    # )

    # å‡¦ç†æ™‚é–“ãƒ†ã‚¹ãƒˆ
    # ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
    # start_time_parallel = time.time()
    # results_parallel = Parallel(n_jobs=n_jobs)(
    #     delayed(run_parallel_processing)(process_number, hinban_info, target_column, start_datetime_for_calc, end_datetime_for_calc, flag_useDataBase, kojo) for process_number in range(3)
    # )
    # parallel_time = time.time() - start_time_parallel

    # é€æ¬¡å‡¦ç†ãƒ†ã‚¹ãƒˆ
    start_time_sequential = time.time()
    results_sequential = [
        run_parallel_processing(i, hinban_info, target_column, start_datetime_for_calc, end_datetime_for_calc, flag_useDataBase, kojo) for i in range(3)
    ]
    sequential_time = time.time() - start_time_sequential
    results_parallel = results_sequential

    #print(f"ä¸¦åˆ—å‡¦ç†æ™‚é–“: {parallel_time:.2f}ç§’")
    #print(f"é€æ¬¡å‡¦ç†æ™‚é–“: {sequential_time:.2f}ç§’")
    #print(f"é€Ÿåº¦å‘ä¸Šç‡: {sequential_time/parallel_time:.2f}å€")

    zaiko_extracted, hourly_kanban_count = results_parallel[0]
    filtered_tehai_data = results_parallel[1]
    kado_df = results_parallel[2]

    # IN
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    past_hours = int(filtered_tehai_data['ç´å…¥LT(H)'].unique()[0])
    # å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°ã®è¨ˆç®—
    column_name = target_column + "ã®ã‹ã‚“ã°ã‚“æ•°"
    # â—‹æ™‚é–“å‰ã®ã‹ã‚“ã°ã‚“æ•°ã‚’è¿½åŠ ã™ã‚‹
    hourly_kanban_count_full = hourly_kanban_count.copy()
    if past_hours != 0:
        past_hours = past_hours*4#! ãƒªãƒŸãƒƒãƒˆè¨ˆç®—ã¯15åˆ†å˜ä½ã®ãŸã‚
        hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count[column_name].shift(past_hours)
    else:
        hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count[column_name]
    # æ¬ æå€¤ï¼ˆæœ€åˆã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®æ™‚é–“åˆ†ï¼‰ã‚’0ã§åŸ‹ã‚ã‚‹
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].fillna(0).astype(int)
    
    # åœ¨åº«äºˆæ¸¬
    inventory_df_adjusted_hako, merged_df_hako, inventory_df_adjusted_buhin, merged_df_buhin, inventory_df_adjusted_hako_and_buhin, merged_df_hako_and_buhin = run_simulation(
        zaiko_extracted,hourly_kanban_count_full,filtered_tehai_data,kado_df,
        start_datetime_for_calc,end_datetime_for_calc,start_datetime_for_show,
        column_name,mode,out_parameter,
        selected_zaiko_hako,selected_zaiko_buhin)
    
    return inventory_df_adjusted_hako, merged_df_hako, inventory_df_adjusted_buhin, merged_df_buhin, inventory_df_adjusted_hako_and_buhin, merged_df_hako_and_buhin
    
# MARK: ã€æ–¹æ³•ï¼’ã€‘ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«å¿…è¦ãªå¤‰æ•°ã‚’æº–å‚™ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†å…±é€šé–¢æ•°ï¼ˆå…¨å“ç•ªä¸€æ‹¬ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ï¼‰
# todo ä½•åº¦ã‚‚èª­ã¿è¾¼ã‚€ã¨è² è·ãŒå¤§ãããªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã®ã§
#! ä»Šã¯åœ¨åº«äºˆæ¸¬å°‚ç”¨ã§ä½¿ç”¨
@st.cache_data
def setup_and_run_simulation_fast(
    hinban_info,
    kojo,
    flag_useDataBase,
    start_datetime_for_calc, # é–‹å§‹æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
    end_datetime_for_calc, # çµ‚äº†æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
    start_datetime_for_show,# çµæœã‚’è¦‹ã›ã‚‹é–‹å§‹æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
    target_column,
    mode,
    out_parameter,
    selected_zaiko_hako = None,
    selected_zaiko_buhin = None
):

    #ã€€ä¸¦åˆ—å‡¦ç†ï¼ˆãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ï¼‰
    def run_parallel_processing(process_number, hinban_info, target_column,  start_datetime_for_calc, end_datetime_for_calc, flag_useDataBase, kojo):

        # å“ç•ªæƒ…å ±è¨­å®š
        hinban = hinban_info[0]
        seibishitsu = hinban_info[1]

        if process_number == 0:

            # åœ¨åº«ï¼ˆå…¨å“ç•ªï¼‰
            start_datetime_for_zaiko = start_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
            end_datetime_for_zaiko = start_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
            # æŒ‡å®šæœŸé–“ã§èª­ã¿è¾¼ã‚€
            zaiko_all_df = compute_hourly_buhin_zaiko_data_by_all_hinban(start_datetime_for_zaiko, end_datetime_for_zaiko, flag_useDataBase, kojo)
            #st.dataframe(zaiko_all_df)
            # å“ç•ªæŠ½å‡º
            zaiko_df = zaiko_all_df[(zaiko_all_df['å“ç•ª'] == hinban) & (zaiko_all_df['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] == seibishitsu)]
            #st.dataframe(zaiko_df)
            # å¿…è¦ãªåˆ—ã®ã¿æŠ½å‡º
            zaiko_extracted = zaiko_df[['æ—¥æ™‚', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰','ç¾åœ¨åœ¨åº«ï¼ˆå°ï¼‰']]

            # INæº–å‚™ï¼ˆå…¨å“ç•ªï¼‰
            #todo æ™‚é–“é…ã‚Œã‚ã‚‹ã‹ã‚‰å‰ã®æ™‚é–“ã‚’é–‹å§‹ã¨ã™ã‚‹
            #todo æ›´æ–°æ—¥æ™‚ã§å–ã£ã¦ã„ã‚‹ã‹ã‚‰å¹…ã‚’è¦‹ã‚‹å¿…è¦ã‚ã‚‹
            #! è¿‘ã„æ™‚åˆ»ã§æ›´æ–°ã•ã‚ŒãŸã‚‚ã®ã¯å¾Œã‚ã®æ™‚åˆ»ã§æ›´æ–°ã•ã‚Œã‚‹ã‹ã‚‰å‰å¾Œä¸¡æ–¹ã§è¦‹ã‚‹å¿…è¦ãŒã‚ã‚‹
            start_datetime_for_input = start_datetime_for_calc - timedelta(hours=24*10)
            end_datetime_for_input = end_datetime_for_calc + timedelta(hours=24*10)
            # æ–‡å­—å‹ã«æˆ»ã™
            start_datetime_for_input = start_datetime_for_input.strftime('%Y-%m-%d %H:%M:%S')
            end_datetime_for_input = end_datetime_for_input.strftime('%Y-%m-%d %H:%M:%S')
            # æŒ‡å®šæœŸé–“ã§èª­ã¿è¾¼ã‚€
            _, df_full = compute_hourly_specific_checkpoint_kanbansu_data_by_all_hinban(target_column, start_datetime_for_input, end_datetime_for_input, flag_useDataBase, kojo)
            #st.dataframe(df_full)
            # å“ç•ªæŠ½å‡º
            hourly_kanban_count = df_full[(df_full['å“ç•ª'] == hinban) & (df_full['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] == seibishitsu)]
            #st.dataframe(hourly_kanban_count)
            # å…¨ã¦ã®åˆ—ã®Noneã‚’0ã«ç½®æ›
            hourly_kanban_count = hourly_kanban_count.fillna(0)
            #st.dataframe(hourly_kanban_count)

            return (zaiko_extracted, hourly_kanban_count)

        elif process_number == 1:

            # OUT
            # æ–‡å­—å‹ã«æˆ»ã™
            start_datetime_for_output = start_datetime_for_show.strftime('%Y-%m-%d %H:%M:%S')
            end_datetime_for_output = end_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
            #ã€€æŒ‡å®šæœŸé–“ã§èª­ã¿è¾¼ã‚€
            time_granularity = 'h'
            tehai_data = compute_hourly_tehai_data_by_hinban(hinban_info, start_datetime_for_output, end_datetime_for_output, time_granularity,
            flag_useDataBase, kojo)
            tehai_data['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = tehai_data['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / 16.5
            tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / 16.5
            tehai_data['æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“'] = tehai_data['æ—¥é‡æ•°'] / 16.5
            tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“'] = tehai_data['æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°'] / 16.5
            # 'æ—¥ä»˜' ã¨ 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
            filtered_tehai_data = tehai_data[['æ—¥æ™‚','åå®¹æ•°','æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“','æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“','æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°/ç¨¼åƒæ™‚é–“','æœˆæœ«ã¾ã§ã®æœ€å¤§æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“','ç´å…¥LT(H)','è¨­è¨ˆå€¤MIN','è¨­è¨ˆå€¤MAX']]
            #st.dataframe(filtered_tehai_data)

            return filtered_tehai_data

        elif process_number == 2:

            # ç¨¼åƒãƒ•ãƒ©ã‚°
            # ç¨¼åƒãƒ•ãƒ©ã‚°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            start_datetime_for_kado = start_datetime_for_show.strftime('%Y-%m-%d %H:%M:%S')
            end_datetime_for_kado = end_datetime_for_calc.strftime('%Y-%m-%d %H:%M:%S')
            kado_df = get_kado_schedule_from_172_20_113_185(start_datetime_for_kado, end_datetime_for_kado, day_col='è¨ˆç”»(æ˜¼)', night_col='è¨ˆç”»(å¤œ)', time_granularity='h')
            #st.dataframe(kado_df)

            return kado_df

    n_jobs = 3

    # ä¸¦åˆ—å‡¦ç†ã®å®Ÿè¡Œ
    # results_parallel = Parallel(n_jobs=n_jobs)(
    #     delayed(run_parallel_processing)(process_number, hinban_info, target_column,  start_datetime_for_calc, end_datetime_for_calc, flag_useDataBase, kojo) for process_number in range(3)
    # )

    # é€æ¬¡å‡¦ç†ãƒ†ã‚¹ãƒˆ
    start_time_sequential = time.time()
    results_sequential = [
        run_parallel_processing(process_number, hinban_info, target_column,  start_datetime_for_calc, end_datetime_for_calc, flag_useDataBase, kojo) for process_number in range(3)
    ]
    sequential_time = time.time() - start_time_sequential
    results_parallel = results_sequential

    zaiko_extracted, hourly_kanban_count = results_parallel[0]
    filtered_tehai_data = results_parallel[1]
    kado_df = results_parallel[2]
    
    # IN
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    past_hours = int(filtered_tehai_data['ç´å…¥LT(H)'].unique()[0])
    # å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°ã®è¨ˆç®—
    column_name = target_column + "ã®ã‹ã‚“ã°ã‚“æ•°"
    # â—‹æ™‚é–“å‰ã®ã‹ã‚“ã°ã‚“æ•°ã‚’è¿½åŠ ã™ã‚‹
    hourly_kanban_count_full = hourly_kanban_count.copy()
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count[column_name].shift(past_hours)
    # æ¬ æå€¤ï¼ˆæœ€åˆã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®æ™‚é–“åˆ†ï¼‰ã‚’0ã§åŸ‹ã‚ã‚‹
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].fillna(0).astype(int)
    #
    if hourly_kanban_count_full is None or hourly_kanban_count_full.empty: 
        # æ—¥æ™‚ç¯„å›²ã®ä½œæˆï¼ˆ1æ™‚é–“é–“éš”ï¼‰
        date_range = pd.date_range(start=start_datetime_for_show, end=end_datetime_for_calc, freq='h')
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        hourly_kanban_count_full = pd.DataFrame({
            'æ—¥æ™‚': date_range,
            column_name: 0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§1ã‚’è¨­å®š
            'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°':0
        })
    
    # åœ¨åº«äºˆæ¸¬
    inventory_df_adjusted_hako, merged_df_hako, inventory_df_adjusted_buhin, merged_df_buhin, inventory_df_adjusted_hako_and_buhin, merged_df_hako_and_buhin = run_simulation(
        zaiko_extracted,hourly_kanban_count_full,filtered_tehai_data,kado_df,
        start_datetime_for_calc,end_datetime_for_calc,start_datetime_for_show,
        column_name,mode,out_parameter,
        selected_zaiko_hako,selected_zaiko_buhin)

    #st.dataframe(inventory_df_adjusted_hako)

    return inventory_df_adjusted_hako, merged_df_hako

# MARK: åœ¨åº«ãƒªãƒŸãƒƒãƒˆè¨ˆç®—ï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰
def compute_zaiko_limit(hinban_info, target_column, start_datetime, selected_zaiko_hako, selected_zaiko_buhin, out_parameter, kojo, flag_useDataBase):

    # æ™‚é–“è¨­å®š
    start_datetime = datetime.strptime(start_datetime, '%Y-%m-%d %H:%M:%S')
    start_datetime_for_calc = start_datetime
    end_datetime_for_calc = start_datetime + timedelta(hours=24)
    start_datetime_for_show = start_datetime - timedelta(hours=6)

    # åœ¨åº«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢ä¿‚
    calc_mode = "ãƒªãƒŸãƒƒãƒˆè¨ˆç®—"
    inventory_df_adjusted_hako, merged_df_hako, inventory_df_adjusted_buhin, merged_df_buhin, inventory_df_adjusted_hako_and_buhin, merged_df_hako_and_buhin = setup_and_run_simulation(
        hinban_info,
        kojo,
        flag_useDataBase,
        start_datetime_for_calc, # é–‹å§‹æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
        end_datetime_for_calc, # çµ‚äº†æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
        start_datetime_for_show,# çµæœã‚’è¦‹ã›ã‚‹é–‹å§‹æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
        target_column,
        calc_mode,
        out_parameter,
        selected_zaiko_hako = selected_zaiko_hako,
        selected_zaiko_buhin = selected_zaiko_buhin
    )

    #-------------------------------------------------------------ã“ã“ã‹ã‚‰æç”»ï¼ˆå°†æ¥çš„ã«ã¯åˆ†å‰²ã—ãŸã„ï¼‰

    # ã‚¿ãƒ–ã®ä½œæˆ
    tab1, tab2, tab3 = st.tabs(["ç®±æ›ç®—", "éƒ¨å“æ›ç®—", "ç®±ï¼‹éƒ¨å“æ›ç®—"])

    #st.dataframe(inventory_df_adjusted_hako)
    #st.dataframe(inventory_df_adjusted_buhin)

    with tab1:

        inventory_df_adjusted = inventory_df_adjusted_hako
        merged_df = merged_df_hako

        # æœ€åˆã®æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨ãã‚Œä»¥é™ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
        actual_data = inventory_df_adjusted.iloc[0:1]  # æœ€åˆã®1æ™‚é–“åˆ†ã¯å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
        forecast_data = inventory_df_adjusted.iloc[1:]  # ãã‚Œä»¥é™ã¯äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿

        # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
        fig = go.Figure()

        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’é’è‰²ã§æç”»
        fig.add_trace(go.Bar(
            x=actual_data['æ—¥æ™‚'], 
            y=actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
            name='å®Ÿç¸¾', 
            marker_color='blue', 
            opacity=0.3
        ))

        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã§è¿½åŠ æç”»
        fig.add_trace(go.Bar(
            x=forecast_data['æ—¥æ™‚'], 
            y=forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
            name='äºˆæ¸¬', 
            marker_color='orange', 
            opacity=0.3
        ))

        # xè»¸ã‚’1æ™‚é–“ã”ã¨ã«è¡¨ç¤ºã™ã‚‹è¨­å®š
        fig.update_layout(
            title='äºˆæ¸¬çµæœ',  # ã“ã“ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
            xaxis_title='æ—¥æ™‚',  # xè»¸ã‚¿ã‚¤ãƒˆãƒ«
            yaxis_title='åœ¨åº«æ•°ï¼ˆç®±ï¼‰',  # yè»¸ã‚¿ã‚¤ãƒˆãƒ«
            xaxis=dict(
                tickformat="%Y-%m-%d %H:%M",  # æ—¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®š
                dtick=3600000  # 1æ™‚é–“ã”ã¨ã«è¡¨ç¤º (3600000ãƒŸãƒªç§’ = 1æ™‚é–“)
            ),
            barmode='group'  # è¤‡æ•°ã®ãƒãƒ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        )

        # è¨­è¨ˆå€¤MINã‚’ç ´ç·šã§è¿½åŠ æç”»
        fig.add_trace(go.Scatter(
            x=inventory_df_adjusted['æ—¥æ™‚'],  # ã¾ãŸã¯ forecast_data['æ—¥æ™‚'] ã‚’ä½¿ç”¨
            y=inventory_df_adjusted['è¨­è¨ˆå€¤MIN'],  # è¨­è¨ˆå€¤MINã®å€¤ã‚’ç¹°ã‚Šè¿”ã—
            name='è¨­è¨ˆå€¤MIN',
            line=dict(
                color='orange',
                dash='dash'  # ç ´ç·šã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒ‡å®š
            )
        ))

        # è¨­è¨ˆå€¤MINã‚’ç ´ç·šã§è¿½åŠ æç”»
        fig.add_trace(go.Scatter(
            x=inventory_df_adjusted['æ—¥æ™‚'],  # ã¾ãŸã¯ forecast_data['æ—¥æ™‚'] ã‚’ä½¿ç”¨
            y=inventory_df_adjusted['è¨­è¨ˆå€¤MAX'],  # è¨­è¨ˆå€¤MINã®å€¤ã‚’ç¹°ã‚Šè¿”ã—
            name='è¨­è¨ˆå€¤MAX',
            line=dict(
                color='green',
                dash='dash'  # ç ´ç·šã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒ‡å®š
            )
        ))

        # ã‚°ãƒ©ãƒ•ã‚’Streamlitã§è¡¨ç¤º
        st.plotly_chart(fig)

        # æ–°ã—ã„åˆ—ã€Œå‚™è€ƒã€ã‚’è¿½åŠ ã—ã€start_timeã«åŸºã¥ã„ã¦ã€Œéå»ã€ã€Œæœªæ¥ã€ã¨è¡¨ç¤º
        merged_df['â€»æ³¨é‡ˆ                                                                               '] = merged_df['æ—¥æ™‚'].apply(
            lambda x: 'ã‚ãªãŸã¯ã“ã®æ™‚é–“ã‚’é¸æŠã—ã¾ã—ãŸ' if x == start_datetime else ('éå»' if x < start_datetime else 'æœªæ¥')
        )

        # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        def highlight_start_time(row):
            return ['background-color: yellow' if row['æ—¥æ™‚'] == start_datetime else '' for _ in row]
        
        st.code(f"ğŸ“ è¨ˆç®—å¼ï¼šæœªæ¥ã®åœ¨åº«æ•° = åœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

        # æ³¨é‡ˆã‚’è¿½åŠ ï¼ˆä¾‹ã¨ã—ã¦start_timeã‚’è¡¨ç¤ºï¼‰
        st.markdown(f"")
        st.markdown(f"")
        st.markdown(f"**ä¸‹ã®è¡¨ã§äºˆæ¸¬ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™ã€‚**")

        # æ¡ä»¶ã«è©²å½“ã™ã‚‹ï¼ˆéå»ã®åœ¨åº«æ•°ï¼‰è¡Œã®åœ¨åº«æ•°ã‚’ "-" ã«ã™ã‚‹
        merged_df.loc[
            (merged_df['æ—¥æ™‚'] >= start_datetime_for_show) & 
            (merged_df['æ—¥æ™‚'] < start_datetime), 
            'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'
        ] = "-"

        # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦è¡¨ç¤º
        st.dataframe(merged_df.style.apply(highlight_start_time, axis=1))

    with tab2:

        inventory_df_adjusted = inventory_df_adjusted_buhin
        merged_df = merged_df_buhin

        # æœ€åˆã®æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨ãã‚Œä»¥é™ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
        actual_data = inventory_df_adjusted.iloc[0:1]  # æœ€åˆã®1æ™‚é–“åˆ†ã¯å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
        forecast_data = inventory_df_adjusted.iloc[1:]  # ãã‚Œä»¥é™ã¯äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿

        # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
        fig = go.Figure()

        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’é’è‰²ã§æç”»
        fig.add_trace(go.Bar(
            x=actual_data['æ—¥æ™‚'], 
            y=actual_data['åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'], 
            name='å®Ÿç¸¾', 
            marker_color='blue', 
            opacity=0.3
        ))

        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã§è¿½åŠ æç”»
        fig.add_trace(go.Bar(
            x=forecast_data['æ—¥æ™‚'], 
            y=forecast_data['åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'], 
            name='äºˆæ¸¬', 
            marker_color='orange', 
            opacity=0.3
        ))

        # xè»¸ã‚’1æ™‚é–“ã”ã¨ã«è¡¨ç¤ºã™ã‚‹è¨­å®š
        fig.update_layout(
            title='äºˆæ¸¬çµæœ',  # ã“ã“ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
            xaxis_title='æ—¥æ™‚',  # xè»¸ã‚¿ã‚¤ãƒˆãƒ«
            yaxis_title='åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰',  # yè»¸ã‚¿ã‚¤ãƒˆãƒ«
            xaxis=dict(
                tickformat="%Y-%m-%d %H:%M",  # æ—¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®š
                dtick=3600000  # 1æ™‚é–“ã”ã¨ã«è¡¨ç¤º (3600000ãƒŸãƒªç§’ = 1æ™‚é–“)
            ),
            barmode='group'  # è¤‡æ•°ã®ãƒãƒ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        )

        # è¨­è¨ˆå€¤MINã‚’ç ´ç·šã§è¿½åŠ æç”»
        fig.add_trace(go.Scatter(
            x=inventory_df_adjusted['æ—¥æ™‚'],  # ã¾ãŸã¯ forecast_data['æ—¥æ™‚'] ã‚’ä½¿ç”¨
            y=inventory_df_adjusted['è¨­è¨ˆå€¤MIN'],  # è¨­è¨ˆå€¤MINã®å€¤ã‚’ç¹°ã‚Šè¿”ã—
            name='è¨­è¨ˆå€¤MIN',
            line=dict(
                color='orange',
                dash='dash'  # ç ´ç·šã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒ‡å®š
            )
        ))

        # è¨­è¨ˆå€¤MINã‚’ç ´ç·šã§è¿½åŠ æç”»
        fig.add_trace(go.Scatter(
            x=inventory_df_adjusted['æ—¥æ™‚'],  # ã¾ãŸã¯ forecast_data['æ—¥æ™‚'] ã‚’ä½¿ç”¨
            y=inventory_df_adjusted['è¨­è¨ˆå€¤MAX'],  # è¨­è¨ˆå€¤MINã®å€¤ã‚’ç¹°ã‚Šè¿”ã—
            name='è¨­è¨ˆå€¤MAX',
            line=dict(
                color='green',
                dash='dash'  # ç ´ç·šã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒ‡å®š
            )
        ))

        # ã‚°ãƒ©ãƒ•ã‚’Streamlitã§è¡¨ç¤º
        st.plotly_chart(fig)

        # æ–°ã—ã„åˆ—ã€Œå‚™è€ƒã€ã‚’è¿½åŠ ã—ã€start_timeã«åŸºã¥ã„ã¦ã€Œéå»ã€ã€Œæœªæ¥ã€ã¨è¡¨ç¤º
        merged_df['â€»æ³¨é‡ˆ                                                                               '] = merged_df['æ—¥æ™‚'].apply(
            lambda x: 'ã‚ãªãŸã¯ã“ã®æ™‚é–“ã‚’é¸æŠã—ã¾ã—ãŸ' if x == start_datetime else ('éå»' if x < start_datetime else 'æœªæ¥')
        )

        # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        def highlight_start_time(row):
            return ['background-color: yellow' if row['æ—¥æ™‚'] == start_datetime else '' for _ in row]
        
        st.code(f"ğŸ“ è¨ˆç®—å¼ï¼šæœªæ¥ã®åœ¨åº«æ•° = åœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

        # æ³¨é‡ˆã‚’è¿½åŠ ï¼ˆä¾‹ã¨ã—ã¦start_timeã‚’è¡¨ç¤ºï¼‰
        st.markdown(f"")
        st.markdown(f"")
        st.markdown(f"**ä¸‹ã®è¡¨ã§äºˆæ¸¬ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™ã€‚**")

        # æ¡ä»¶ã«è©²å½“ã™ã‚‹ï¼ˆéå»ã®åœ¨åº«æ•°ï¼‰è¡Œã®åœ¨åº«æ•°ã‚’ "-" ã«ã™ã‚‹
        merged_df.loc[
            (merged_df['æ—¥æ™‚'] >= start_datetime_for_show) & 
            (merged_df['æ—¥æ™‚'] < start_datetime), 
            'åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'
        ] = "-"

        # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦è¡¨ç¤º
        st.dataframe(merged_df.style.apply(highlight_start_time, axis=1))
    
    with tab3:
        
        inventory_df_adjusted = inventory_df_adjusted_hako_and_buhin
        merged_df = merged_df_hako_and_buhin

        # æœ€åˆã®æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨ãã‚Œä»¥é™ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
        actual_data = inventory_df_adjusted.iloc[0:1]  # æœ€åˆã®1æ™‚é–“åˆ†ã¯å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
        forecast_data = inventory_df_adjusted.iloc[1:]  # ãã‚Œä»¥é™ã¯äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿

        # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
        fig = go.Figure()

        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’é’è‰²ã§æç”»
        fig.add_trace(go.Bar(
            x=actual_data['æ—¥æ™‚'], 
            y=actual_data['åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'], 
            name='å®Ÿç¸¾', 
            marker_color='blue', 
            opacity=0.3
        ))

        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã§è¿½åŠ æç”»
        fig.add_trace(go.Bar(
            x=forecast_data['æ—¥æ™‚'], 
            y=forecast_data['åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'], 
            name='äºˆæ¸¬', 
            marker_color='orange', 
            opacity=0.3
        ))

        # xè»¸ã‚’1æ™‚é–“ã”ã¨ã«è¡¨ç¤ºã™ã‚‹è¨­å®š
        fig.update_layout(
            title='äºˆæ¸¬çµæœ',  # ã“ã“ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
            xaxis_title='æ—¥æ™‚',  # xè»¸ã‚¿ã‚¤ãƒˆãƒ«
            yaxis_title='åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰',  # yè»¸ã‚¿ã‚¤ãƒˆãƒ«
            xaxis=dict(
                tickformat="%Y-%m-%d %H:%M",  # æ—¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®š
                dtick=3600000  # 1æ™‚é–“ã”ã¨ã«è¡¨ç¤º (3600000ãƒŸãƒªç§’ = 1æ™‚é–“)
            ),
            barmode='group'  # è¤‡æ•°ã®ãƒãƒ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        )

        # è¨­è¨ˆå€¤MINã‚’ç ´ç·šã§è¿½åŠ æç”»
        fig.add_trace(go.Scatter(
            x=inventory_df_adjusted['æ—¥æ™‚'],  # ã¾ãŸã¯ forecast_data['æ—¥æ™‚'] ã‚’ä½¿ç”¨
            y=inventory_df_adjusted['è¨­è¨ˆå€¤MIN'],  # è¨­è¨ˆå€¤MINã®å€¤ã‚’ç¹°ã‚Šè¿”ã—
            name='è¨­è¨ˆå€¤MIN',
            line=dict(
                color='orange',
                dash='dash'  # ç ´ç·šã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒ‡å®š
            )
        ))

        # è¨­è¨ˆå€¤MINã‚’ç ´ç·šã§è¿½åŠ æç”»
        fig.add_trace(go.Scatter(
            x=inventory_df_adjusted['æ—¥æ™‚'],  # ã¾ãŸã¯ forecast_data['æ—¥æ™‚'] ã‚’ä½¿ç”¨
            y=inventory_df_adjusted['è¨­è¨ˆå€¤MAX'],  # è¨­è¨ˆå€¤MINã®å€¤ã‚’ç¹°ã‚Šè¿”ã—
            name='è¨­è¨ˆå€¤MAX',
            line=dict(
                color='green',
                dash='dash'  # ç ´ç·šã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒ‡å®š
            )
        ))

        # ã‚°ãƒ©ãƒ•ã‚’Streamlitã§è¡¨ç¤º
        st.plotly_chart(fig)

        # æ–°ã—ã„åˆ—ã€Œå‚™è€ƒã€ã‚’è¿½åŠ ã—ã€start_timeã«åŸºã¥ã„ã¦ã€Œéå»ã€ã€Œæœªæ¥ã€ã¨è¡¨ç¤º
        merged_df['â€»æ³¨é‡ˆ                                                                               '] = merged_df['æ—¥æ™‚'].apply(
            lambda x: 'ã‚ãªãŸã¯ã“ã®æ™‚é–“ã‚’é¸æŠã—ã¾ã—ãŸ' if x == start_datetime else ('éå»' if x < start_datetime else 'æœªæ¥')
        )

        # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        def highlight_start_time(row):
            return ['background-color: yellow' if row['æ—¥æ™‚'] == start_datetime else '' for _ in row]
        
        st.code(f"ğŸ“ è¨ˆç®—å¼ï¼šæœªæ¥ã®åœ¨åº«æ•° = åœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

        # æ³¨é‡ˆã‚’è¿½åŠ ï¼ˆä¾‹ã¨ã—ã¦start_timeã‚’è¡¨ç¤ºï¼‰
        st.markdown(f"")
        st.markdown(f"")
        st.markdown(f"**ä¸‹ã®è¡¨ã§äºˆæ¸¬ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™ã€‚**")

        # æ¡ä»¶ã«è©²å½“ã™ã‚‹ï¼ˆéå»ã®åœ¨åº«æ•°ï¼‰è¡Œã®åœ¨åº«æ•°ã‚’ "-" ã«ã™ã‚‹
        merged_df.loc[
            (merged_df['æ—¥æ™‚'] >= start_datetime_for_show) & 
            (merged_df['æ—¥æ™‚'] < start_datetime), 
            'åœ¨åº«æ•°ï¼ˆéƒ¨å“æ•°ï¼‰'
        ] = "-"

        # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦è¡¨ç¤º
        st.dataframe(merged_df.style.apply(highlight_start_time, axis=1))

    return 0

# MARKï¼šåœ¨åº«ãƒªãƒŸãƒƒãƒˆè¨ˆç®—è¡¨ç¤ºï¼ˆãƒ•ãƒ­ãƒ³ãƒˆï¼‰
def show_results_of_zaiko_limit(hinban_info, target_column, start_datetime, selected_zaiko_hako, selected_zaiko_buhin, out_parameter, kojo, flag_useDataBase):
    #st.write(kojo)
    start_time = time.time()
    # å“ç•ªæƒ…å ±
    #! 15åˆ†å˜ä½ã‚’0åˆ†ã«ç›´ã—ã¦
    flag_display = 1
    start_datetime = pd.to_datetime(start_datetime).replace(minute=0, second=0).strftime('%Y-%m-%d %H:%M:%S')
    get_hinban_info_detail(hinban_info, start_datetime, flag_display,flag_useDataBase, kojo)
    compute_zaiko_limit(hinban_info, target_column, start_datetime, selected_zaiko_hako, selected_zaiko_buhin, out_parameter, kojo, flag_useDataBase)
    resultstime = time.time() - start_time
    print(resultstime)

# MARK: åœ¨åº«äºˆæ¸¬ï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰
def compute_future_zaiko(target_column, start_datetime, run_mode, out_parameter, kojo, flag_useDataBase):

    # æ™‚é–“è¨­å®š
    start_datetime = datetime.strptime(start_datetime, '%Y-%m-%d %H:%M:%S')
    start_datetime_for_calc = start_datetime
    end_datetime_for_calc = start_datetime + timedelta(hours=24)
    start_datetime_for_show = start_datetime - timedelta(hours=6)

    #ã€€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå“ç•ª_æ•´å‚™å®¤ã®çµ„ã¿åˆã‚ã›ã‚’æŠ½å‡º
    # todo åŠå¹´ç­‰ã§è¦‹ã‚‹ã¨600å“ç•ªãã‚‰ã„ã‚ã‚‹
    # todo ç´å…¥ä¾¿ãŒNULLã«ãªã‚Šã‚¨ãƒ©ãƒ¼ã§ãŠã¡ã‚‹
    unique_hinbans = get_hinban_master()[:5]
    #st.write(unique_hinbans)

    # ç©ºã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    hinban_list = []
    data_list = []
    hinban_info = ["", ""]

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå“ç•ªã®çµ„ã¿åˆã‚ã›ã®æ•°ã ã‘å‡¦ç†ã‚’è¡Œã†
    for unique_hinban in unique_hinbans:

        # æœ€åˆã® _ ã§ 2 ã¤ã«åˆ†å‰²
        hinban_info[0], hinban_info[1] = unique_hinban.split("_", 1)
        #st.write(hinban_info[0], hinban_info[1])

        try:
            # åœ¨åº«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢ä¿‚
            #todo ä»•å…¥å…ˆãƒ€ã‚¤ãƒ¤ã¨ç´ã¥ã‹ãšã‚¨ãƒ©ãƒ¼å‡ºã‚‹
            mode = "åœ¨åº«äºˆæ¸¬"
            zaiko_actuals_and_forecast_df, merged_df = setup_and_run_simulation_fast(
                hinban_info,
                kojo,
                flag_useDataBase,
                start_datetime_for_calc, # é–‹å§‹æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
                end_datetime_for_calc, # çµ‚äº†æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
                start_datetime_for_show,# çµæœã‚’è¦‹ã›ã‚‹é–‹å§‹æ—¥æ™‚ï¼ˆdatetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰
                target_column,
                mode,
                out_parameter,
                selected_zaiko_hako=None,
                selected_zaiko_buhin=None
            )
            #st.dataframe(zaiko_actuals_and_forecast_df)
            #st.dataframe(merged_df)
        except Exception as e:
            # logger.error(f"Error processing hinban {unique_hinban}: {str(e)}")
            # logger.error(traceback.format_exc())  # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å‡ºåŠ›
            # st.write("test")
            continue

        #st.dataframe(zaiko_actuals_and_forecast_df)

        temp_df = zaiko_actuals_and_forecast_df

        # åˆ¤å®š
        temp_df["ä¸‹é™å‰²ã‚Œ"] = (temp_df["åœ¨åº«æ•°ï¼ˆç®±ï¼‰"] < temp_df["è¨­è¨ˆå€¤MIN"]).astype(int)
        temp_df["ä¸Šé™è¶Šãˆ"] = (temp_df["åœ¨åº«æ•°ï¼ˆç®±ï¼‰"] > temp_df["è¨­è¨ˆå€¤MAX"]).astype(int)
        temp_df["åœ¨åº«0"] = (temp_df["åœ¨åº«æ•°ï¼ˆç®±ï¼‰"] < 0).astype(int)

        # å„é …ç›®ã®åˆè¨ˆã‚’è¨ˆç®—
        total_lower_limit = temp_df["ä¸‹é™å‰²ã‚Œ"].sum()
        total_upper_exceed = temp_df["ä¸Šé™è¶Šãˆ"].sum()
        total_stock_zero = temp_df["åœ¨åº«0"].sum()

        # æ¡ä»¶åˆ†å²ã§OK/NGã«å¤‰æ›
        total_lower_limit = "NG" if total_lower_limit > 0 else "OK"
        total_upper_exceed = "NG" if total_upper_exceed > 0 else "OK"
        total_stock_zero = "NG" if total_stock_zero > 0 else "OK"

        # Matplotlibã§ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(temp_df["æ—¥æ™‚"], temp_df["åœ¨åº«æ•°ï¼ˆç®±ï¼‰"], label="åœ¨åº«æ•°ï¼ˆç®±ï¼‰", marker="o")
        ax.fill_between(temp_df["æ—¥æ™‚"],
         temp_df["è¨­è¨ˆå€¤MIN"], temp_df["è¨­è¨ˆå€¤MAX"], color="lightgray", alpha=0.5, label="è¨­è¨ˆå€¤ç¯„å›² (MIN-MAX)")
        #ã“ã‚Œã¯ã„ã‚‰ãªã„ã‹ã‚‚
        #ax.axhline(y=basedata_filtered["è¨­è¨ˆå€¤MIN"].iloc[0], color="blue", linestyle="--", label="è¨­è¨ˆå€¤MIN")
        #ax.axhline(y=basedata_filtered["è¨­è¨ˆå€¤MAX"].iloc[0], color="red", linestyle="--", label="è¨­è¨ˆå€¤MAX")

        # ---- ã‚°ãƒ©ãƒ•ã®è£…é£¾ ----
        ax.set_title("åœ¨åº«äºˆæ¸¬çµæœã¨è¨­è¨ˆå€¤ï¼ˆåŸºæº–ç·šï¼‰ã¨ã®æ¯”è¼ƒ", fontsize=14)
        ax.set_xlabel("æ—¥æ™‚", fontsize=12)
        ax.set_ylabel("åœ¨åº«æ•°ï¼ˆç®±ï¼‰", fontsize=12)
        ax.legend()
        ax.grid(True)
        plt.xticks(rotation=45)

        # æ—¥æ™‚åˆ—ã‚’datetimeå‹ã«å¤‰æ›
        temp_df['æ—¥æ™‚'] = pd.to_datetime(temp_df['æ—¥æ™‚'])

        # ä¸€ç•ªå¤ã„æ™‚åˆ»ã‚’åŸºæº–æ™‚åˆ»ï¼ˆç¾åœ¨æ™‚åˆ»ï¼‰ã¨ã™ã‚‹
        base_time = temp_df['æ—¥æ™‚'].min()

        # åŸºæº–æ™‚åˆ»ã‹ã‚‰ã®çµŒéæ™‚é–“ (æ™‚é–“å˜ä½) ã‚’è¨ˆç®—
        temp_df['çµŒéæ™‚é–“(æ™‚é–“)'] = (temp_df['æ—¥æ™‚'] - base_time).dt.total_seconds() / 3600

        # è¨­è¨ˆå€¤MINã‚’å‰²ã‚‹æœ€åˆã®æ™‚é–“
        time_min = temp_df.loc[temp_df['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] < temp_df['è¨­è¨ˆå€¤MIN'], 'çµŒéæ™‚é–“(æ™‚é–“)'].min()

        # è¨­è¨ˆå€¤MAXã‚’å‰²ã‚‹æœ€åˆã®æ™‚é–“
        time_max = temp_df.loc[temp_df['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] > temp_df['è¨­è¨ˆå€¤MAX'], 'çµŒéæ™‚é–“(æ™‚é–“)'].min()

        # åœ¨åº«ãŒ0ã‚ˆã‚Šå°ã•ããªã‚‹æœ€åˆã®æ™‚é–“
        time_zero = temp_df.loc[temp_df['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] < 0, 'çµŒéæ™‚é–“(æ™‚é–“)'].min()

        # ---- PNGãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ ----
        save_dir = "outputs/åœ¨åº«äºˆæ¸¬çµæœ"
        os.makedirs(save_dir, exist_ok=True)
        output_file = f"{save_dir}/{unique_hinban}.png"
        fig.savefig(output_file, format="png", dpi=300, bbox_inches="tight")

        flag_display = 0
        hinban_indo_detail_df = get_hinban_info_detail(hinban_info, start_datetime, flag_display,flag_useDataBase, kojo)

        # å¿…è¦ãƒ‡ãƒ¼ã‚¿ã ã‘æº–å‚™
        hinban_list.append(output_file)
        unique_hinmei = hinban_indo_detail_df['å“å'].iloc[0]
        unique_shiresaki = hinban_indo_detail_df['ä»•å…¥å…ˆå'].iloc[0]
        unique_shiresaki_kojo = hinban_indo_detail_df['ä»•å…¥å…ˆå·¥å ´å'].iloc[0]
        data_list.append({"å“ç•ª_æ•´å‚™å®¤": unique_hinban, "å“å": unique_hinmei,
                           "ä»•å…¥å…ˆå": unique_shiresaki, "ç™ºé€å·¥å ´å": unique_shiresaki_kojo,
                           "ä¸‹é™å‰²ã‚Œ":total_lower_limit,"ä¸Šé™è¶Šãˆ":total_upper_exceed,"æ¬ å“":total_stock_zero,
                           "ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“":time_min,"ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“":time_max,"æ¬ å“ã¾ã§ã®æ™‚é–“":time_zero})

    # ãƒ­ãƒ¼ã‚«ãƒ«ã® PNG ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
    def img_to_base64(file_path):
        with open(file_path, "rb") as f:
            data = f.read()
        # Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦æ–‡å­—åˆ—ã«å¤‰æ›
        return base64.b64encode(data).decode("utf-8")

    # DataFrame ã«å¤‰æ›
    df_A = pd.DataFrame(data_list)
    # ç”»åƒã‚’ Base64 å¤‰æ›
    base64_images = [img_to_base64(p) for p in hinban_list]
    # DataFrame ã«å¤‰æ›
    df_B = pd.DataFrame(base64_images, columns=["ç”»åƒbase64"])

    #edited_df = st.data_editor(df_A, num_rows="dynamic")

    # DataFrame ã‚’çµ±åˆï¼ˆæ¨ªæ–¹å‘ã«çµåˆï¼‰
    data = pd.concat([df_A, df_B], axis=1)

    df = pd.DataFrame(data)
    #st.dataframe(df)

    # dfãŒç©ºã£ã½ã ã¨ã‚¨ãƒ©ãƒ¼å‡ºã‚‹
    if len(df) != 0:

        #st.dataframe(df)

        #import csv

        st.divider()

        # æœ€å¾Œã®åˆ—ã‚’é™¤ã
        df_excluded_last = df.iloc[:, :-1]

        # 3ã¤ã®åˆ—ãã‚Œãã‚Œã«ã¤ã„ã¦ã€NGãªã‚‰1ã€OKãªã‚‰0ã«å¤‰æ›
        df_excluded_last['ä¸‹é™å‰²ã‚Œ'] = (df_excluded_last['ä¸‹é™å‰²ã‚Œ'] == 'NG').astype(int)
        df_excluded_last['ä¸Šé™è¶Šãˆ'] = (df_excluded_last['ä¸Šé™è¶Šãˆ'] == 'NG').astype(int)
        df_excluded_last['æ¬ å“'] = (df_excluded_last['æ¬ å“'] == 'NG').astype(int)

        # ä¾‹ï¼š'å“ç•ª'åˆ—ã‚’åˆ†å‰²ã™ã‚‹å ´åˆ
        df_excluded_last[['å“ç•ª', 'æ•´å‚™å®¤']] = df_excluded_last['å“ç•ª_æ•´å‚™å®¤'].str.split('_', expand=True)
        df_excluded_last['å®Ÿè¡Œæ—¥æ™‚'] = start_datetime

        df_excluded_last = df_excluded_last.drop('å“ç•ª_æ•´å‚™å®¤', axis=1)

        # CSVæ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆShift_JISã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰
        csv_data = df_excluded_last.to_csv(index=False, encoding='cp932')#, quoting=csv.QUOTE_ALL)

        # CSVã‚’ãƒã‚¤ãƒŠãƒªã«å¤‰æ› â†’ Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        b64_encoded = base64.b64encode(csv_data.encode('cp932')).decode()

        # data URI ã‚¹ã‚­ãƒ¼ãƒ ã®æ–‡å­—åˆ—ã‚’ä½œæˆ
        # Shift_JIS ã§è§£é‡ˆã•ã‚Œã‚‹ã‚ˆã† charset=shift_jis ã‚‚ä»˜ä¸
        csv_uri = f"data:text/csv;charset=shift_jis;base64,{b64_encoded}"

        # ã‚«ã‚¹ã‚¿ãƒ HTMLãƒœã‚¿ãƒ³ï¼ˆä¾‹ï¼‰
        custom_button = f"""
            <a download="åœ¨åº«äºˆæ¸¬çµæœ.csv" href="{csv_uri}">
                <button style="
                    background-color: #4CAF50;
                    border: none;
                    color: white;
                    padding: 12px 24px;
                    text-align: center;
                    text-decoration: none;
                    display: inline-block;
                    font-size: 16px;
                    border-radius: 8px;
                    cursor: pointer;
                ">
                ğŸ“¥ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
                </button>
            </a>
        """

        if run_mode == "æ‰‹å‹•å®Ÿè¡Œ":

            st.markdown(custom_button, unsafe_allow_html=True)

        def style_ok_ng(value):
            """OK/NGæ–‡å­—åˆ—ã‚’è‰²ä»˜ããƒãƒƒã‚¸HTMLã«å¤‰æ›"""
            if value == "OK":
                return """<span class="badge-ok">OK</span>"""
            elif value == "NG":
                return """<span class="badge-ng">NG</span>"""
            else:
                return str(value)

        #HTML çµ„ã¿ç«‹ã¦
        html_code = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>DataTables with Default Filters and Sorting</title>

            <!-- â–¼ DataTablesç”¨CSS (CDN) â–¼ -->
            <link rel="stylesheet" type="text/css"
                href="https://cdn.datatables.net/1.13.4/css/jquery.dataTables.css"/>
            <script type="text/javascript"
                    src="https://cdn.jsdelivr.net/npm/jquery@3.6.4/dist/jquery.min.js"></script>
            <script type="text/javascript"
                    src="https://cdn.datatables.net/1.13.4/js/jquery.dataTables.js"></script>

            <style>
            /* ãƒ†ãƒ¼ãƒ–ãƒ«ã®åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ« */
            table {
                width: 100%;
                border-collapse: collapse;
            }
            th, td {
                border: 1px solid #ccc;
                padding: 8px;
                text-align: center;
            }

            /* OK/NGãƒãƒƒã‚¸ã®ã‚¹ã‚¿ã‚¤ãƒ« */
            .badge-ok {
                display: inline-block;
                padding: 5px 10px;
                color: #fff;
                background-color: #00aaff;
                border-radius: 5px;
            }
            .badge-ng {
                display: inline-block;
                padding: 5px 10px;
                color: #fff;
                background-color: #ff4444;
                border-radius: 5px;
            }

            /* ãƒˆã‚°ãƒ«ãƒœã‚¿ãƒ³ */
            .toggle-button {
                padding: 8px 16px;
                font-size: 16px;
                background-color: #008CBA;
                color: white;
                border: none;
                border-radius: 6px;
                cursor: pointer;
            }
            .toggle-button:hover {
                background-color: #006F9A;
            }

            /* ãƒˆã‚°ãƒ«è¡¨ç¤ºéƒ¨åˆ†ï¼ˆç”»åƒï¼‰ã¯åˆæœŸéè¡¨ç¤º */
            .hidden-content {
                display: none;
                margin-top: 8px;
            }

            /* ã‚½ãƒ¼ãƒˆã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚¹ã‚¿ã‚¤ãƒ« */
            .filter-select {
                margin: 10px 0;
                padding: 6px 12px;
                font-size: 14px;
                border-radius: 4px;
                border: 1px solid #ccc;
            }
            </style>

            <script>
            $(document).ready(function() {
                // DataTables ã®åˆæœŸåŒ–
                var table = $('#myTable').DataTable({
                    paging: true,
                    searching: true,
                    ordering: true,
                    pageLength: 10,
                    lengthMenu: [10, 20, 30],
                    order: [[5, 'asc']],  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã€Œæ¬ å“ã¾ã§ã®æ™‚é–“ã€ã‚’é™é †ã«ã‚½ãƒ¼ãƒˆ
                    columnDefs: [
                        {
                            targets: [7, 9, 5], // æ•°å€¤åˆ—ï¼ˆä¸‹é™å‰²ã‚Œã€ä¸Šé™è¶Šãˆã€æ¬ å“ã¾ã§ã®æ™‚é–“ï¼‰
                            render: function(data, type, row) {
                                if (type === 'sort' || type === 'type') {
                                    // NaN ã‚’ -Infinity ã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆå¯èƒ½ã«
                                    return data === null || data === '' ? Infinity : parseFloat(data);
                                }
                                return data; // è¡¨ç¤ºæ™‚ã¯ãã®ã¾ã¾
                            }
                        }
                    ]
                });

                // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
                table.column(4).search('NG').draw();  // æ¬ å“åˆ—ã‚’ NG ã§ãƒ•ã‚£ãƒ«ã‚¿
                table.column(6).search('NG').draw();  // ä¸‹é™å‰²ã‚Œåˆ—ã‚’ NG ã§ãƒ•ã‚£ãƒ«ã‚¿
                table.column(8).search('').draw();   // ä¸Šé™è¶Šãˆåˆ—ã¯ãƒ•ã‚£ãƒ«ã‚¿ãªã—ï¼ˆã™ã¹ã¦ï¼‰

                // åˆ—å˜ä½ãƒ•ã‚£ãƒ«ã‚¿ã®å‡¦ç†
                function doFilter() {
                    var valKekin = $('#filter_kekin').val();
                    var valKagen = $('#filter_kagen').val();
                    var valJougen = $('#filter_jougen').val();
                    table.column(4).search(valKekin).draw();
                    table.column(6).search(valKagen).draw();
                    table.column(8).search(valJougen).draw();
                }

                // ãƒ•ã‚£ãƒ«ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ doFilter ã‚’å®Ÿè¡Œ
                $('#filter_kekin').on('change', doFilter);
                $('#filter_kagen').on('change', doFilter);
                $('#filter_jougen').on('change', doFilter);

                // ã‚½ãƒ¼ãƒˆæ¡ä»¶ã®å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆ
                $('#sort-order').on('change', function() {
                    var columnIndex = $(this).val();  // ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®å€¤ã‚’å–å¾—
                    table.order([columnIndex, 'asc']).draw();  // æŒ‡å®šåˆ—ã§é™é †ã‚½ãƒ¼ãƒˆ
                });
            });

            // ãƒˆã‚°ãƒ«æ©Ÿèƒ½ã®å®Ÿè£…
            function toggleImage(id) {
                var elem = document.getElementById(id);
                if (elem.style.display === 'none' || elem.style.display === '') {
                    elem.style.display = 'block';
                } else {
                    elem.style.display = 'none';
                }
            }
            </script>
        </head>
        <body>
            <!-- â–¼ åˆ—å˜ä½ãƒ•ã‚£ãƒ«ã‚¿UI: æ¬ å“, ä¸‹é™å‰²ã‚Œ, ä¸Šé™è¶Šãˆ â–¼ -->
            <div class="filter-boxes">
                <label>æ¬ å“:
                    <select id="filter_kekin" class="filter-select">
                        <option value="">(ã™ã¹ã¦)</option>
                        <option value="OK">OKã®ã¿</option>
                        <option value="NG" selected>NGã®ã¿</option>
                    </select>
                </label>

                <label>ä¸‹é™å‰²ã‚Œ:
                    <select id="filter_kagen" class="filter-select">
                        <option value="">(ã™ã¹ã¦)</option>
                        <option value="OK">OKã®ã¿</option>
                        <option value="NG" selected>NGã®ã¿</option>
                    </select>
                </label>

                <label>ä¸Šé™è¶Šãˆ:
                    <select id="filter_jougen" class="filter-select">
                        <option value="" selected>(ã™ã¹ã¦)</option>
                        <option value="OK">OKã®ã¿</option>
                        <option value="NG">NGã®ã¿</option>
                    </select>
                </label>
            </div>

            <!-- â–¼ ã‚½ãƒ¼ãƒˆç”¨ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’è¿½åŠ  -->
            <div>
                <label for="sort-order">ä¸¦ã³æ›¿ãˆæ¡ä»¶:</label>
                <select id="sort-order" class="filter-select">
                    <option value="6">ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“ï¼ˆå¤§ãã„é †ï¼‰</option>
                    <option value="8">ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“ï¼ˆå¤§ãã„é †ï¼‰</option>
                    <option value="4" selected>æ¬ å“ã¾ã§ã®æ™‚é–“ï¼ˆå¤§ãã„é †ï¼‰</option>
                </select>
            </div>

            <!-- â–¼ DataTables å¯¾å¿œãƒ†ãƒ¼ãƒ–ãƒ« -->
            <table id="myTable" class="display">
                <thead>
                    <tr>
                        <th>å“ç•ª_æ•´å‚™å®¤</th>
                        <th>å“å</th>
                        <th>ä»•å…¥å…ˆå</th>
                        <th>ä»•å…¥å…ˆå·¥å ´å</th>
                        <th>æ¬ å“</th>
                        <th>æ¬ å“ã¾ã§ã®æ™‚é–“</th>
                        <th>ä¸‹é™å‰²ã‚Œ</th>
                        <th>ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“</th>
                        <th>ä¸Šé™è¶Šãˆ</th>
                        <th>ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“</th>
                        <th>ã‚°ãƒ©ãƒ•</th>
                    </tr>
                </thead>
                <tbody>
        """

        # DataFrame ã®è¡Œã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦ HTML ã«å¤‰æ›
        # for i, row in df.iterrows():
        #     html_code += f"""
        #     <tr>
        #         <td>{row['å“ç•ª_æ•´å‚™å®¤']}</td>
        #         <td>{row['å“å']}</td>
        #         <td>{row['ä»•å…¥å…ˆå']}</td>
        #         <td>{row['ç™ºé€å·¥å ´å']}</td>
        #         <td>{row['ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“']}</td>
        #         <td>{row['ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“']}</td>
        #         <td>{row['æ¬ å“ã¾ã§ã®æ™‚é–“']}</td>
        #         <td>{style_ok_ng(row['æ¬ å“'])}</td>
        #         <td>{style_ok_ng(row['ä¸‹é™å‰²ã‚Œ'])}</td>
        #         <td>{style_ok_ng(row['ä¸Šé™è¶Šãˆ'])}</td>
        #         <td>
        #             <button class="toggle-button" onclick="toggleImage('hidden-content-{i}')">è¡¨ç¤º</button>
        #             <div id="hidden-content-{i}" class="hidden-content">
        #                 <img src="data:image/png;base64,{row['ç”»åƒbase64']}" style="max-width: 200px;">
        #             </div>
        #         </td>
        #     </tr>
        #     """
        for i, row in df.iterrows():
            html_code += f"""
            <tr>
                <td>{row['å“ç•ª_æ•´å‚™å®¤']}</td>
                <td>{row['å“å']}</td>
                <td>{row['ä»•å…¥å…ˆå']}</td>
                <td>{row['ç™ºé€å·¥å ´å']}</td>
                <td>{style_ok_ng(row['æ¬ å“'])}</td>
                <td>{row['æ¬ å“ã¾ã§ã®æ™‚é–“']}</td>
                <td>{style_ok_ng(row['ä¸‹é™å‰²ã‚Œ'])}</td>
                <td>{row['ä¸‹é™å‰²ã‚Œã¾ã§ã®æ™‚é–“']}</td>
                <td>{style_ok_ng(row['ä¸Šé™è¶Šãˆ'])}</td>
                <td>{row['ä¸Šé™è¶Šãˆã¾ã§ã®æ™‚é–“']}</td>
                <td>
                    <button class="toggle-button" onclick="toggleImage('hidden-content-{i}')">è¡¨ç¤º</button>
                    <div id="hidden-content-{i}" class="hidden-content">
                        <img src="data:image/png;base64,{row['ç”»åƒbase64']}" style="max-width: 200px;">
                    </div>
                </td>
            </tr>
            """

        html_code += """
                </tbody>
            </table>
        </body>
        </html>
        """

        if run_mode == "æ‰‹å‹•å®Ÿè¡Œ":

            # 4) Streamlit ã§è¡¨ç¤º
            st.components.v1.html(html_code, height=1000, scrolling=True)

        #st.dataframe(df)

    else:
        st.write("ã™ã¹ã¦ã®å“ç•ªã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚é¸æŠã—ãŸæ—¥æ™‚ã®ãƒ‡ãƒ¼ã‚¿ã¯å­˜åœ¨ã—ã¾ã›ã‚“")
        df_excluded_last = 0

    return df_excluded_last

# MARK: åœ¨åº«äºˆæ¸¬è¡¨ç¤ºï¼ˆãƒ•ãƒ­ãƒ³ãƒˆï¼‰
def show_results_of_future_zaiko(target_column,  start_datetime, run_mode, out_parameter, kojo, flag_useDataBase):
    compute_future_zaiko(target_column,  start_datetime, run_mode, out_parameter, kojo, flag_useDataBase)

# MARK: å˜ç‹¬ãƒ†ã‚¹ãƒˆç”¨
if __name__ == "__main__":

    kojo = 'anjo1'
    hinban_info = ['3559850A010', '1Y']
    start_datetime = '2025-02-01 00:00:00'
    end_datetime = '2025-03-12 09:00:00'
    target_column = 'ç´å…¥äºˆå®šæ—¥æ™‚'
    flag_useDataBase = 1
    selected_zaiko = 10

    # åœ¨åº«ãƒªãƒŸãƒƒãƒˆè¨ˆç®—
    out_parameter = "æ—¥é‡ã‚’æ¡ç”¨ã™ã‚‹"
    #df = compute_zaiko_limit(hinban_info, target_column, start_datetime, selected_zaiko, out_parameter, kojo, flag_useDataBase)
    #print(df)

    # åœ¨åº«äºˆæ¸¬
    out_parameter = "æ—¥é‡ã‚’æ¡ç”¨ã™ã‚‹"
    run_mode = "æ‰‹å‹•å®Ÿè¡Œ"
    df = compute_future_zaiko(target_column, start_datetime, run_mode, out_parameter, kojo, flag_useDataBase)
    #print(df)