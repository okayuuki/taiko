#åˆ†æç”¨

#! ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®import
import os
import pandas as pd
import warnings
import numpy as np
import pandas as pd
#%matplotlib inline#Jupyter Notebook å°‚ç”¨ã®ãƒã‚¸ãƒƒã‚¯ã‚³ãƒãƒ³ãƒ‰ã€‚ãƒ¡ãƒ³ãƒ†ç”¨ã§åˆ©ç”¨
import matplotlib.pyplot as plt
import shap
import seaborn as sns
import matplotlib as mpl
import re
from dateutil.relativedelta import relativedelta
from IPython.display import display, clear_output
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from matplotlib.gridspec import GridSpec
from datetime import datetime
from datetime import timedelta
from PIL import Image
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, max_error, mean_absolute_error
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, date, time
import pickle
from sklearn.preprocessing import StandardScaler

#! è‡ªä½œãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®import
#ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Šç”¨
#from main_v3 import create_hinban_info
from read_v3 import read_data, process_Activedata, read_activedata_from_IBMDB2, read_zaiko_by_using_archive_data
#ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ç”¨
from functions_v3 import display_message,display_corr_matrix, calculate_hourly_counts,calculate_business_time_base,calculate_business_time_order, \
    calculate_business_time_reception,calculate_median_lt,find_best_lag_range,create_lagged_features,add_part_supplier_info, \
        find_columns_with_word_in_name,calculate_elapsed_time_since_last_dispatch, \
            calculate_window_width,process_shiresakibin_flag,feature_engineering, \
                plot_inventory_graph, display_shap_contributions,plot_inventory_graph2

#! ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã®å¤‰æ›´ï¼ˆæ—¥æœ¬èªå¯¾å¿œã®ãŸã‚ï¼‰
mpl.rcParams['font.family'] = 'MS Gothic'

#! ã‚¹ãƒ†ãƒƒãƒ—ï¼ã®å‡¦ç†ã€ä¸‹é™å‰²ã‚Œorä¸Šé™è¶Šãˆå“ç•ªã®è¡¨ç¤º
def show_abnormal( selected_date, selected_time):

    #! é€£ç¶šæ™‚é–“ã‚’è¨ˆç®—
    def calculate_max_consecutive_time(selected_datetime, data, time_column, flag_column, group_columns):
        """
        å“ç•ªã¨å—å…¥å ´æ‰€ã”ã¨ã®æœ€å¤§é€£ç¶šæ™‚é–“ã¨å¯¾è±¡æ™‚é–“ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã€‚

        Parameters:
            data (pd.DataFrame): å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
            time_column (str): æ—¥æ™‚ã‚’ç¤ºã™åˆ—åã€‚
            flag_column (str): ç•°å¸¸ã‚’ç¤ºã™ãƒ•ãƒ©ã‚°åˆ—åã€‚
            group_columns (list): ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã®åŸºæº–ã¨ãªã‚‹åˆ—åï¼ˆä¾‹: å“ç•ª, å—å…¥å ´æ‰€ï¼‰ã€‚

        Returns:
            pd.DataFrame: æœ€å¤§é€£ç¶šæ™‚é–“ã¨å¯¾è±¡æ™‚é–“ã‚’å«ã‚€çµæœãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
        """
        results = []

        for group_keys, group in data.groupby(group_columns):
            group = group.sort_values(by=time_column)  # æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆ
            group['é€£ç¶šãƒ•ãƒ©ã‚°'] = (group[flag_column] != group[flag_column].shift()).cumsum()
            max_consecutive_time = 0
            max_time_range = ""
            going = ""

            # ä¸‹é™å‰²ã‚Œã€ä¸Šé™è¶Šãˆã—ã¦ã„ã‚‹åŒºé–“
            for _, sub_group in group[group[flag_column] == 1].groupby('é€£ç¶šãƒ•ãƒ©ã‚°'):
                # é€£ç¶šã™ã‚‹åŒºé–“ã®é–‹å§‹ã¨çµ‚äº†ã‚’å–å¾—ã—ã€æ™‚é–“å·®ã‚’è¨ˆç®—
                start_time = sub_group[time_column].min()
                end_time = sub_group[time_column].max()
                consecutive_time = (end_time - start_time).total_seconds() / 3600

                if consecutive_time > max_consecutive_time:
                    max_consecutive_time = consecutive_time
                    max_time_range = f"{start_time} ~ {end_time}"
                    if end_time == selected_datetime:
                        going = "é€²è¡Œä¸­"
                    else:
                        going = "è§£æ¶ˆæ¸ˆ"

            # çµæœã‚’ãƒªã‚¹ãƒˆã«ä¿å­˜
            # result = {col: val for col, val in zip(group_columns, group_keys)}
            # result['å“ç•ª'] = "_".join(map(str, group_keys))
            # result['é€£ç¶šæ™‚é–“ï¼ˆhï¼‰'] = int(max_consecutive_time)
            # result['å¯¾è±¡æ™‚é–“'] = max_time_range
            result = {
                'å“ç•ª':"_".join(map(str, group_keys)),
                'é€£ç¶šæ™‚é–“ï¼ˆhï¼‰' : int(max_consecutive_time),
                'å¯¾è±¡æ™‚é–“': max_time_range,
                'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹':going,
            }
            results.append(result)

        # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–ã—ã¦é™é †ã«ã‚½ãƒ¼ãƒˆ
        results_df = pd.DataFrame(results).sort_values(by='é€£ç¶šæ™‚é–“ï¼ˆhï¼‰', ascending=False)
        return results_df
    
    #! ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
    def create_abnormal_hinban_ranking(df_min: pd.DataFrame, df_max: pd.DataFrame):

        """
        2ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤ºã—ã€è¤‡æ•°è¡ŒãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒãƒ¼ã§é–²è¦§ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹

        Parameters
        ----------
        df_min : pd.DataFrame
            1ã¤ç›®ï¼ˆä¸‹é™ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        df_max : pd.DataFrame
            2ã¤ç›®ï¼ˆä¸Šé™ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """

        # é †ä½åˆ—ã‚’è¿½åŠ ï¼ˆ1ã‹ã‚‰å§‹ã¾ã‚‹é€£ç•ªï¼‰
        df_min["å±é™ºé †ä½"] = range(1, len(df_min) + 1)
        df_max["å±é™ºé †ä½"] = range(1, len(df_max) + 1)

        # é †ä½åˆ—ã‚’ä¸€ç•ªå·¦ã«ç§»å‹•
        columns = ["å±é™ºé †ä½"] + [col for col in df_min.columns if col != "å±é™ºé †ä½"]
        df_min = df_min[columns]
        columns = ["å±é™ºé †ä½"] + [col for col in df_max.columns if col != "å±é™ºé †ä½"]
        df_max = df_max[columns]

        # ãƒ†ãƒ¼ãƒ–ãƒ«HTMLéƒ¨åˆ†
        df_min_html = df_min.to_html(index=False, classes="my-table", table_id="table1")
        df_max_html = df_max.to_html(index=False, classes="my-table", table_id="table2")

        # æ¡ä»¶ã‚’å¤‰æ•°ã§æŒ‡å®š
        column_name = "é€£ç¶šæ™‚é–“ï¼ˆhï¼‰"
        low_threshold = 3
        high_threshold = 8
        max_threshold = 9

        # CSSéƒ¨åˆ†
        custom_css = """
        <style>
        .parent-container {
            display: flex;
            gap: 20px;
        }
        .table-container {
            flex: 1; 
            max-height: 500px;
            overflow-y: auto;
            border: 0px solid #ccc; /* æ ç·š */
            padding: 8px;
            box-sizing: border-box;
        }
        table.my-table {
            border-collapse: collapse;
            width: 100%;
        }
        table.my-table th, table.my-table td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        #table1 th {
            background-color: #9BD8FF; /* ãƒ†ãƒ¼ãƒ–ãƒ«1ã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆè–„ã„é’ï¼‰ */
            color: #000; /* ãƒ˜ãƒƒãƒ€ãƒ¼ã®æ–‡å­—è‰²ï¼ˆé»’ï¼‰ */
        }

        #table2 th {
            background-color: #FFB99B; /* ãƒ†ãƒ¼ãƒ–ãƒ«2ã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆè–„ã„èµ¤ï¼‰ */
            color: #000; /* ãƒ˜ãƒƒãƒ€ãƒ¼ã®æ–‡å­—è‰²ï¼ˆé»’ï¼‰ */
        }
        .table-container h3 {
            font-size: 30px;/* è¡¨ã‚¿ã‚¤ãƒˆãƒ«ã®æ–‡å­—ã‚µã‚¤ã‚º */
        }
        </style>
        """

        # JavaScriptï¼ˆåˆ—å & é–¾å€¤å¼•æ•°å¯¾å¿œï¼‰
        # highlightRedIfOver(ãƒ†ãƒ¼ãƒ–ãƒ«ID, åˆ—å, é–¾å€¤) ã‚’å®šç¾©
        script = f"""
                <script>
                function highlightByValueRange(tableId, colName, lowThreshold, highThreshold, maxThreshold) {{
                    const table = document.getElementById(tableId);
                    if (!table) return;

                    // ãƒ˜ãƒƒãƒ€è¡Œã® <th> ã‚’èµ°æŸ»ã—ã¦ã€è©²å½“åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹
                    const headerCells = table.getElementsByTagName('th');
                    let colIndex = -1;
                    for (let i = 0; i < headerCells.length; i++) {{
                        if (headerCells[i].innerText.trim() === colName) {{
                            colIndex = i;
                            break;
                        }}
                    }}
                    // è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚‰ä½•ã‚‚ã—ãªã„
                    if (colIndex === -1) return;

                    // ãƒ‡ãƒ¼ã‚¿è¡Œã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦æ¡ä»¶ã«å¿œã˜ãŸè‰²ã‚’è¨­å®š
                    const rows = table.getElementsByTagName('tr');
                    for (let r = 1; r < rows.length; r++) {{
                        const cells = rows[r].getElementsByTagName('td');
                        if (!cells[colIndex]) continue;

                        // æ•°å€¤ã«ãƒ‘ãƒ¼ã‚¹ã—ã¦æ¯”è¼ƒ
                        let val = parseFloat(cells[colIndex].innerText);
                        if (!isNaN(val)) {{
                            if (val >= lowThreshold && val <= highThreshold) {{
                                cells[colIndex].style.color = 'orange';
                            }} else if (val >= maxThreshold) {{
                                cells[colIndex].style.color = 'red';
                            }}
                        }}
                    }}
                }}

                // ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦èª­ã¿è¾¼ã¿æ™‚ã«å®Ÿè¡Œ
                window.onload = function() {{
                    highlightByValueRange('table1', '{column_name}', {low_threshold}, {high_threshold}, {max_threshold});
                    highlightByValueRange('table2', '{column_name}', {low_threshold}, {high_threshold}, {max_threshold});
                }};
                </script>
        """

        # HTMLå…¨ä½“
        combined_html = f"""
        <div class="parent-container">
            <div class="table-container">
                <h3>ğŸ“‰ ä¸‹é™å‰²ã‚Œå“ç•ªãƒªã‚¹ãƒˆ</h3>
                {df_min_html}
            </div>
            <div class="table-container">
                <h3>ğŸ“ˆ ä¸Šé™è¶Šãˆå“ç•ªãƒªã‚¹ãƒˆ</h3>
                {df_max_html}
            </div>
        </div>
        {script}
        """

        # ä¸Šã§å®šç¾©ã—ãŸCSS + HTMLã‚’1ã¤ã«ã¾ã¨ã‚ã‚‹
        html_content = custom_css + combined_html

        # st.components.v1.htmlã‚’ä½¿ã£ã¦HTML+JSã‚’åŸ‹ã‚è¾¼ã‚€
        # ãªãœï¼Ÿ
        # Streamlitã®st.markdownã‚„st.writeã§HTMLæ–‡å­—åˆ—ã‚’åŸ‹ã‚è¾¼ã‚€å ´åˆã€unsafe_allow_html=Trueã‚’æŒ‡å®šã—ã¦ã‚‚ã€
        # JavaScriptã‚¿ã‚°ï¼ˆ<script>ï¼‰ã¯ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã•ã‚Œã¦å®Ÿè¡Œã•ã‚Œãªã„ãŸã‚ã€è‰²å¤‰æ›´å‡¦ç†ã®éƒ¨åˆ†ãŒå‹•ä½œã—ãªã„ã‹ã‚‰
        # Streamlit ãŒç”¨æ„ã—ã¦ã„ã‚‹ st.components.v1.html ã‚’ä½¿ã†ã¨ã€HTMLï¼‹JavaScriptã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œã§ãã‚‹
        st.components.v1.html(html_content, height=500)

    #! æ—¥ä»˜ï¼ˆYYYYMMDDï¼‰ã¨æ™‚é–“ï¼ˆHHï¼‰ã‚’çµ±åˆã—ã¦æ—¥æ™‚å¤‰æ•°ã‚’ä½œæˆ
    selected_datetime = datetime.combine(selected_date, datetime.strptime(selected_time, "%H:%M").time())
    # å®Ÿè¡Œçµæœã®è¡¨ç¤º
    st.sidebar.code(f"æ–°ãŸã«é¸æŠã•ã‚ŒãŸæ—¥æ™‚: {selected_datetime}")

    #! ã‚¹ãƒ†ãƒƒãƒ—0ã®ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
    st.header("ç•°å¸¸å“ç•ªãƒªã‚¹ãƒˆ")

    #! å‡¦ç†ã®èª¬æ˜
    display_message("**ã‚¹ãƒ†ãƒƒãƒ—ï¼ã®å‡¦ç†ã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸã€‚ä¸‹é™å‰²ã‚Œorä¸Šé™è¶Šãˆã—ã¦ã„ã‚‹å“ç•ªã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚**")
    
    #! é¸æŠæ—¥æ™‚è¡¨ç¤º
    st.metric(label="é¸æŠæ—¥æ™‚", value=selected_datetime.strftime("%Y-%m-%d %H:%M"))

    #! æ¢ç´¢æ™‚é–“å‰ã‚’è¨­å®š
    # é¸æŠã—ãŸæ™‚é–“ï½éå»24æ™‚é–“ã‚’è¦‹ã‚‹
    selected_datetime_start = (selected_datetime - timedelta(hours=24)).strftime('%Y-%m-%d-%H')
    selected_datetime_end = selected_datetime.strftime('%Y-%m-%d-%H')

    #! è‡ªå‹•ãƒ©ãƒƒã‚¯ã®åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    # todo å¼•æ•°é–¢ä¿‚ãªãå…¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã—ã¦ã‚‹
    zaiko_df = read_zaiko_by_using_archive_data(selected_datetime_start, selected_datetime_end)
    # å®Ÿè¡Œçµæœã®ç¢ºèª
    # é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ã‚’å–å¾—
    #min_datetime = zaiko_df['æ—¥æ™‚'].min()
    #max_datetime = zaiko_df['æ—¥æ™‚'].max()
    #st.write(min_datetime, max_datetime)

    #! å“ç•ªåˆ—ã‚’æ˜‡é †ã«ã‚½ãƒ¼ãƒˆ
    zaiko_df = zaiko_df.sort_values(by='å“ç•ª', ascending=True)
    #! ç„¡åŠ¹ãªå€¤ã‚’ NaN ã«å¤‰æ›
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = pd.to_numeric(zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'], errors='coerce')
    #! å“ç•ªã”ã¨ã«æ¬ æå€¤ï¼ˆNaNï¼‰ã‚’åŸ‹ã‚ã‚‹(å‰æ–¹åŸ‹ã‚å¾Œæ–¹åŸ‹ã‚)
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df.groupby('å“ç•ª')['æ‹ ç‚¹æ‰€ç•ªåœ°'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))
    #! ãã‚Œã§ã‚‚ç½®æ›ã§ããªã„ã‚‚ã®ã¯NaN ã‚’ 0 ã§åŸ‹ã‚ã‚‹
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'].fillna(0).astype(int).astype(str)
    #! strå‹ã«å¤‰æ›
    zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'].astype(int).astype(str)

    #! 
    file_path = 'temp/ãƒã‚¹ã‚¿ãƒ¼_å“ç•ª&ä»•å…¥å…ˆå&ä»•å…¥å…ˆå·¥å ´å.csv'
    syozaikyotenchi_data = pd.read_csv(file_path, encoding='shift_jis')
    #! ç©ºç™½æ–‡å­—åˆ—ã‚„éæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’NaNã«å¤‰æ›
    syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'] = pd.to_numeric(syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'], errors='coerce')
    #! strå‹ã«å¤‰æ›
    syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'] = syozaikyotenchi_data['æ‹ ç‚¹æ‰€ç•ªåœ°'].fillna(0).astype(int).astype(str)

    #! å—å…¥å ´æ‰€è¿½åŠ 
    zaiko_df = pd.merge(zaiko_df, syozaikyotenchi_data[['å“ç•ª','æ‹ ç‚¹æ‰€ç•ªåœ°','å—å…¥å ´æ‰€']], on=['å“ç•ª', 'æ‹ ç‚¹æ‰€ç•ªåœ°'], how='left')
    #! æ—¥ä»˜åˆ—ã‚’ä½œæˆ
    zaiko_df['æ—¥ä»˜'] = zaiko_df['æ—¥æ™‚'].dt.date

    #st.dataframe(zaiko_df.head(20000))

    #! Activedata
    file_path = 'temp/activedata.csv'#ã‚¹ãƒ†ãƒƒãƒ—ï¼‘,2ã§ä½µç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€å¤‰æ•°ã§ã¯ãªãä¸€æ™‚ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã«æ ¼ç´ã—ã¦ä½¿ç”¨
    Activedata = pd.read_csv(file_path, encoding='shift_jis')
    #st.dataframe(Activedata)

    #! ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã§ 'æ—¥ä»˜' åˆ—ã‚’ datetime å‹ã«çµ±ä¸€
    zaiko_df['æ—¥ä»˜'] = pd.to_datetime(zaiko_df['æ—¥ä»˜'])
    Activedata['æ—¥ä»˜'] = pd.to_datetime(Activedata['æ—¥ä»˜'])

    #! æ—¥æ™‚ã§ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
    zaiko_df = pd.merge(zaiko_df, Activedata, on=['å“ç•ª','å—å…¥å ´æ‰€','æ—¥ä»˜'])

    #! ç‰¹å®šã®æ™‚é–“å¸¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    zaiko_df = zaiko_df[(zaiko_df['æ—¥æ™‚'] >= selected_datetime_start) & (zaiko_df['æ—¥æ™‚'] <= selected_datetime_end)]

    #column = ['æ—¥æ™‚','å“ç•ª','å—å…¥å ´æ‰€','åœ¨åº«æ•°ï¼ˆç®±ï¼‰','è¨­è¨ˆå€¤MIN','è¨­è¨ˆå€¤MAX']
    #st.dataframe(zaiko_df[column].head(20000))

    data = zaiko_df

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆæœŸå‡¦ç†: æ–°ã—ã„åˆ—ã€Œä¸‹é™å‰²ã‚Œã€ã‚’ä½œæˆ
    data['ä¸‹é™å‰²ã‚Œ'] = 0
    data['ä¸Šé™è¶Šãˆ'] = 0

    # ã€Œåœ¨åº«æ•°ï¼ˆç®±ï¼‰ã€ãŒã€Œè¨­è¨ˆå€¤MINã€ã‚’ä¸‹å›ã£ã¦ã„ã‚‹å ´åˆã€ã€Œä¸‹é™å‰²ã‚Œã€ã‚’1ã«è¨­å®š
    data.loc[data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] < data['è¨­è¨ˆå€¤MIN'], 'ä¸‹é™å‰²ã‚Œ'] = 1
    data.loc[data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] > data['è¨­è¨ˆå€¤MAX'], 'ä¸Šé™è¶Šãˆ'] = 1

    # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
    data['æ—¥æ™‚'] = pd.to_datetime(data['æ—¥æ™‚'])

    # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    # é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦è¨ˆç®—
    results_min_df = calculate_max_consecutive_time(
        selected_datetime = selected_datetime,
        data=data,  # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        time_column='æ—¥æ™‚',  # æ—¥æ™‚åˆ—
        flag_column='ä¸‹é™å‰²ã‚Œ',  # ãƒ•ãƒ©ã‚°åˆ—
        group_columns=['å“ç•ª', 'å—å…¥å ´æ‰€']  # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã®åŸºæº–åˆ—
    )
    results_min_df = results_min_df.sort_values(by='é€£ç¶šæ™‚é–“ï¼ˆhï¼‰', ascending=False).reset_index(drop=True)

    results_max_df = calculate_max_consecutive_time(
        selected_datetime = selected_datetime,
        data=data,  # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        time_column='æ—¥æ™‚',  # æ—¥æ™‚åˆ—
        flag_column='ä¸Šé™è¶Šãˆ',  # ãƒ•ãƒ©ã‚°åˆ—
        group_columns=['å“ç•ª', 'å—å…¥å ´æ‰€']  # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã®åŸºæº–åˆ—
    )
    results_max_df = results_max_df.sort_values(by='é€£ç¶šæ™‚é–“ï¼ˆhï¼‰', ascending=False).reset_index(drop=True)

    create_abnormal_hinban_ranking(results_min_df, results_max_df)

    # ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã®è¡¨ç¤º
    st.markdown("""
        <div style="background-color: #ffffff; padding: 10px; border-radius: 5px;">
        ğŸ“Œ <strong>ã‚³ãƒ©ãƒ ã®èª¬æ˜</strong><br>
        <ul>
        <li><strong>é€£ç¶šæ™‚é–“ï¼ˆhï¼‰ï¼š</strong> ä¸‹é™å‰²ã‚Œ or ä¸Šé™è¶Šãˆã—ã¦ã„ãŸé€£ç¶šæ™‚é–“ï¼ˆhourï¼‰ã‚’è¡¨ã—ã¦ã„ã¾ã™</li>
        <li><strong>å¯¾è±¡æ™‚é–“ï¼š</strong> ä¸‹é™å‰²ã‚Œ or ä¸Šé™è¶Šãˆã—ã¦ã„ãŸæœŸé–“ã‚’è¡¨ã—ã¦ã„ã¾ã™</li>
        <li><strong>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼š</strong> ã€Œé€²è¡Œä¸­ã€ â‡’ é¸æŠã—ãŸæ™‚åˆ»ã§ã‚‚ç•°å¸¸ç™ºç”Ÿä¸­ã€ã€Œè§£æ¶ˆæ¸ˆã€ â‡’ é¸æŠã—ãŸæ™‚åˆ»ã§ã¯ç•°å¸¸è§£æ¶ˆæ¸ˆã¿</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

#! ã‚¹ãƒ†ãƒƒãƒ—ï¼‘ã®å‡¦ç†ã€ãƒ‡ãƒ¼ã‚¿çµ±åˆï½å‰å‡¦ç†ï½å­¦ç¿’   
def show_analysis(product):

    #!å­¦ç¿’æœŸé–“ï¼ˆè§£ææœŸé–“ï¼‰ä»»æ„ã«è¨­å®šã§ãã‚‹ã‚ˆã†ã«ã€‚ç›´è¿‘1å¹´ã¨ã‹ã§
    #* ï¼œãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨ã™ã‚‹å ´åˆï¼
    start_date = '2024-05-01-00'
    end_date = '2024-08-29-00'
    #*ï¼œå®Ÿè¡Œæ™‚é–“ã§æ—¥æ™‚ã‚’é¸æŠã™ã‚‹å ´åˆï¼
    #current_time = datetime.now()# ç¾åœ¨ã®å®Ÿè¡Œæ™‚é–“ã‚’å–å¾—
    #end_date = (current_time - timedelta(days=1)).strftime('%Y-%m-%d-%H')# end_dateã‚’å®Ÿè¡Œæ™‚é–“ã®å‰æ—¥
    #start_date = (current_time - timedelta(days=1) - timedelta(days=180)).strftime('%Y-%m-%d-%H')# start_dateã‚’å®Ÿè¡Œæ™‚é–“ã®å‰æ—¥ã‹ã‚‰ã•ã‚‰ã«åŠå¹´å‰

    #! å‰å‡¦ç†æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    #! å®Ÿè¡Œå†…å®¹ã®èª¬æ˜
    # å®Ÿè¡ŒçŠ¶æ…‹ã®è¡¨ç¤º
    display_message("**ã‚¹ãƒ†ãƒƒãƒ—ï¼‘ã®å‡¦ç†ã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚**")
    #! ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
    #AutomatedRack_Details_df, arrival_times_df, kumitate_df, teikibin_df, Timestamp_df, zaiko_df = read_data(start_date, end_date)
    AutomatedRack_Details_df, arrival_times_df, teikibin_df, Timestamp_df, zaiko_df = read_data(start_date, end_date)
    # å®Ÿè¡ŒçŠ¶æ…‹ã®è¡¨ç¤º
    display_message("**ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚æ¬¡ã«ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨çµ±åˆå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚**")

    #! ç¨¼åƒãƒ•ãƒ©ã‚°ã®è¨ˆç®—
    # åŒã˜æ—¥æ™‚ã”ã¨ã«å…¥åº«æ•°ãƒ»å‡ºåº«æ•°ã‚’åˆè¨ˆ
    kado_df = zaiko_df.groupby('æ—¥æ™‚')[['å…¥åº«æ•°ï¼ˆç®±ï¼‰', 'å‡ºåº«æ•°ï¼ˆç®±ï¼‰']].sum().reset_index()
    kado_df["å…¥å‡ºåº«æ•°ï¼ˆç®±ï¼‰"] = kado_df["å…¥åº«æ•°ï¼ˆç®±ï¼‰"]-kado_df["å‡ºåº«æ•°ï¼ˆç®±ï¼‰"]
    # 'å…¥åº«æ•°ï¼ˆç®±ï¼‰'ã‹'å‡ºåº«æ•°ï¼ˆç®±ï¼‰'ã®ã©ã¡ã‚‰ã‹ãŒXå€‹ä»¥ä¸Šãªã‚‰ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’1ã¨ã™ã‚‹
    x = 5
    kado_df['ç¨¼åƒãƒ•ãƒ©ã‚°'] = ((kado_df['å…¥åº«æ•°ï¼ˆç®±ï¼‰'] >= x) | (kado_df['å‡ºåº«æ•°ï¼ˆç®±ï¼‰'] >= x)).astype(int)
    display_message("**ç¨¼åƒæ™‚é–“ã®è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚**")
    st.dataframe(kado_df.head(50000))

    #! è¨­å®š
    order_time_col = 'ç™ºæ³¨æ—¥æ™‚'
    reception_time_col = 'æ¤œåæ—¥æ™‚'
    target_time_col = 'é †ç«‹è£…ç½®å…¥åº«æ—¥æ™‚'
    leave_time_col = 'é †ç«‹è£…ç½®å‡ºåº«æ—¥æ™‚'

    #! å…¨ã¦ã®è­¦å‘Šã‚’ç„¡è¦–ã™ã‚‹
    warnings.filterwarnings('ignore')
        
    #-------------------------------------------------------------
    
    #! çµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆæœŸåŒ–
    results_df = pd.DataFrame(columns=['å“ç•ª','ä»•å…¥å…ˆå','å¹³å‡åœ¨åº«','Ridgeå›å¸°ã®å¹³å‡èª¤å·®', 'Ridgeå›å¸°ã®ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®', 'Ridgeå›å¸°ã®ãƒ—ãƒ©ã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®',
                                           'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®å¹³å‡èª¤å·®', 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®', 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ãƒ—ãƒ©ã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®'],dtype=object)
    

    #! å…¨å“ç•ªã®å‚¾å‘ç¢ºèªï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æå¯èƒ½ãªå“ç•ªç¢ºèªï¼‰
    # å“ç•ªã”ã¨ã®ç™ºæ³¨æ¤œåLTã®ä¸­å¤®å€¤ã‚’è¨ˆç®—
    Timestamp_df['ä»•å…¥å…ˆå·¥å ´å'] = Timestamp_df['ä»•å…¥å…ˆå·¥å ´å'].apply(lambda x: '<NULL>' if pd.isna(x) else x)
    Timestamp_df['å“ç•ª_å—å…¥å ´æ‰€'] = Timestamp_df['å“ç•ª'].astype(str) + "_" + Timestamp_df['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'].astype(str)
    hatyukensyu_median_lt = Timestamp_df.groupby(['å“ç•ª_å—å…¥å ´æ‰€','å“å','åå®¹æ•°','ä»•å…¥å…ˆå','ä»•å…¥å…ˆå·¥å ´å'])['ç™ºæ³¨æ¤œåLT'].median().reset_index()
    hatyukensyu_median_lt.columns = ['å“ç•ª_å—å…¥å ´æ‰€','å“å','åå®¹æ•°','ä»•å…¥å…ˆå','ä»•å…¥å…ˆå·¥å ´å','ç™ºæ³¨æ¤œåLTã®ä¸­å¤®å€¤']
    # ç™ºæ³¨æ¤œåLTã®ä¸­å¤®å€¤ã‚’å¤§ãã„é †ã«ã‚½ãƒ¼ãƒˆ
    hatyukensyu_median_lt = hatyukensyu_median_lt.sort_values(by='ç™ºæ³¨æ¤œåLTã®ä¸­å¤®å€¤', ascending=False).reset_index(drop=True)
    display_message("**å®Ÿç¸¾ã®ã‹ã‚“ã°ã‚“å›è»¢æ—¥æ•°ã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚**")
    st.dataframe(hatyukensyu_median_lt)

    #! å“ç•ªã®æ•°ã ã‘ãƒ«ãƒ¼ãƒ—ã‚’å›ã™
    #! ä»Šã¯1å“ç•ªã§
    count = 0
    for unique_product in [product]:
    #!ã€€ä»¥ä¸‹ã¯å…¨å“ç•ªå‹•ä½œãƒ†ã‚¹ãƒˆç”¨
    #!ã€€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª 'å“ç•ª_æ•´å‚™å®¤' åˆ—ã‚’ä½œæˆã—ã€foråˆ†ã§å›ã™
    #hinban_seibishitsu_df = create_hinban_info()
    #for unique_product in hinban_seibishitsu_df['å“ç•ª_æ•´å‚™å®¤']:
        #count = count + 1

        #if count < 260:
            #continue
        
        # ç¢ºèªç”¨ï¼šå®Ÿè¡Œæ™‚ã®æ¡ä»¶ç¢ºèª
        # filtered_Timestamp_df = Timestamp_df[Timestamp_df['å“ç•ª'] == part_number]#ç‰¹å®šå“ç•ªã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        # suppliers = filtered_Timestamp_df['ä»•å…¥å…ˆå'].unique()#è©²å½“ä»•å…¥å…ˆåã‚’æŠ½å‡º
        # supplier = str(suppliers[0])
        # count = count + 1
        # print("å“ç•ªï¼š", part_number)
        # print("ä»•å…¥å…ˆåï¼š", supplier)
        # print("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå“ç•ªã®æ•°ï¼š", len(Timestamp_df['å“ç•ª'].unique()))
        # print("ãƒ«ãƒ¼ãƒ—ï¼š", count)

        #! å“ç•ªã€æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        part_number = unique_product.split('_')[0]
        seibishitsu = unique_product.split('_')[1]

        #! å®Ÿè¡Œçµæœã®ç¢ºèª
        # å®Ÿè¡ŒçŠ¶æ…‹ã®è¡¨ç¤º
        display_message(f"**å“ç•ª{part_number}_æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰{seibishitsu}ã«å¯¾ã—ã¦å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚**")

        # if part_number == "01912ECB040":
        #     continue#ã‚¹ã‚­ãƒƒãƒ—
        
        #! å†…å®¹ï¼šé–¢æ‰€æ¯ã®ã‹ã‚“ã°ã‚“æ•°ï¼ˆ1æ™‚é–“å˜ä½ï¼‰ã‚’è¨ˆç®—
        #! Argsï¼šé–¢æ‰€æ¯ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‡ãƒ¼ã‚¿ã€é–‹å§‹æ™‚é–“ã€çµ‚äº†æ™‚é–“
        #! Returnï¼šé–¢æ‰€æ¯ã®ã‹ã‚“ã°ã‚“æ•°ï¼ˆ1æ™‚é–“å˜ä½ï¼‰
        hourly_counts_of_order, _ , _ , kyoten = calculate_hourly_counts(Timestamp_df, part_number, seibishitsu, order_time_col, start_date, end_date)#ç™ºæ³¨
        hourly_counts_of_reception, delivery_info, reception_times, _ = calculate_hourly_counts(Timestamp_df, part_number, seibishitsu, reception_time_col, start_date, end_date)#æ¤œå
        hourly_counts_of_in, _ , _ , _  = calculate_hourly_counts(Timestamp_df, part_number, seibishitsu, target_time_col, start_date, end_date)#å…¥åº«
        hourly_counts_of_out, _ , _ , _ = calculate_hourly_counts(Timestamp_df, part_number, seibishitsu, leave_time_col, start_date, end_date)#å‡ºåº«

        #! å†…å®¹ï¼šæ™‚é–“é…ã‚Œã‚’è¨ˆç®—ã€‚ç™ºæ³¨ã‹ã‚‰å…¥åº«ã¾ã§ã®æ™‚é–“ã€æ¤œåã‹ã‚‰å…¥åº«ã¾ã§ã®æ™‚é–“ã‚’è¨ˆç®—ï¼ˆéç¨¼å‹•æ—¥æ™‚é–“ã‚’ã®å–ã‚Šé™¤ã„ã¦ï¼‰
        #! Argsï¼šå“ç•ªã€é–¢æ‰€æ¯ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‡ãƒ¼ã‚¿
        #! Returnï¼šç™ºæ³¨ã€œå…¥åº«LTã€æ¤œåã€œå…¥åº«LTï¼ˆæ—¥å˜ä½ï¼‰ã®ä¸­å¤®å€¤
        median_lt_order, median_lt_reception = calculate_median_lt(part_number, Timestamp_df)
        #median_lt_order = median_lt_order*24
        #median_lt_reception = median_lt_reception*24
        display_message(f"**ä¼‘æ—¥ã‚’å‰Šé™¤ã—ãŸå ´åˆã€ç™ºæ³¨å…¥åº«LT={median_lt_order}ã¨æ¤œåå…¥åº«LT={median_lt_reception}ã¨ãªã‚Šã¾ã—ãŸ**")
        #st.dataframe(hourly_counts_of_order)
        #todo ãƒ¡ãƒ¢ï¼šå¸¸ã«éƒ¨å“ç½®ãå ´ãªã©ã§æ»ç•™ã—ã¦ã„ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã€å“ç•ªG117362010_Yã¯æ¤œåå…¥åº«LTã®ä¸­å¤®å€¤ãŒ10ã«ãªã‚‹ã€‚ç†è«–ä¸Šã¯5ç¨‹åº¦ï¼Ÿ
        filtered_Timestamp_df = Timestamp_df[Timestamp_df['å“ç•ª'] == part_number]
        kensyu = filtered_Timestamp_df["ç™ºæ³¨æ¤œåLT"].median()
        nyuuko = filtered_Timestamp_df["ç™ºæ³¨é †ç«‹è£…ç½®å…¥åº«LT"].median()
        kaisyu = filtered_Timestamp_df["ç™ºæ³¨å›åLT"].median()
        display_message(f"**ä¼‘æ—¥ã‚’å‰Šé™¤ã—ãªã„å ´åˆã€ç™ºæ³¨æ¤œåLT={kensyu}ã¨ç™ºæ³¨é †ç«‹è£…ç½®å…¥åº«LT={nyuuko}ã¨ç™ºæ³¨å›åLT={kaisyu}ã¨ãªã‚Šã¾ã—ãŸ**")
        WWWW = kaisyu - kensyu
        
        # Todoï¼šç™ºæ³¨æ—¥æ™‚ã¯2å±±ã‚ã‚‹ã€‚ç™ºæ³¨ã—ã¦4æ—¥å¾Œã«ç´å…¥ã›ã‚ˆã¨ã‹ã‚ã‚‹ã€åœŸæ—¥ã®å½±éŸ¿ï¼Ÿ
        #! å†…å®¹ï¼šç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã®æœ€é©ãªå½±éŸ¿æ™‚é–“ç¯„å›²ã‚’è¦‹ã¤ã‘ã‚‹
        #! Argsï¼š1æ™‚é–“ã”ã¨ã®ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã€1æ™‚é–“ã”ã¨ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ã€æ¢ç´¢æ™‚é–“ç¯„å›²
        #! Returnï¼šæœ€é©ç›¸é–¢å€¤ã€æœ€é©é–‹å§‹é…ã‚Œã€çµ‚äº†ç¯„å›²é…ã‚Œ
        min_lag =int(median_lt_order * 24)-4  # LTä¸­å¤®å€¤ã‚’åŸºæº–ã«æœ€å°é…ã‚Œæ™‚é–“ã‚’è¨­å®š
        max_lag =int(median_lt_order * 24)+4  # LTä¸­å¤®å€¤ã‚’åŸºæº–ã«æœ€å¤§é…ã‚Œæ™‚é–“ã‚’è¨­å®š
        best_corr_order, best_range_start_order, best_range_end_order = find_best_lag_range(hourly_counts_of_order, hourly_counts_of_in, min_lag, max_lag, 'ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°')

        #! å†…å®¹ï¼šæ¤œåã‹ã‚“ã°ã‚“æ•°ã®æœ€é©ãªå½±éŸ¿æ™‚é–“ç¯„å›²ã‚’è¦‹ã¤ã‘ã‚‹
        #! Argsï¼š1æ™‚é–“ã”ã¨ã®æ¤œåã‹ã‚“ã°ã‚“æ•°ã€1æ™‚é–“ã”ã¨ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ã€æ¢ç´¢æ™‚é–“ç¯„å›²
        #! Returnï¼šæœ€é©ç›¸é–¢å€¤ã€æœ€é©é–‹å§‹é…ã‚Œã€çµ‚äº†ç¯„å›²é…ã‚Œ
        min_lag = int(median_lt_reception * 24)-4  # LTä¸­å¤®å€¤ã‚’åŸºæº–ã«æœ€å°é…ã‚Œæ™‚é–“ã‚’è¨­å®š
        max_lag = int(median_lt_reception * 24)+4  # LTä¸­å¤®å€¤ã‚’åŸºæº–ã«æœ€å¤§é…ã‚Œæ™‚é–“ã‚’è¨­å®š
        best_corr_reception, best_range_start_reception, best_range_end_reception = find_best_lag_range(hourly_counts_of_reception, hourly_counts_of_in, min_lag, max_lag, 'ç´å…¥ã‹ã‚“ã°ã‚“æ•°')
        
        # ç¢ºèªç”¨ï¼šå®Ÿè¡Œçµæœã®ç¢ºèª
        #print(f"Best range for ç™ºæ³¨: {best_range_start_order}æ™‚é–“å‰ã‹ã‚‰{best_range_end_order}æ™‚é–“å‰ã¾ã§")
        #print(f"Best correlation for ç™ºæ³¨: {best_corr_order}")
        #print(f"æ¤œåã€œå…¥åº«LTä¸­å¤®å€¤ï¼š{median_lt_reception}æ—¥,æ¤œåã€œå…¥åº«æ™‚é–“ä¸­å¤®å€¤ï¼š{median_lt_reception*24}æ™‚é–“")
        #print(f"Best range for æ¤œå: {best_range_start_reception}æ™‚é–“å‰ã‹ã‚‰{best_range_end_reception}æ™‚é–“å‰ã¾ã§")
        #print(f"Best correlation for æ¤œå: {best_corr_reception}")
        
        #st.header("ç´å…¥æ™‚é–“ã®ç¢ºèª")
        #st.dataframe(reception_times)
        #st.dataframe(delivery_info)

        #! å†…å®¹ï¼šæœ€é©ãªå½±éŸ¿æ™‚é–“ç¯„å›²ã«åŸºã¥ã„ã¦ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã¨æ¤œåã‹ã‚“ã°ã‚“æ•°ã‚’è¨ˆç®—
        #! Argsï¼š1æ™‚é–“ã”ã¨ã®ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã€1æ™‚é–“ã”ã¨ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ã€æœ€é©æ™‚é–“é…ã‚Œç¯„å›²
        #! Returnï¼šæœ€é©æ™‚é–“é…ã‚Œã§è¨ˆç®—ã—ãŸç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã€å…¥åº«ã‹ã‚“ã°ã‚“æ•°
        lagged_features_order = create_lagged_features(hourly_counts_of_order, hourly_counts_of_in, hourly_counts_of_out, best_range_start_order, best_range_end_order, 'ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°', delivery_info, reception_times)
        lagged_features_reception = create_lagged_features(hourly_counts_of_reception, hourly_counts_of_in, hourly_counts_of_out, best_range_start_reception, best_range_end_reception, 'ç´å…¥ã‹ã‚“ã°ã‚“æ•°', delivery_info, reception_times)
        # å‰å‡¦ç†ï¼šé‡è¤‡ã®ã‚ã‚‹target åˆ—ã‚’å‰Šé™¤
        lagged_features_reception = lagged_features_reception.drop(columns=['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'])
        lagged_features_reception = lagged_features_reception.drop(columns=['å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'])
        # æœ€é©ãªå½±éŸ¿æ™‚é–“ç¯„å›²ã«åŸºã¥ã„ãŸç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã¨ã€æ¤œåã‹ã‚“ã°ã‚“æ•°ã‚’çµ±åˆ
        lagged_features = lagged_features_order.join(lagged_features_reception, how='outer')

        reception_times = reception_times.to_frame()
        lagged_features = pd.merge(lagged_features, reception_times, on=['ã‚¤ãƒ™ãƒ³ãƒˆæ™‚é–“'], how='left')
        delivery_info = delivery_info.to_frame()
        lagged_features = pd.merge(lagged_features, delivery_info, on=['ã‚¤ãƒ™ãƒ³ãƒˆæ™‚é–“'], how='left')

        #ç¢ºèªï¼šå®Ÿè¡Œçµæœ
        display_message(f"**1æ™‚é–“ã‚ãŸã‚Šã®é–¢æ‰€åˆ¥ã®ã‹ã‚“ã°ã‚“æ•°ã®è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚**")
        st.dataframe(lagged_features)

        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! Resultï¼šã€Œæ‹ ç‚¹æ‰€ç•ªåœ°ã€åˆ—ã€ã€Œæ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ã€åˆ—ã®è¿½åŠ 
        lagged_features['å“ç•ª'] = part_number
        lagged_features['æ‹ ç‚¹æ‰€ç•ªåœ°'] = kyoten
        lagged_features['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] = seibishitsu

        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! Resultï¼šã€Œåœ¨åº«å¢—æ¸›æ•°ï¼ˆtï¼‰ã€åˆ—ã€ã€Œç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã€åˆ—ã€ã€Œç´å…¥ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã€åˆ—ã®è¿½åŠ 
        lagged_features['åœ¨åº«å¢—æ¸›æ•°ï¼ˆtï¼‰'] = lagged_features['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] - lagged_features['å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰']#åœ¨åº«å¢—æ¸›æ•°ã‚’è¨ˆç®—
        lagged_features['ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = hourly_counts_of_order# ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°(t)ã‚’è¨ˆç®—
        lagged_features['ç´å…¥ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = hourly_counts_of_reception# ç´å…¥ã‹ã‚“ã°ã‚“æ•°(t)ã‚’è¨ˆç®—

        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! Whatï¼šã€Œå“ç•ªã€åˆ—ã¨ã€Œæ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ã€åˆ—ã‚’ã‚‚ã¨ã«ã€ã€Œä»•å…¥å…ˆåã€åˆ—ã€ã€Œç™ºé€å ´æ‰€åã€åˆ—ã‚’æ¢ã—ã€çµ±åˆ
        #! Resultï¼šã€Œä»•å…¥å…ˆåã€åˆ—ã€ã€Œç™ºé€å ´æ‰€åï¼ˆåç§°å¤‰æ›´ã€‚æ—§ä»•å…¥ã‚Œå…ˆå·¥å ´åï¼‰ã€åˆ—ã®è¿½åŠ 
        lagged_features = add_part_supplier_info(Timestamp_df, lagged_features, seibishitsu)
        lagged_features = lagged_features.rename(columns={'ä»•å…¥å…ˆå·¥å ´å': 'ç™ºé€å ´æ‰€å'})# ã‚³ãƒ©ãƒ åå¤‰æ›´

        #! éå»ã®å‡ºåº«ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’è¨ˆç®—
        lagged_features, median_interval_out = calculate_elapsed_time_since_last_dispatch(lagged_features)

        # 0ã‚’é™¤ã„ãŸæ•°å€¤ã®ä¸­å¤®å€¤ã‚’è¨ˆç®—
        # median_value_out = lagged_features[lagged_features['å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] != 0]['å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'].median()

        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! Whatï¼šã€Œæ‹ ç‚¹æ‰€ç•ªåœ°ã€åˆ—ã‚’ã‚‚ã¨ã«åœ¨åº«æ•°ã‚’ç´ã¥ã‘ã‚‹
        # ã¾ãšã€ç„¡åŠ¹ãªå€¤ã‚’ NaN ã«å¤‰æ›
        zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = pd.to_numeric(zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'], errors='coerce')
        # å“ç•ªã”ã¨ã«æ¬ æå€¤ï¼ˆNaNï¼‰ã‚’åŸ‹ã‚ã‚‹(å‰æ–¹åŸ‹ã‚å¾Œæ–¹åŸ‹ã‚)
        zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df.groupby('å“ç•ª')['æ‹ ç‚¹æ‰€ç•ªåœ°'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))
        # ãã‚Œã§ã‚‚ç½®æ›ã§ããªã„ã‚‚ã®ã¯NaN ã‚’ 0 ã§åŸ‹ã‚ã‚‹
        zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'].fillna(0).astype(int).astype(str)
        # ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã® 'æ‹ ç‚¹æ‰€ç•ªåœ°' åˆ—ã‚’æ–‡å­—åˆ—å‹ã«å¤‰æ›
        lagged_features['æ‹ ç‚¹æ‰€ç•ªåœ°'] = lagged_features['æ‹ ç‚¹æ‰€ç•ªåœ°'].astype(int).astype(str)
        zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'] = zaiko_df['æ‹ ç‚¹æ‰€ç•ªåœ°'].astype(int).astype(str)
        lagged_features = pd.merge(lagged_features, zaiko_df[['æ—¥æ™‚', 'å“ç•ª', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰','æ‹ ç‚¹æ‰€ç•ªåœ°']], on=['å“ç•ª', 'æ—¥æ™‚', 'æ‹ ç‚¹æ‰€ç•ªåœ°'], how='left')#! è‡ªå‹•ãƒ©ãƒƒã‚¯åœ¨åº«çµåˆ
        
        #! åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®æ¬ ææ™‚é–“ã‚’åŸ‹ã‚ã‚‹
        # 'æ—¥æ™‚' åˆ—ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚½ãƒ¼ãƒˆ
        lagged_features = lagged_features.sort_values(by=['å“ç•ª', 'æ—¥æ™‚'])
        # åœ¨åº«æ•°ï¼ˆç®±ï¼‰ãŒ NULL ã®å ´åˆã€å‰ã®æ™‚é–“ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰ã§è£œå®Œ
        #lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] = lagged_features.groupby('å“ç•ª')['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].transform(lambda x: x.fillna(method='ffill'))
        # todo åœ¨åº«æ•°ï¼ˆç®±ï¼‰ãŒNULLã®ã¨ãã€å‰ã®æ™‚é–“ã®åœ¨åº«å¢—æ¸›æ•°ï¼ˆtï¼‰+åœ¨åº«æ•°ï¼ˆtï¼‰ã§è£œå®Œã™ã‚‹
        for idx in lagged_features.index:
            if pd.isnull(lagged_features.loc[idx,'åœ¨åº«æ•°ï¼ˆç®±ï¼‰']):
                if idx > 0:
                    lagged_features.loc[idx,'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] = lagged_features.loc[idx - 1,'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] + lagged_features.loc[idx-1,'åœ¨åº«å¢—æ¸›æ•°ï¼ˆtï¼‰']

        lagged_features = pd.merge(lagged_features, AutomatedRack_Details_df, on=['æ—¥æ™‚'], how='left')#! 1æ™‚é–“ã‚ã‚ãŸã‚Šã®é–“å£åˆ¥åœ¨åº«ã®è¨ˆç®—
        for col in lagged_features.columns:
            if pd.api.types.is_timedelta64_dtype(lagged_features[col]):
                lagged_features[col] = lagged_features[col].fillna(pd.Timedelta(0))
            else:
                lagged_features[col] = lagged_features[col].fillna(0)

        #! ä»•å…¥å…ˆä¾¿åˆ°ç€ãƒ•ãƒ©ã‚°è¨ˆç®—
        #! ä¸€è‡´ã™ã‚‹ä»•å…¥ã‚Œå…ˆãƒ•ãƒ©ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ã‚¨ãƒ©ãƒ¼ã‚’å‡ºã™
        lagged_features, matched_arrival_times_df,nonyu_type = process_shiresakibin_flag(lagged_features, arrival_times_df)
        # å®Ÿè¡Œçµæœã®ç¢ºèª
        display_message(f"**æ—©ç€å®šåˆ»é…ç€ã®åŸºæº–ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸ**")
        st.dataframe(lagged_features)
        #st.write(nonyu_type)

        #! lagged_features ã¨ kumitate_df ã‚’æ—¥æ™‚ã§çµ±åˆ
        # lagged_features = pd.merge(lagged_features, kumitate_df[['æ—¥æ™‚','æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰','ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ','è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ','è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡æ¸ˆ']], on=['æ—¥æ™‚', 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'], how='left')
        # # å®Ÿè¡Œçµæœ
        # display_message(f"**ITç”Ÿç”£ç®¡ç†ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¾ã—ãŸã€‚**")
        # st.dataframe(lagged_features)

        #! æœ€é©ãªé…ã‚Œæ™‚é–“ã‚’è¨ˆç®—
        best_range_order = int((best_range_start_order + best_range_end_order)/2)#æœ€é©ãªç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã®å¹…
        best_range_reception = int((best_range_start_reception + best_range_end_reception)/2)#æœ€é©ãªç´å…¥ã‹ã‚“ã°ã‚“æ•°ã®å¹…
        #st.write(f"ç™ºæ³¨å…¥åº«LTï¼š{best_range_order},æ¤œåå…¥åº«LTï¼š{best_range_reception}")

        #todo 
        #! ã‹ã‚“ã°ã‚“ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        # æ‰€åœ¨ç®¡ç†ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        Timestamp_df = Timestamp_df.rename(columns={'ä»•å…¥å…ˆå·¥å ´å': 'ç™ºé€å ´æ‰€å'})# ã‚³ãƒ©ãƒ åå¤‰æ›´
        shiresaki = lagged_features['ä»•å…¥å…ˆå'].unique()
        shiresaki_hassou = lagged_features['ç™ºé€å ´æ‰€å'].unique()
        Timestamp_filtered_df = Timestamp_df[(Timestamp_df['å“ç•ª'] == part_number) & (Timestamp_df['ä»•å…¥å…ˆå'] == shiresaki[0]) & (Timestamp_df['ç™ºé€å ´æ‰€å'] == shiresaki_hassou[0]) & (Timestamp_df['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] == seibishitsu)]# æ¡ä»¶ã‚’æº€ãŸã™è¡Œã‚’æŠ½å‡º
        #st.header("ã‹ã‚“ã°ã‚“ãƒ‡ãƒ¼ã‚¿ç¢ºèª")
        #st.dataframe(Timestamp_filtered_df.head(10000))
        # ä»•å…¥å…ˆãƒ€ã‚¤ãƒ¤ã®æº–å‚™
        matched_arrival_times_df = matched_arrival_times_df.rename(columns={'å—å…¥': 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'})# ã‚³ãƒ©ãƒ åå¤‰æ›´
        # çµ±åˆã™ã‚‹åˆ—ã®é¸åˆ¥
        columns_to_extract_t = ['ã‹ã‚“ã°ã‚“ã‚·ãƒªã‚¢ãƒ«','ç´å…¥æ—¥', 'ç´å…¥ä¾¿','æ¤œåæ—¥æ™‚','ä»•å…¥å…ˆå', 'ç™ºé€å ´æ‰€å', 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰']
        columns_to_extract_l = matched_arrival_times_df.filter(regex='ä¾¿_å®šåˆ»').columns.tolist() + ['ä»•å…¥å…ˆå', 'ç™ºé€å ´æ‰€å', 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰']
        # çµ±åˆ
        Timestamp_filtered_df = pd.merge(Timestamp_filtered_df[columns_to_extract_t], matched_arrival_times_df[columns_to_extract_l], on=['ä»•å…¥å…ˆå', 'ç™ºé€å ´æ‰€å', 'æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'], how='left')
        #å®Ÿè¡Œçµæœã®ç¢ºèª
        #st.header("æ‰€åœ¨ç®¡ç†ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºç¢ºèª")
        #st.write(len(Timestamp_filtered_df))
        #st.dataframe(Timestamp_filtered_df.head(10000))

        #! ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã®è¨ˆç®—é–¢æ•°
        def calculate_scheduled_nouyu_kanban(df, start_date, end_date):
            """
            æŒ‡å®šæœŸé–“å†…ã®ç´å…¥ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€ç´å…¥äºˆå®šæ—¥æ™‚ã”ã¨ã«é›†è¨ˆã™ã‚‹é–¢æ•°ã€‚

            Args:
                df (pd.DataFrame): ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
                start_date (str): æŠ½å‡ºé–‹å§‹æ—¥ï¼ˆä¾‹ï¼š'2024/3/5'ï¼‰ã€‚
                end_date (str): æŠ½å‡ºçµ‚äº†æ—¥ã€‚

            Returns:
                pd.DataFrame: ç´å…¥äºˆå®šæ—¥æ™‚ã”ã¨ã®é›†è¨ˆçµæœã‚’æ ¼ç´ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
            """
            # æ—¥ä»˜ã‚’datetimeå½¢å¼ã«å¤‰æ›
            start_date = pd.to_datetime(start_date)
            end_date = pd.to_datetime(end_date) + pd.Timedelta(days=1)

            # â‘  "ç´å…¥æ—¥"åˆ—ãŒæœŸé–“å†…ã«è©²å½“ã™ã‚‹è¡Œã‚’æŠ½å‡º
            filtered_df = df[(pd.to_datetime(df['ç´å…¥æ—¥']) >= start_date) & (pd.to_datetime(df['ç´å…¥æ—¥']) < end_date)]

            #st.header("å®šåˆ»ä¾¿ç¢ºèª")
            #st.dataframe(filtered_df)

            # â‘¡ æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å‡¦ç†
            # â‘¡-1 "ç´å…¥ä¾¿"åˆ—ã‹ã‚‰æ•°å€¤ã‚’å–å¾—
            filtered_df['B'] = filtered_df['ç´å…¥ä¾¿'].astype(int)

            # â‘¡-2 "Bä¾¿_å®šåˆ»"åˆ—ã®å€¤ã‚’å–å¾—ã—ã¦æ–°ã—ã„åˆ—"ç´å…¥äºˆå®šæ™‚é–“"ã«æ ¼ç´
            filtered_df['ç´å…¥äºˆå®šæ™‚é–“'] = filtered_df.apply(lambda row: row[f"{row['B']}ä¾¿_å®šåˆ»"] if f"{row['B']}ä¾¿_å®šåˆ»" in df.columns else None, axis=1)

            # â‘¡-3 "ç´å…¥äºˆå®šæ™‚é–“"åˆ—ãŒ0æ™‚ï½8æ™‚ã®å ´åˆã«"ç´å…¥æ—¥_è£œæ­£"åˆ—ã‚’1æ—¥å¾Œã«è¨­å®š
            filtered_df['ç´å…¥äºˆå®šæ™‚é–“'] = pd.to_datetime(filtered_df['ç´å…¥äºˆå®šæ™‚é–“'], format='%H:%M:%S', errors='coerce').dt.time
            #todo å¤œå‹¤ä¾¿ã¯+1ãŒå¿…è¦ï¼ï¼ï¼ï¼
            #todo ä»Šã®è¨ˆç®—ã§ã„ã„ã‹ä¸æ˜ï¼ï¼
            filtered_df['ç´å…¥æ—¥_è£œæ­£'] = filtered_df.apply(lambda row: (pd.to_datetime(row['ç´å…¥æ—¥']) + pd.Timedelta(days=1)).strftime('%Y-%m-%d')
                                                        if row['ç´å…¥äºˆå®šæ™‚é–“'] and 0 <= row['ç´å…¥äºˆå®šæ™‚é–“'].hour < 6 else row['ç´å…¥æ—¥'], axis=1)

            # â‘¡-4 "ç´å…¥æ—¥_è£œæ­£"åˆ—ã¨"ç´å…¥äºˆå®šæ™‚é–“"åˆ—ã‚’çµ±åˆã—"ç´å…¥äºˆå®šæ—¥æ™‚"åˆ—ã‚’ä½œæˆ
            filtered_df['ç´å…¥äºˆå®šæ—¥æ™‚'] = pd.to_datetime(filtered_df['ç´å…¥æ—¥_è£œæ­£']) + pd.to_timedelta(filtered_df['ç´å…¥äºˆå®šæ™‚é–“'].astype(str))

            #st.write(len(filtered_df))

            # â‘¡-5 "ç´å…¥äºˆå®šæ—¥æ™‚"åˆ—ã§é›†è¨ˆã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ ¼ç´
            nonyu_yotei_df = filtered_df.groupby('ç´å…¥äºˆå®šæ—¥æ™‚').agg(
                ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°=('ç´å…¥äºˆå®šæ—¥æ™‚', 'size'),
                ç´å…¥äºˆå®šä¾¿ä¸€è¦§=('ç´å…¥ä¾¿', lambda x: list(x)),
                ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“ä¸€è¦§=('ã‹ã‚“ã°ã‚“ã‚·ãƒªã‚¢ãƒ«', lambda x: list(x)),
                ç´å…¥äºˆå®šä¾¿=('ç´å…¥ä¾¿', lambda x: list(set(x))[0] if len(set(x)) == 1 else list(set(x)))  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªç´å…¥ä¾¿ã‚’ã‚¹ã‚«ãƒ©ãƒ¼ã«å¤‰æ›
            ).reset_index()
            
            nonyu_yotei_df['ç´å…¥äºˆå®šæ—¥æ™‚_raw'] = nonyu_yotei_df['ç´å…¥äºˆå®šæ—¥æ™‚']
            # "ç´å…¥äºˆå®šæ—¥æ™‚"åˆ—ã®åˆ†ä»¥é™ã‚’0ã«è¨­å®š
            nonyu_yotei_df['ç´å…¥äºˆå®šæ—¥æ™‚'] = nonyu_yotei_df['ç´å…¥äºˆå®šæ—¥æ™‚'].apply(lambda x: x.replace(minute=0, second=0) if pd.notna(x) else x)

            nonyu_yotei_df = nonyu_yotei_df.rename(columns={'ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°': 'ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'})# ã‚³ãƒ©ãƒ åå¤‰æ›´
            nonyu_yotei_df = nonyu_yotei_df.rename(columns={'ç´å…¥äºˆå®šæ—¥æ™‚': 'æ—¥æ™‚'})# ã‚³ãƒ©ãƒ åå¤‰æ›´

            #todo æ¤œåæ—¥æ™‚2æ™‚56åˆ†ã ã¨ã€2æ™‚ã«ãªã‚‹ãªã€‚
            kensyu_df = filtered_df.groupby('æ¤œåæ—¥æ™‚').agg(
                æ¤œåã‹ã‚“ã°ã‚“æ•°=('æ¤œåæ—¥æ™‚', 'size'),
                æ¤œåã‹ã‚“ã°ã‚“ä¸€è¦§=('ã‹ã‚“ã°ã‚“ã‚·ãƒªã‚¢ãƒ«', lambda x: list(x))
            ).reset_index()

            kensyu_df['æ¤œåæ—¥æ™‚_raw'] = kensyu_df['æ¤œåæ—¥æ™‚']
            kensyu_df['æ¤œåæ—¥æ™‚'] = kensyu_df['æ¤œåæ—¥æ™‚'].apply(lambda x: x.replace(minute=0, second=0) if pd.notna(x) else x)
            kensyu_df = kensyu_df.rename(columns={'æ¤œåæ—¥æ™‚': 'æ—¥æ™‚'})# ã‚³ãƒ©ãƒ åå¤‰æ›´

            return nonyu_yotei_df, kensyu_df
        
        def calculate_disruption(df):
            """
            ç´å…¥äºˆå®šæ—¥æ™‚ã¨æ¤œåæ—¥æ™‚ã®ä¹±ã‚Œã‚’è¨ˆç®—ã—ã€æ–°ã—ã„åˆ—ã‚’ä½œæˆã™ã‚‹é–¢æ•°ã€‚

            Args:
                df (pd.DataFrame): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚

            Returns:
                pd.DataFrame: æ–°ã—ã„åˆ—"ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ"ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
            """
            # æ–°ã—ã„åˆ—ã‚’åˆæœŸåŒ–
            df['ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ'] = None

            for idx, row in df.iterrows():
                if row['ç´å…¥äºˆå®šæ—¥æ™‚_raw'] != 0:
                    # baseè¡Œã‚’å–å¾—
                    base_time = pd.to_datetime(row['ç´å…¥äºˆå®šæ—¥æ™‚_raw'])

                    # å‰2è¡Œã¨å¾Œã‚2è¡Œã‚’å–å¾—
                    prev_rows = df.iloc[max(0, idx - 2):idx]
                    next_rows = df.iloc[idx + 1:idx + 3]

                    # earlyè¡Œã¨delayè¡Œã‚’æ¢ã™
                    early_row = prev_rows[prev_rows['æ¤œåæ—¥æ™‚_raw'] != 0].tail(1)
                    delay_row = next_rows[next_rows['æ¤œåæ—¥æ™‚_raw'] != 0].head(1)

                    if not early_row.empty:
                        # earlyè¡ŒãŒã‚ã‚‹å ´åˆ
                        early_time = pd.to_datetime(early_row['æ¤œåæ—¥æ™‚_raw'].values[0])
                        time_diff = (base_time - early_time).total_seconds() / 3600  # æ™‚é–“å˜ä½ã®å·®åˆ†ã‚’è¨ˆç®—
                        df.at[idx, 'ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ'] = time_diff
                    elif not delay_row.empty:
                        # earlyãŒãªãã€delayè¡ŒãŒã‚ã‚‹å ´åˆ
                        delay_time = pd.to_datetime(delay_row['æ¤œåæ—¥æ™‚_raw'].values[0])
                        time_diff = (delay_time - base_time).total_seconds() / 3600  # æ™‚é–“å˜ä½ã®å·®åˆ†ã‚’è¨ˆç®—
                        df.at[idx, 'ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ'] = time_diff

            return df
        
        #! ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã®è¨ˆç®—
        nonyu_yotei_df, kensyu_df = calculate_scheduled_nouyu_kanban(Timestamp_filtered_df, start_date, end_date)
        #! æ—¥æ™‚ã§ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
        lagged_features = pd.merge(lagged_features, nonyu_yotei_df, on='æ—¥æ™‚', how='left')
        lagged_features = pd.merge(lagged_features, kensyu_df, on='æ—¥æ™‚', how='left')
        #! ã™ã¹ã¦ã®Noneå€¤ã‚’0ã«ç½®ãæ›ãˆ
        # lagged_featuresã«çµ±åˆã™ã‚‹éš›ã€nonyu_yotei_dfã«å­˜åœ¨ã—ãªã„æ—¥æ™‚ã¯Noneã«ãªã‚‹ãŸã‚
        lagged_features = lagged_features.fillna(0)

        # å®Ÿè¡Œçµæœã®ç¢ºèª
        display_message(f"**ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚**")
        st.dataframe(nonyu_yotei_df)
        display_message(f"**å‚è€ƒï¼‰æ¤œåã‹ã‚“ã°ã‚“æ•°ã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚**")
        st.dataframe(kensyu_df)
        display_message(f"**ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ã€æ¤œåã‹ã‚“ã°ã‚“æ•°ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚**")
        st.dataframe(lagged_features)

        #! ä»•å…¥å…ˆä¾¿ã®åˆ°ç€ä¹±ã‚Œ
        display_message(f"**å‚è€ƒï¼‰æ¤œåã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ä¹±ã‚Œã‚’ç¢ºèªã—ã¾ã™ã€‚**")
        columns_to_display = ['æ—¥æ™‚','ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“ä¸€è¦§','æ¤œåã‹ã‚“ã°ã‚“ä¸€è¦§']
        st.dataframe(lagged_features[columns_to_display])

        #! Activedataã®çµ±åˆ
        file_path = 'temp/activedata.csv'#ã‚¹ãƒ†ãƒƒãƒ—ï¼‘,2ã§ä½µç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€å¤‰æ•°ã§ã¯ãªãä¸€æ™‚ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã«æ ¼ç´ã—ã¦ä½¿ç”¨
        Activedata = pd.read_csv(file_path, encoding='shift_jis')
        # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
        Activedata['æ—¥ä»˜'] = pd.to_datetime(Activedata['æ—¥ä»˜'], errors='coerce')
        #! å“ç•ªã€æ•´å‚™å®¤æƒ…å ±èª­ã¿è¾¼ã¿
        #seibishitsu = product.split('_')[1]#æ•´å‚™å®¤ã®ã¿
        product = part_number#product.split('_')[0]#å“ç•ªã®ã¿
        #! åŒå“ç•ªã€åŒæ•´å‚™å®¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        Activedata = Activedata[(Activedata['å“ç•ª'] == product) & (Activedata['æ•´å‚™å®¤'] == seibishitsu)]
        #! 1æ™‚é–“ã”ã¨ã«å¤‰æ›
        Activedata = Activedata.set_index('æ—¥ä»˜').resample('H').ffill().reset_index()
        filtered_Activedata = Activedata[Activedata['æ—¥ä»˜'].isin(lagged_features['æ—¥æ™‚'])].copy()
        filtered_Activedata = filtered_Activedata.reset_index(drop=True)
        filtered_Activedata = filtered_Activedata.rename(columns={'æ—¥ä»˜': 'æ—¥æ™‚'})
        # æ—¥æ™‚ã®å½¢å¼ãŒåŒã˜ã‹ç¢ºèªã—ã€å¿…è¦ãªã‚‰ã°å¤‰æ›
        lagged_features['æ—¥ä»˜'] = pd.to_datetime(lagged_features['æ—¥æ™‚'])
        filtered_Activedata['æ—¥æ™‚'] = pd.to_datetime(filtered_Activedata['æ—¥æ™‚'])
        #! æ˜¼å‹¤å¤œå‹¤ã®è€ƒæ…®
        def adjust_datetime(x):
            if 0 <= x.hour < 8:
                # æ—¥ä»˜ã‚’å‰æ—¥ã«å¤‰æ›´ã—ã€æ™‚é–“ã¯ãã®ã¾ã¾
                return x + pd.Timedelta(days=1)
            else:
                # ãã®ã¾ã¾ã®æ—¥ä»˜ã‚’è¿”ã™
                return x
        #! æ˜¼å‹¤å¤œå‹¤ã®è€ƒæ…®
        filtered_Activedata['æ—¥æ™‚'] = filtered_Activedata['æ—¥æ™‚'].apply(adjust_datetime)
        #! æ—¥æ™‚ã§ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
        lagged_features = pd.merge(lagged_features, filtered_Activedata, on='æ—¥æ™‚')
        #! ã‹ã‚“ã°ã‚“å›è»¢æ—¥æ•°è¨ˆç®—
        lagged_features["ã‹ã‚“ã°ã‚“å›è»¢æ—¥æ•°"] = (lagged_features["ã‚µã‚¤ã‚¯ãƒ«é–“éš”"] * (lagged_features["ã‚µã‚¤ã‚¯ãƒ«æƒ…å ±"] + 1)) / lagged_features["ã‚µã‚¤ã‚¯ãƒ«å›æ•°"]
        #! é¸æŠã•ã‚ŒãŸåˆ—ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—
        kanban_kaiten_nissu = int(lagged_features["ã‹ã‚“ã°ã‚“å›è»¢æ—¥æ•°"].unique()[0])
        #! ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’è¡¨ç¤º
        display_message(f"**ã‹ã‚“ã°ã‚“å›è»¢æ—¥æ•°ï¼ˆè¨­è¨ˆå€¤ï¼‰ã¯{kanban_kaiten_nissu}ã«ãªã‚Šã¾ã—ãŸã€‚**")
        # å®Ÿè¡Œç¢ºèª
        # st.dataframe(filtered_Activedata)

        #! ITç”Ÿç”£ç®¡ç†ç‰ˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸç¨¼åƒãƒ•ãƒ©ã‚°ã®è¨ˆç®—ã€€â‡’ã€€ä¼‘æ—¥ã«ç”Ÿç”£è¨ˆç”»ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ãŸã‚Šã€ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„æ—¥ãªã©ãŒã‚ã‚‹ãŸã‚ãƒœãƒ„ã«
        #! Whatï¼šã‚ã‚‹æ™‚é–“ãŒç¨¼åƒæ™‚é–“ãªã®ã‹éç¨¼åƒæ™‚é–“ãªã®ã‹è¨ˆç®—
        #! Resultï¼škado_dfã®ä½œæˆ
        # #todo æ¨æ¸¬ã§ã¯ãªãå®Ÿç¸¾ã®ç¨¼åƒãƒ‡ãƒ¼ã‚¿ãŒæ¬²ã—ã„
        # # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚³ãƒ”ãƒ¼
        # kado_df = kumitate_df.copy()
        # # ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’è¨­å®šã€‚'è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ'>0ãªã‚‰ç¨¼åƒ1ã€0ãªã‚‰éç¨¼åƒ0ã¨ã™ã‚‹
        # kado_df['ç¨¼åƒãƒ•ãƒ©ã‚°'] = kado_df['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ'].apply(lambda x: 1 if x != 0 else 0)
        # # å¿…è¦ãªåˆ—ã‚’æŠ½å‡º
        # kado_df = kado_df[kado_df['æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰'] == seibishitsu]
        # kado_df = kado_df[['æ—¥æ™‚', 'ç¨¼åƒãƒ•ãƒ©ã‚°']]
        # # å‡¦ç†è¿½åŠ ã€‚å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰>0ã®æ™‚é–“ã‚‚ç¨¼åƒã¨ã™ã‚‹
        # kado_df2 = lagged_features.copy()
        # kado_df2['ç¨¼åƒãƒ•ãƒ©ã‚°_å…¥åº«ã‹ã‚“ã°ã‚“æ•°åŸºæº–'] = kado_df2['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'].apply(lambda x: 1 if x != 0 else 0)
        # kado_df2 = kado_df2[['æ—¥æ™‚', 'ç¨¼åƒãƒ•ãƒ©ã‚°_å…¥åº«ã‹ã‚“ã°ã‚“æ•°åŸºæº–']]
        # kado_df = pd.merge(kado_df, kado_df2, on='æ—¥æ™‚', how='right')
        # # æ¡ä»¶ã‚’æº€ãŸã™å ´åˆã«ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’1ã«è¨­å®š
        # kado_df.loc[kado_df['ç¨¼åƒãƒ•ãƒ©ã‚°_å…¥åº«ã‹ã‚“ã°ã‚“æ•°åŸºæº–'] > 0, 'ç¨¼åƒãƒ•ãƒ©ã‚°'] = 1
        # st.dataframe(kado_df)

        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! Resultï¼šã€Œç¨¼åƒãƒ•ãƒ©ã‚°ã€åˆ—ã®è¿½åŠ 
        lagged_features = pd.merge(lagged_features, kado_df, on='æ—¥æ™‚', how='left')

        #! ä»•å…¥å…ˆä¾¿åˆ°ç€ã®ä¹±ã‚Œè¨ˆç®—
        lagged_features = calculate_disruption(lagged_features)
        # 0ä»¥ä¸Š2ä»¥ä¸‹ã®å€¤ã‚’0ã«ç½®ãæ›ãˆã‚‹
        lagged_features = lagged_features.fillna(0)
        lagged_features['ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ_è£œæ­£'] = lagged_features['ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ'].apply(lambda x: 0 if 0 <= x <= 2 else x)
        columns_to_display = ['æ—¥æ™‚','ç¨¼åƒãƒ•ãƒ©ã‚°','ç´å…¥äºˆå®šæ—¥æ™‚_raw','æ¤œåæ—¥æ™‚_raw','ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ','ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ_è£œæ­£']
        display_message(f"**ä»•å…¥å…ˆä¾¿åˆ°ç€ã®ä¹±ã‚Œã‚’ç¢ºèªã—ã¾ã™ã€‚**")
        st.dataframe(lagged_features[columns_to_display])

        #!æ—¥é‡ç®±æ•°è¨ˆç®—
        lagged_features['æ—¥é‡ç®±æ•°'] = lagged_features['æ—¥é‡æ•°']/lagged_features['åå®¹æ•°']

        def shift_with_leadtime(df, target_column, output_column, leadtime):
            """
            æŒ‡å®šåˆ—ã®å€¤ã‚’ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚’è€ƒæ…®ã—ã¦æ–°ã—ã„åˆ—ã«æ ¼ç´ã™ã‚‹é–¢æ•°ã€‚

            Args:
                df (pd.DataFrame): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
                target_column (str): å‡¦ç†å¯¾è±¡ã®åˆ—åã€‚
                output_column (str): æ–°ã—ãä½œæˆã™ã‚‹åˆ—åã€‚
                leadtime (int): ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆç¨¼åƒãƒ•ãƒ©ã‚°ãŒ1ã®è¡Œã‚’é€²ã‚ã‚‹æ•°ï¼‰ã€‚

            Returns:
                pd.DataFrame: å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
            """
            # æ–°ã—ã„åˆ—ã‚’åˆæœŸåŒ–
            df[output_column] = 0

            # target_columnãŒ0ä»¥å¤–ã®è¡Œã‚’å‡¦ç†
            for idx, row in df.iterrows():
                if row[target_column] != 0:
                    base_time = row['æ—¥æ™‚']
                    base_value = row[target_column]

                    # ç¨¼åƒãƒ•ãƒ©ã‚°ãŒ1ã®è¡Œã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦é€²ã‚€
                    subset = df[(df['æ—¥æ™‚'] > base_time)]
                    active_rows = subset[subset['ç¨¼åƒãƒ•ãƒ©ã‚°'] == 1]

                    if len(active_rows) >= leadtime:
                        target_row = active_rows.iloc[leadtime - 1]
                        df.at[target_row.name, output_column] = base_value

            return df
        
        #! ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰ï¼ˆå¾Œã®å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼‰ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
        #! Whatï¼šå…¥åº«ã‹ã‚“ã°ã‚“æ•°ã¨ç´å…¥ã‹ã‚“ã°ã‚“æ•°ã®é–“ã§ç›¸é–¢ãŒç”Ÿã¾ã‚Œã‚‹ã‚ˆã†ã«æ™‚é–“é…ã‚Œã‚’è€ƒæ…®ã—ãŸç´å…¥ã‹ã‚“ã°ã‚“æ•°ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
        #! Resultï¼š'ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰'åˆ—ã‚’è¿½åŠ 
        def calculate_delivery_kanban_with_time_delay(row, df, delivery_column, target_column, lead_time=5):

            """
            ç´å…¥ã‹ã‚“ã°ã‚“æ•°ã®æ™‚é–“é…ã‚Œã‚’è¨ˆç®—ã™ã‚‹æ±ç”¨é–¢æ•°ã€‚

            ã“ã®é–¢æ•°ã¯ã€æŒ‡å®šã•ã‚ŒãŸãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã¨ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’åŸºã«ç´å…¥ã‹ã‚“ã°ã‚“æ•°ã‚’å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ã«å¤‰æ›ã—ã€
            ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®è©²å½“ã™ã‚‹è¡Œã«å€¤ã‚’åŠ ç®—ã™ã‚‹ã€‚

            Args:
                row (pd.Series): ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®è¡Œãƒ‡ãƒ¼ã‚¿ã€‚
                df (pd.DataFrame): å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
                delivery_column (str): ç´å…¥ã‹ã‚“ã°ã‚“æ•°ã‚’æŒã¤åˆ—åã€‚
                target_column (str): å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ã‚’æ›´æ–°ã™ã‚‹åˆ—åã€‚
                lead_time (int): åŸºæœ¬ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆæ™‚é–“å˜ä½ï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯5æ™‚é–“ã€‚

            Returns:
                None: å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ãŒæ›´æ–°ã•ã‚Œã‚‹ãŒã€æ˜ç¤ºçš„ãªæˆ»ã‚Šå€¤ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
            """

            current_time = row['æ—¥æ™‚']
            kanban_count = row[delivery_column]

            # ç´å…¥ã‹ã‚“ã°ã‚“æ•°ãŒ0ã®å ´åˆã¯è¨ˆç®—ã›ãšçµ‚äº†
            if kanban_count == 0:
                return None
            
            # ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚’å››æ¨äº”å…¥ã—ã€æ•´æ•°ã«å¤‰æ›
            lead_time = int(round(lead_time))

            # 5æ™‚é–“åˆ†ã®ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’å–å¾—
            end_time = current_time + pd.Timedelta(hours=lead_time)
            subset = df[(df['æ—¥æ™‚'] > current_time) & (df['æ—¥æ™‚'] <= end_time)]
            
            # ç¨¼åƒãƒ•ãƒ©ã‚°ãŒ0ã®å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            zero_flag_count = subset[subset['ç¨¼åƒãƒ•ãƒ©ã‚°'] == 0].shape[0]
            
            # å®Ÿéš›ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚’è¨ˆç®—
            adjusted_lead_time = lead_time + zero_flag_count
            delivery_time = current_time + pd.Timedelta(hours=adjusted_lead_time)
            
            # ç´å…¥æ™‚åˆ»ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç¯„å›²å¤–ãªã‚‰ç´å…¥ã‹ã‚“ã°ã‚“æ•°ã¯æ›´æ–°ã—ãªã„
            if delivery_time in df['æ—¥æ™‚'].values:
                delivery_index = df[df['æ—¥æ™‚'] == delivery_time].index[0]
                df.at[delivery_index, target_column] += kanban_count

            return None
        
        #todo è‡¨æ™‚è¨ˆç®—ã€ç™ºæ³¨å…¥åº«Ltã‚’éç¨¼åƒæ™‚é–“å‰Šé™¤ã§è¨ˆç®—ã™ã‚‹ã¾ã§ã®é–“
        def calculate_best_kanban_with_delay(df):
            """
            å…¥åº«ã‹ã‚“ã°ã‚“æ•°ãŒ0ã§ãªã„ã¨ãã€å‰å¾Œ2æ™‚é–“ã®æœ€å¤§å€¤ã‚’æ–°ã—ã„åˆ—ã«æ ¼ç´ã—ã¾ã™ã€‚

            Args:
                df (pd.DataFrame): å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚

            Returns:
                pd.DataFrame: çµæœã‚’æ ¼ç´ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
            """

            df['æ—¥æ™‚'] = pd.to_datetime(df['æ—¥æ™‚'])
            df.set_index('æ—¥æ™‚', inplace=True)

            # æ–°ã—ã„åˆ—ã‚’åˆæœŸåŒ–
            df['ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰'] = 0
            #df['ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œ'] = 0

            # å„è¡Œã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦å‡¦ç†
            for idx, row in df.iterrows():
                if row['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] != 0:
                    # å‰å¾Œ2æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                    start_time = idx - pd.Timedelta(hours=2)
                    end_time = idx + pd.Timedelta(hours=2)
                    window_df = df[(df.index >= start_time) & (df.index <= end_time)]
                    
                    # ã€Œç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°bestã€ã¨ã„ã†æ–‡å­—åˆ—ã‚’å«ã‚€åˆ—ã®æœ€å¤§å€¤ã‚’è¨ˆç®—
                    order_cols = [col for col in df.columns if "ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°best" in col]
                    if order_cols:
                        max_order = window_df[order_cols].max().max()
                        df.at[idx, 'ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰'] = max_order

                    # ã€Œç´å…¥ã‹ã‚“ã°ã‚“æ•°bestã€ã¨ã„ã†æ–‡å­—åˆ—ã‚’å«ã‚€åˆ—ã®æœ€å¤§å€¤ã‚’è¨ˆç®—
                    #delivery_cols = [col for col in df.columns if "ç´å…¥ã‹ã‚“ã°ã‚“æ•°best" in col]
                    #if delivery_cols:
                        #max_delivery = window_df[delivery_cols].max().max()
                        #df.at[idx, 'ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œ'] = max_delivery

            return df.reset_index()

        #! å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã®è£œæ­£
        def adjust_time_based_on_scheduled_incoming_kanban(df):

            """
            å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã‚’åŸºã«ç‰¹å®šã®æ¡ä»¶ã§è£œæ­£ã‚’è¡Œã†é–¢æ•°ã€‚

            Args:
                df (pd.DataFrame): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
                                å¿…é ˆåˆ—:
                                - "å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"
                                - "å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"
                                - "ç¨¼åƒãƒ•ãƒ©ã‚°"
                                - "æ™‚é–“"

            Returns:
                pd.DataFrame: è£œæ­£å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆæ–°ã—ã„åˆ— "å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ" ã‚’è¿½åŠ ï¼‰ã€‚
            """

            # è£œæ­£çµæœã‚’è¨˜éŒ²ã™ã‚‹æ–°ã—ã„åˆ—ã‚’åˆæœŸåŒ–
            df['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ'] = 0

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å„è¡Œã‚’é †ç•ªã«å‡¦ç†
            for idx, row in df.iterrows():
                # ã€Œå…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã€ãŒ0ã§ãªã„è¡Œã‚’å¯¾è±¡ã¨ã™ã‚‹
                if row['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] != 0:
                    # ç¾åœ¨ã®è¡Œã‚ˆã‚Šå‰ã§ã€Œç¨¼åƒãƒ•ãƒ©ã‚°ã€ãŒ1ã®è¡Œã‚’å–å¾—
                    # todoã€€ã€é‡è¦ï¼ã€‘ãªãœ3ã«è¨­å®šã—ã¦ã„ã‚‹ã‹ï¼Ÿ
                    # todo å…¥åº«ã‹ã‚“ã°ã‚“æ•°ãŒå…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ã‚ˆã‚Šæ—©ã„ã“ã¨ãŒã‚ã‚‹
                    # todo 17æ™‚18å€‹å…¥åº«ã€18æ™‚39å€‹å…¥åº«ã€19æ™‚1å€‹å…¥åº«ã¿ãŸã„ãªã‚±ãƒ¼ã‚¹ãŒã‚ã‚Šã€tail(1)ã ã¨ã€19æ™‚å…¥åº«äºˆå®šã«è£œæ­£ã•ã‚Œã‚‹
                    # todo ä¾‹ï¼šå“ç•ª351710LC010_1Zã€24å¹´5æœˆ9æ—¥17æ™‚
                    before_active = df[(df.index < idx) & (df['ç¨¼åƒãƒ•ãƒ©ã‚°'] == 1)].tail(4)

                    # ç¾åœ¨ã®è¡Œã‚ˆã‚Šå¾Œã§ã€Œç¨¼åƒãƒ•ãƒ©ã‚°ã€ãŒ1ã®è¡Œã‚’å–å¾—
                    after_active = df[(df.index > idx) & (df['ç¨¼åƒãƒ•ãƒ©ã‚°'] == 1)].head(1)

                    # ç¾åœ¨ã®è¡Œã‚’å«ã‚ã¦å‰å¾Œã®ç¨¼åƒè¡Œã‚’çµåˆ
                    current_row = df.loc[[idx]]
                    active_rows = pd.concat([before_active, current_row, after_active])

                    # ã€Œå…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã€åˆ—ã®å€¤ã‚’ç¢ºèª
                    if active_rows['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'].sum() == 0:
                        # ã™ã¹ã¦ã®å€¤ãŒ0ã®å ´åˆã€ç¾åœ¨ã®è¡Œã®ã€Œå…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆã€ã«å€¤ã‚’è¨­å®š
                        df.at[idx, 'å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ'] = row['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰']
                    else:
                        # 0ä»¥å¤–ã®å€¤ãŒå«ã¾ã‚Œã‚‹å ´åˆã€æœ€åˆã®é0è¡Œã‚’è¦‹ã¤ã‘ã€ãã®è¡Œã«å€¤ã‚’è¨­å®š
                        first_non_zero = active_rows[active_rows['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] != 0].head(1)
                        if not first_non_zero.empty:
                            first_non_zero_idx = first_non_zero.index[0]
                            df.at[first_non_zero_idx, 'å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ'] = row['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰']

            return df
        
        #! æ»ç•™ã‹ã‚“ã°ã‚“ã®æ™‚é–“å¤‰åŒ–ã‚’è€ƒæ…®
        def update_tairyukanban_by_considering_time_changes(df):

            """
            æ»ç•™ã‹ã‚“ã°ã‚“æ•°ã‚’æ›´æ–°ã—ã€å¤‰åŒ–ã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã«æ»ç•™ã‹ã‚“ã°ã‚“æ•°_beforeã¨æ»ç•™ã‹ã‚“ã°ã‚“æ•°_afterã‚’å‡ºåŠ›ã—ã¾ã™ã€‚
            æ»ç•™ã‹ã‚“ã°ã‚“æ•°ãŒ0æœªæº€ã®å ´åˆã¯ã€0ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã™ã€‚
            """

            df["è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®"] = df["è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"].copy()
            
            for i in range(1, len(df)):
                df.loc[i, "è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®"] = max(
                    0,
                    df.loc[i - 1, "è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®"]
                    + df.loc[i, "è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"]
                    - df.loc[i, "å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"]
                )
            return df

        #! å‡ºåº«æ•°ã‚’è€ƒæ…®ã—ã¦ç”Ÿç”£å°æ•°_å‡ºåº«æ•°è€ƒæ…®ã‚’è¨ˆç®—ã™ã‚‹
        def calculate_production_considering_shipment(df):
            """
            å‡ºåº«æ•°ã‚’è€ƒæ…®ã—ã¦ç”Ÿç”£å°æ•°_å‡ºåº«æ•°è€ƒæ…®ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã€‚
            å‡ºåº«æ•°ãŒ0ã®å ´åˆã€ç”Ÿç”£å°æ•°ã‚’è“„ç©ã™ã‚‹ãŒã€å‡ºåº«æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã¯ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã€‚

            å¼•æ•°:
            df : DataFrame
                ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆæ—¥æ™‚åˆ—ã€å‡ºåº«æ•°ã€ç”Ÿç”£å°æ•°ã‚’å«ã‚€ï¼‰

            æˆ»ã‚Šå€¤:
            DataFrame
                ã€Œç”Ÿç”£å°æ•°_å‡ºåº«æ•°è€ƒæ…®ã€ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            """
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
            df = df.copy()
            
            # æ–°ã—ã„åˆ—ã‚’åˆæœŸåŒ–
            df["è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_å‡ºåº«æ•°è€ƒæ…®"] = 0
            df["è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡æ¸ˆ_å‡ºåº«æ•°è€ƒæ…®"] = 0.0
            
            # ç´¯ç©å¤‰æ•°ã‚’åˆæœŸåŒ–
            cumulative_production = 0
            cumulative_utilization = 0

            #ã‚«ã‚¦ãƒ³ãƒˆç”¨
            count = 0

            for idx in df.index:
                cumulative_production += df.loc[idx, "è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ"]
                cumulative_utilization += df.loc[idx, "è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡æ¸ˆ"]
                count += 1

                df.loc[idx, "è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_å‡ºåº«æ•°è€ƒæ…®"] = cumulative_production
                df.loc[idx, "è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡æ¸ˆ_å‡ºåº«æ•°è€ƒæ…®"] = cumulative_utilization / count if count > 0 else 0

                if df.loc[idx, "å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"] > 0 and idx + 1 in df.index:
                    # å‡ºåº«æ•°ãŒ1ä»¥ä¸Šã®å ´åˆã€ãƒªã‚»ãƒƒãƒˆ
                    cumulative_production = 0
                    cumulative_utilization = 0
                    count = 0

            return df
        
        #! å‡ºåº«ã‹ã‚“ã°ã‚“æ•°åˆ—ãŒ0ã§ãªã„è¡Œã®é–“éš”ã®ä¸­å¤®å€¤ã‚’è¨ˆç®—ã™ã‚‹
        def calculate_median_interval(df):
            """
            å‡ºåº«ã‹ã‚“ã°ã‚“æ•°åˆ—ãŒ0ã§ãªã„è¡Œã®é–“éš”ã®ä¸­å¤®å€¤ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã€‚
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆæ—¥æ™‚åˆ—ã¨å‡ºåº«ã‹ã‚“ã°ã‚“æ•°åˆ—ã‚’å«ã‚€ï¼‰
            """
            # å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ãŒ0ã§ãªã„è¡Œç•ªå·ã‚’æŠ½å‡º
            non_zero_indices = df[df["å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰"] != 0].index
            
            # è¡Œç•ªå·ã®å·®ã‚’è¨ˆç®—
            row_intervals = non_zero_indices.to_series().diff().dropna()
            
            # è¡Œç•ªå·ã®å·®ã®ä¸­å¤®å€¤ã‚’è¨ˆç®—
            median_row_interval = row_intervals.median()
            
            return median_row_interval
        
        median_interval_syuko = calculate_median_interval(lagged_features)

        #st.header("å‡ºåº«ã®é–“éš”ï¼ˆè¡Œæ•°ï¼‰")
        #st.write(median_interval_syuko)

        if nonyu_type == 'è¥¿å°¾æ±':
            nonyu_lt = 5
        else:
            nonyu_lt = 0

        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! Resultï¼šå…¥åº«ã‹ã‚“ã°ã‚“æ•°ã«åˆã‚ã›ãŸã€Œç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰ã€åˆ—ã®è¿½åŠ 
        # ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰åˆ—ã‚’åˆæœŸåŒ–
        #lagged_features['ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰'] = 0
        #lagged_features['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰'] = 0
        #st.dataframe(lagged_features)
        # ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰åˆ—ã‚’æ›´æ–°
        #lagged_features.apply(lambda row: calculate_delivery_kanban_with_time_delay(row, lagged_features, delivery_column='ç´å…¥ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰', target_column='ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰', lead_time=5), axis=1)
        # ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰åˆ—ã‚’æ›´æ–°
        #lagged_features.apply(lambda row: calculate_delivery_kanban_with_time_delay(row, lagged_features, delivery_column='ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰', target_column='ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰', lead_time=5), axis=1)
        lagged_features = shift_with_leadtime(lagged_features, target_column='ç´å…¥ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰', output_column='ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰', leadtime=nonyu_lt)
        lagged_features = shift_with_leadtime(lagged_features, target_column='ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰', output_column='ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰', leadtime=nonyu_lt)
        lagged_features = shift_with_leadtime(lagged_features, target_column='ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ_è£œæ­£', output_column='ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ_è£œæ­£_æ™‚é–“é…ã‚Œ', leadtime=nonyu_lt)
        display_message(f"**ç´å…¥ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã€ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã€ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ_è£œæ­£ã®æ™‚é–“é…ã‚Œã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚**")
        st.dataframe(lagged_features)

        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! Resultï¼šã€Œå…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã€åˆ—ã€ã€Œå…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£ã€åˆ—ã®è¿½åŠ 
        # # å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°åˆ—ã«ç´å…¥ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰ã®å€¤ã‚’ã‚³ãƒ”ãƒ¼
        lagged_features['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = lagged_features['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰']

        #! å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆã®è¨ˆç®—
        lagged_features = adjust_time_based_on_scheduled_incoming_kanban(lagged_features)

        #!
        lagged_features['è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = lagged_features['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ'] - lagged_features['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰']
        # ãƒã‚¤ãƒŠã‚¹å€¤ã‚’0ã«å¤‰æ›´
        lagged_features.loc[lagged_features['è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] < 0, 'è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = 0

        #todo ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã«ã¤ã„ã¦ã¯ç¨¼åƒæ™‚é–“æŠœãã®æ­£ç¢ºãªãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãŒã‚ã‹ã‚‰ãªã„ãŸã‚ä»Šã¯å‰ã®ã‚„ã¤ã‚’æµç”¨
        #lagged_features['ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰']=0
        #lagged_features.apply(lambda row: calculate_delivery_kanban_with_time_delay(row, lagged_features, delivery_column='ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰', target_column='ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰', lead_time=median_lt_order), axis=1)
        #todo ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°
        #lagged_features = adjust_time_based_on_incoming_kanban(lagged_features, target_column="ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰")

        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! Resultï¼šè¥¿å°¾æ±oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰åˆ—ã‚’è¿½åŠ 
        #! Whatï¼›å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰- â˜…å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰ã®å‰å¾Œ1æ™‚é–“ã®åˆè¨ˆâ˜…â€»å‰å¾Œ1æ™‚é–“ã®åˆè¨ˆãŒãƒã‚¤ãƒ³ãƒˆ
        #lagged_features = calculate_tairyukanban(lagged_features, target_column="å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰")
        
        #todo ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œè¨ˆç®—
        lagged_features = calculate_best_kanban_with_delay(lagged_features)

        #todo ç´å…¥ãƒ•ãƒ¬æ•°ã‚’è¨ˆç®—
        #lagged_features['ç´å…¥ãƒ•ãƒ¬æ•°ï¼ˆtï¼‰'] = lagged_features['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£'] - lagged_features['ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰']
        lagged_features['ç´å…¥ãƒ•ãƒ¬æ•°ï¼ˆtï¼‰'] = lagged_features['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ'] - lagged_features['ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰']

        # æ–°ã—ã„åˆ—ã‚’ä½œæˆã—ã€äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ã‚’è¨ˆç®—
        lagged_features['å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = 0
        lagged_features.loc[lagged_features['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] != 0, 'å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = (
            lagged_features['å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] - lagged_features['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ']
        )
        # ãƒã‚¤ãƒŠã‚¹å€¤ã‚’0ã«å¤‰æ›´
        lagged_features.loc[lagged_features['å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] < 0, 'å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] = 0
        
        #! æ»ç•™ã‹ã‚“ã°ã‚“ã®æ™‚é–“å¤‰åŒ–ã‚’è€ƒæ…®
        lagged_features = update_tairyukanban_by_considering_time_changes(lagged_features)
    
        #! lagged_featuresã«å¤‰æ•°è¿½åŠ 
        #! "è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_å‡ºåº«æ•°è€ƒæ…®"åˆ—ã€"è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡æ¸ˆ_å‡ºåº«æ•°è€ƒæ…®"åˆ—ã‚’è¿½åŠ 
        #lagged_features = calculate_production_considering_shipment(lagged_features)

        # å®Ÿè¡Œçµæœã®ç¢ºèª
        columns_to_display = ['æ—¥æ™‚','ç¨¼åƒãƒ•ãƒ©ã‚°','ç´å…¥ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰','ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰','å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰','å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰','å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ',
                               'å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰','è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰',
                               'è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®']
        display_message(f"**è¥¿å°¾æ±Bcï½éƒ¨å“ç½®ãå ´ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ãªã©ã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚**")
        st.dataframe(lagged_features[columns_to_display])

        #! é–“å£ã®å……è¶³ç‡ã‚’è¨ˆç®—
        lagged_features[f'é–“å£A1ã®å……è¶³ç‡'] = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰åˆè¨ˆ_A1']/2592
        lagged_features[f'é–“å£A2ã®å……è¶³ç‡'] = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰åˆè¨ˆ_A2']/1668
        lagged_features[f'é–“å£B1ã®å……è¶³ç‡'] = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰åˆè¨ˆ_B1']/827
        lagged_features[f'é–“å£B2ã®å……è¶³ç‡'] = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰åˆè¨ˆ_B2']/466
        lagged_features[f'é–“å£B3ã®å……è¶³ç‡'] = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰åˆè¨ˆ_B3']/330
        lagged_features[f'é–“å£B4ã®å……è¶³ç‡'] = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰åˆè¨ˆ_B4']/33
        lagged_features[f'å…¨é–“å£ã®å¹³å‡å……è¶³ç‡'] = (
            lagged_features[f'é–“å£A1ã®å……è¶³ç‡'] +
            lagged_features[f'é–“å£A2ã®å……è¶³ç‡'] + 
            lagged_features[f'é–“å£B1ã®å……è¶³ç‡'] + 
            lagged_features[f'é–“å£B2ã®å……è¶³ç‡'] + 
            lagged_features[f'é–“å£B3ã®å……è¶³ç‡'] + 
            lagged_features[f'é–“å£B4ã®å……è¶³ç‡'])/6
        #!ã„ãšã‚Œã‹ãŒ0.95ã‚’è¶…ãˆãŸå ´åˆã«1ã«è¨­å®š
        lagged_features['æŠ•å…¥é–“å£ã®æ¸‹æ»åˆ¤å®šãƒ•ãƒ©ã‚°'] = (
            (lagged_features['é–“å£A1ã®å……è¶³ç‡'] > 0.95) |
            (lagged_features['é–“å£A2ã®å……è¶³ç‡'] > 0.95) |
            (lagged_features['é–“å£B1ã®å……è¶³ç‡'] > 0.95) |
            (lagged_features['é–“å£B2ã®å……è¶³ç‡'] > 0.95) |
            (lagged_features['é–“å£B3ã®å……è¶³ç‡'] > 0.95) |
            (lagged_features['é–“å£B4ã®å……è¶³ç‡'] > 0.95)
        ).astype(int)
        display_message(f"**æŠ•å…¥é–“å£ã®æ¸‹æ»åˆ¤å®šã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚**")
        st.dataframe(lagged_features)

        #todo---------------------------------------------------------------------------------------------------------------------------
    
        # å®Ÿè¡Œçµæœã®ç¢ºèª
        # å„å¤‰æ•°ã®ç›¸é–¢ã‚’èª¿ã¹ã‚‹
        #? ç›®çš„é–¢æ•°ã‚’ã©ã®ã‚ˆã†ã«è¨­è¨ˆã™ã¹ãã‹ï¼Ÿ
        
        # ï¼œçµè«–ï¼
        # è¨­è¨ˆæ¡ˆ2ã®æ–¹ãŒæ»ç•™ã‹ã‚“ã°ã‚“æ•°ã¨ã®ç›¸é–¢ãŒå‡ºã‚‹ã®ã§ã€2ã‚’æ¡ç”¨
        
        #* ï¼œç›®çš„é–¢æ•°ã®è¨­è¨ˆæ¡ˆï¼‘ï¼
        # å…¨ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®ä¸­å¤®å€¤ã«å¯¾ã™ã‚‹ã‚ºãƒ¬
        #lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬'] = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] - lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].median()
        # å®Ÿè¡Œçµæœã®ç¢ºèª
        #st.write(lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].median())

        #* ï¼œç›®çš„é–¢æ•°ã®è¨­è¨ˆæ¡ˆï¼’ï¼
        #ã€€å„æ™‚ç‚¹ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰ã‹ã‚‰åŒã˜æ™‚åˆ»ï¼ˆä¾‹: 0æ™‚ã€1æ™‚ï¼‰ã®ä¸­å¤®å€¤ã‚’å¼•ã„ãŸå€¤

        #! æ™‚é–“å¸¯ã”ã¨ã®ç®±ã²ã’å›³
        def plot_box_by_hour(dataframe, value_col, time_col):
            """
            æ™‚é–“å¸¯ã”ã¨ã®ç®±ã²ã’å›³ã‚’ä½œæˆã™ã‚‹é–¢æ•°ã€‚

            Parameters:
            - dataframe: pd.DataFrame - ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            - value_col: str - ç®±ã²ã’å›³ã«ä½¿ç”¨ã™ã‚‹å€¤ã®åˆ—å
            - time_col: str - æ™‚é–“å¸¯ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹åˆ—åï¼ˆæ—¥æ™‚åˆ—ï¼‰
            """
            # 'æ™‚é–“'åˆ—ã‚’ä½œæˆ
            dataframe['Hour'] = pd.to_datetime(dataframe[time_col]).dt.hour

            # ç®±ã²ã’å›³ã‚’ä½œæˆ
            fig = px.box(
                dataframe,
                x='Hour',
                y=value_col,
                title=f"{value_col}ã®æ™‚é–“å¸¯åˆ¥ç®±ã²ã’å›³",
                labels={'Hour': 'æ™‚é–“', value_col: value_col},
                points="all"  # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚‚è¡¨ç¤º
            )

            # Streamlitã§è¡¨ç¤º
            st.plotly_chart(fig, use_container_width=True)

        #! 'Hour'åˆ—ã‚’ä½œæˆ
        lagged_features['Hour'] = pd.to_datetime(lagged_features['æ—¥æ™‚']).dt.hour

        #! å„æ™‚é–“å¸¯ã®ä¸­å¤®å€¤ã‚’å¼•ã„ãŸæ–°ã—ã„åˆ—ã‚’ä½œæˆ
        lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬'] = (
            lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] - 
            lagged_features.groupby('Hour')['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].transform('median')
        )
        st.header("test")
        st.dataframe(lagged_features.groupby('Hour')['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].transform('median'))
        lagged_features['ã„ã¤ã‚‚ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰'] = lagged_features.groupby('Hour')['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].transform('median')
        column = ['æ—¥æ™‚','ã„ã¤ã‚‚ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰']
        basezaiko_data = lagged_features[column]
        basezaiko_data.to_csv('temp/ã„ã¤ã‚‚ã®åœ¨åº«æ•°.csv', index=False, encoding='shift_jis')
        st.dataframe(basezaiko_data)

        # å®Ÿè¡Œçµæœã®ç¢ºèª
        # åœ¨åº«æ•°ã®ç®±ã²ã’å›³ç¢ºèª
        plot_box_by_hour(dataframe=lagged_features, value_col='åœ¨åº«æ•°ï¼ˆç®±ï¼‰', time_col='æ—¥æ™‚')
        # å„æ™‚é–“å¸¯ã®ä¸­å¤®å€¤ã‚’è¨ˆç®—
        hourly_median = lagged_features.groupby('Hour')['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].median()
        # å„æ™‚é–“ã®ä¸­å¤®å€¤ã‚’ç¢ºèª
        st.write(hourly_median)

        #todo ä¸Šã«ä¸€ã¤ç§»å‹•ã™ã‚‹å‡¦ç†
        # 16æ™‚ã«åœ¨åº«10å€‹ã€å…¥åº«ã‹ã‚“ã°ã‚“æ•°ãŒ20å€‹ã ã‹ã‚‰ã€17æ™‚ã®åœ¨åº«ãŒ30å€‹ã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã«ãªã£ã¦ã„ã‚‹
        lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬'] = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬'].shift(-1)

        # ã“ã“ã¾ã§ã§ä½œæˆã—ãŸå¤‰æ•°
        # 'è¥¿å°¾æ±oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®'
        # 'è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ'

        # lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬'] = lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ'] - lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ'].median()

        # lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬'] = (
        #     lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ'] - 
        #     lagged_features.groupby('Hour')['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ'].transform('median')
        # )

        lagged_features['å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬'] = (
            lagged_features['å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'] - 
            lagged_features.groupby('Hour')['å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰'].transform('median')
        )

        #lag_end = 24*5*2 #ã€‡å‰ã‹ã‚‰
        #lag_start = 24*5 #â–³è¡Œå€‹
        # lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_é•·æœŸéå»è¦å› '] = (
        #     lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ']
        #     .shift(lag_end)
        #     .rolling(window=lag_start, min_periods=lag_start)  # 6è¡Œåˆ†ï¼ˆ5è¡Œç›®ã‹ã‚‰10è¡Œç›®ã¾ã§ï¼‰ã‚’å¯¾è±¡ã«åˆè¨ˆ
        #     .sum()
        # )

        def calculate_flag_based_sum(df, target_col,output_column, flag_col, lag_past_count, lag_future_count):
            """
            ç¨¼åƒãƒ•ãƒ©ã‚°åˆ—ã‚’åŸºæº–ã¨ã—ã¦éå»ã«lag_past_countè¡Œã€æœªæ¥ã«lag_future_countè¡Œã‚’æ¢ã—ã€
            æŒ‡å®šã•ã‚ŒãŸåˆ—ã®åˆè¨ˆã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã€‚
            
            Args:
                df (pd.DataFrame): å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚
                target_col (str): åˆè¨ˆã‚’è¨ˆç®—ã™ã‚‹å¯¾è±¡åˆ—åã€‚
                flag_col (str): ç¨¼åƒãƒ•ãƒ©ã‚°åˆ—ã®åˆ—åï¼ˆ1ã¾ãŸã¯0ã®å€¤ï¼‰ã€‚
                lag_past_count (int): éå»æ–¹å‘ã«æ¢ã™ç¨¼åƒãƒ•ãƒ©ã‚°1ã®è¡Œæ•°ã€‚
                lag_future_count (int): ç¾åœ¨ã®è¡Œæ–¹å‘ã«æ¢ã™ç¨¼åƒãƒ•ãƒ©ã‚°1ã®è¡Œæ•°ã€‚

            Returns:
                pd.DataFrame: å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆæ–°ã—ã„åˆ—ã‚’è¿½åŠ ï¼‰ã€‚
            """
            result = []  # è¨ˆç®—çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å…¨è¡Œã‚’å¯¾è±¡ã«ã€lag_past_countè¡Œã¾ã§é¡ã‚‹å‡¦ç†ã‚’è¡Œã†
            for i in range(lag_past_count, len(df)):
                # 1. ç¾åœ¨ã®è¡Œ`i`ã®lag_past_countè¡Œå‰ã¾ã§ã‚’å–å¾—ï¼ˆéå»æ–¹å‘ï¼‰
                past_rows = df.iloc[:i][flag_col]  # ç¾åœ¨ã®è¡Œã‹ã‚‰éå»ã®è¡Œã®ç¨¼åƒãƒ•ãƒ©ã‚°åˆ—ã‚’å–å¾—

                # 2. ç¨¼åƒãƒ•ãƒ©ã‚°ãŒ1ã®è¡Œã‚’éå»æ–¹å‘ã«lag_past_countå€‹è¦‹ã¤ã‘ã‚‹
                past_indices = past_rows[past_rows == 1].index[-lag_past_count:]  # ç¨¼åƒãƒ•ãƒ©ã‚°1ã®è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

                if len(past_indices) < lag_past_count:
                    # ç¨¼åƒãƒ•ãƒ©ã‚°1ãŒæŒ‡å®šæ•°è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è¨ˆç®—ã›ãšæ¬¡ã¸
                    result.append(None)
                    continue

                # 3. éå»æ–¹å‘ã®lag_past_countè¡Œè¦‹ã¤ã‹ã£ãŸã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹ã‚’å–å¾—
                start_index = past_indices[0]

                # 4. æœªæ¥æ–¹å‘ã«lag_future_countè¡Œã®ç¨¼åƒãƒ•ãƒ©ã‚°1ã‚’æ¢ã™
                future_rows = df.iloc[start_index:i][flag_col]  # ã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹ã‹ã‚‰ç¾åœ¨è¡Œæ–¹å‘ã¸ç¨¼åƒãƒ•ãƒ©ã‚°ã‚’æ¢ç´¢
                future_indices = future_rows[future_rows == 1].index[:lag_future_count]  # æœªæ¥æ–¹å‘ã«ç¨¼åƒãƒ•ãƒ©ã‚°1ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—

                if len(future_indices) < lag_future_count:
                    # ç¨¼åƒãƒ•ãƒ©ã‚°1ãŒæŒ‡å®šæ•°è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è¨ˆç®—ã›ãšæ¬¡ã¸
                    result.append(None)
                    continue

                # 5. æœªæ¥æ–¹å‘ã®lag_future_countè¡Œåˆ†ã®ç¯„å›²ã§åˆè¨ˆã‚’è¨ˆç®—
                sum_value = df.loc[future_indices, target_col].sum()  # åˆè¨ˆã‚’è¨ˆç®—
                result.append(sum_value)  # è¨ˆç®—çµæœã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 

            # 6. çµæœãƒªã‚¹ãƒˆã®å…ˆé ­ã«`NaN`ã‚’lag_past_countå€‹è¿½åŠ ã—ã€å…¨ä½“ã®è¡Œæ•°ã‚’æƒãˆã‚‹
            result = [None] * lag_past_count + result  # éå»æ–¹å‘ã«é¡ã‚‹æ•°åˆ†ã ã‘`None`ã‚’è¿½åŠ 

            df[output_column] = result
            return df
        
        #! è¨ˆç”»ç”Ÿç”£å°æ•°_é•·æœŸéå»è¦å› 
        lag_past_count_value = (int(WWWW)+kanban_kaiten_nissu)*24 #24*kanban_kaiten_nissu*3
        lag_future_count_value = (int(WWWW))*24#24*kanban_kaiten_nissu*2
        st.write(lag_past_count_value)
        lagged_features = calculate_flag_based_sum(lagged_features,
                                                   target_col='æ—¥é‡æ•°',output_column='è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_é•·æœŸéå»è¦å› ',
                                                     flag_col='ç¨¼åƒãƒ•ãƒ©ã‚°',lag_past_count = lag_past_count_value, lag_future_count = lag_future_count_value)

        # lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_é•·æœŸéå»è¦å› '] = (
        #     lagged_features['æ—¥é‡æ•°']
        #     .shift(lag_past_count_value)
        #     .rolling(window=lag_future_count_value, min_periods=lag_future_count_value)  # 6è¡Œåˆ†ï¼ˆ5è¡Œç›®ã‹ã‚‰10è¡Œç›®ã¾ã§ï¼‰ã‚’å¯¾è±¡ã«åˆè¨ˆ
        #     .sum()
        # )

        fig = px.line(lagged_features, x='æ—¥æ™‚', y='æ—¥é‡æ•°', title='æ—¥ä»˜ã”ã¨ã®æ•°é‡æ¨ç§»', markers=True)
        st.plotly_chart(fig)
        st.dataframe(lagged_features)
        
        # æ—¥ä»˜ã”ã¨ã®å¹³å‡å€¤è¨ˆç®—
        lagged_features['æ—¥ä»˜'] = lagged_features['æ—¥æ™‚'].dt.date  # æ—¥ä»˜åˆ—ã‚’è¿½åŠ 
        mean_values = lagged_features.groupby('æ—¥ä»˜')['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_é•·æœŸéå»è¦å› '].transform('mean')  # åŒã˜æ—¥ä»˜ã”ã¨ã®å¹³å‡å€¤
        # å€¤ã‚’æ—¥ä»˜ã”ã¨ã®å¹³å‡å€¤ã«ç½®ãæ›ãˆ
        lagged_features['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_é•·æœŸéå»è¦å› '] = mean_values
        
        
        #è¨ˆç”»ç”Ÿç”£å°æ•°ã¯åœ¨åº«å¢—ã€æ¸›ä¸¡æ–¹ã«é–¢ä¿‚ã™ã‚‹è¦å› 

        from plotly.subplots import make_subplots

        #!ã€€æ•£å¸ƒå›³ã¨ç›¸é–¢ä¿‚æ•°ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
        def scatter_and_correlation(dataframe, x_col, y_col):

            """
            æ•£å¸ƒå›³ã‚’ä½œæˆã—ã€ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤ºã™ã‚‹é–¢æ•°ã€‚

            Parameters:
            - dataframe: pd.DataFrame - å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            - x_col: str - æ•£å¸ƒå›³ã®xè»¸ã«ä½¿ç”¨ã™ã‚‹åˆ—å
            - y_col: str - æ•£å¸ƒå›³ã®yè»¸ã«ä½¿ç”¨ã™ã‚‹åˆ—å
            """

            # ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
            correlation = dataframe[x_col].corr(dataframe[y_col])

            # æ•£å¸ƒå›³ã‚’ä½œæˆ
            fig = px.scatter(
                dataframe,
                x=x_col,
                y=y_col,
                title=f"{x_col} vs {y_col}",
                labels={x_col: x_col, y_col: y_col}
                #trendline="ols"  # å›å¸°ç›´ç·šã‚’è¿½åŠ 
            )

            # 2. æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
            time_col = 'æ—¥æ™‚'
            fig_time_series = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1,
                                            subplot_titles=(f"{x_col} Over Time", f"{y_col} Over Time"))

            # ä¸Šæ®µãƒ—ãƒ­ãƒƒãƒˆ (X)
            fig_time_series.add_trace(
                go.Scatter(x=dataframe[time_col], y=dataframe[x_col], mode='lines+markers', name=x_col),
                row=1, col=1
            )

            # ä¸‹æ®µãƒ—ãƒ­ãƒƒãƒˆ (Y)
            fig_time_series.add_trace(
                go.Scatter(x=dataframe[time_col], y=dataframe[y_col], mode='lines+markers', name=y_col),
                row=2, col=1
            )


            # ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’èª¿æ•´
            fig.update_layout(
                width=1200,  # å¹…
                height=600  # é«˜ã•
            )

            # ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’èª¿æ•´
            fig_time_series.update_layout(
                width=1200,  # å¹…
                height=600  # é«˜ã•
            )

            # Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†…ã§è¡¨ç¤º
            st.plotly_chart(fig)
            st.write(f"ç›¸é–¢ä¿‚æ•°: {correlation:.2f}")

            st.plotly_chart(fig_time_series, use_container_width=True)

        # é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦çµæœã‚’è¡¨ç¤º
        # è¥¿å°¾æ±oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®'ã®å ´åˆ
        # scatter_and_correlation(
        #     dataframe=lagged_features,
        #     x_col='åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬',
        #     y_col='è¥¿å°¾æ±oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®')
        
        scatter_and_correlation(
            dataframe=lagged_features,
            x_col='åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬',
            y_col="è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®")
        
        scatter_and_correlation(
            dataframe=lagged_features,
            x_col='åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬',
            y_col='å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰')
        
        scatter_and_correlation(
            dataframe=lagged_features,
            x_col='åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬',
            y_col='å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ')
        
        scatter_and_correlation(
            dataframe=lagged_features,
            x_col='åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬',
            y_col="å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰")
        
        # scatter_and_correlation(
        #     dataframe=lagged_features,
        #     x_col='åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬',
        #     y_col='è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ')
        
        lagged_features = lagged_features[lagged_features['æ—¥æ™‚'].dt.weekday < 5]
        
        scatter_and_correlation(
            dataframe=lagged_features,
            x_col='åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬',
            y_col='è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_é•·æœŸéå»è¦å› ')
        
        #! ç®±ã²ã’å›³ç¢ºèª
        plot_box_by_hour(dataframe=lagged_features, value_col='å‡ºåº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰', time_col='æ—¥æ™‚')

        # ã‚„ã‚‹ã“ã¨
        # ç™ºæ³¨ã—ã¦å–ã‚Šæ¶ˆã—ãŸã‚‚ã®ãŒã©ã‚Œã ã‘ã‚ã‚‹ã‹ï¼Ÿ

        #todo---------------------------------------------------------------------------------------------------------------------------
        
        #!å®šæœŸä¾¿
        lagged_features = pd.merge(lagged_features, teikibin_df[['æ—¥æ™‚', 'è·å½¹æ™‚é–“(t-4)','è·å½¹æ™‚é–“(t-5)','è·å½¹æ™‚é–“(t-6)']], on='æ—¥æ™‚', how='left')
        #!ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        lagged_features = feature_engineering(lagged_features)

        #!è§£æçª“
        timelag = 48#best_range_order
        end_hours_ago = 0

        #!ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´é‡
        #! è§£æçª“ã§è¨ˆç®—
        #lagged_features = calculate_window_width(lagged_features, timelag, best_range_order, best_range_reception)

        #! NaNå€¤ã‚’å‡¦ç†ã™ã‚‹ï¼ˆä¾‹: 0ã§åŸ‹ã‚ã‚‹ï¼‰
        lagged_features = lagged_features.fillna(0)
        
        #    ##todo å…¨éƒ¨çµ‚ã‚ã£ãŸå¾Œã«éç¨¼å‹•æ—¥æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã€‚ä¸Šã¾ã§é…ã‚Œè¨ˆç®—ã§åœŸæ—¥ãªã©ã‚’é™¤å¤–ã—ã¦ã„ã‚‹ã®ã§ã€‚
        #    # è£œå®Œã™ã‚‹æ™‚é–“ç¯„å›²ã‚’æ±ºå®š
        #    full_range = pd.date_range(start=start_date, end=end_date, freq='H')
        #    # full_rangeã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
        #    full_df = pd.DataFrame(full_range, columns=['æ—¥æ™‚'])
        #    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ãƒãƒ¼ã‚¸ã—ã¦æ¬ æå€¤ã‚’è£œå®Œ
        #    lagged_features = pd.merge(full_df, lagged_features, on='æ—¥æ™‚', how='left')
        #    # æ¬ æå€¤ã‚’0ã§è£œå®Œ
        #    lagged_features.fillna(0, inplace=True)
        #    #
        #    lagged_features = lagged_features.drop(columns=['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'])
        #    lagged_features['å“ç•ª']=part_number
        #    lagged_features = pd.merge(lagged_features, df2[['æ—¥æ™‚', 'å“ç•ª','åœ¨åº«æ•°ï¼ˆç®±ï¼‰']], on=['å“ç•ª', 'æ—¥æ™‚'], how='left')#è‡ªå‹•ãƒ©ãƒƒã‚¯åœ¨åº«çµåˆ

        
        #todo é•·æœŸä¼‘æš‡åˆ†å‰Šé™¤
        def delete_holiday(lagged_features):

            #todo ç¨¼åƒæ—¥ãƒ•ãƒ©ã‚°æ¬²ã—ã„
        
            #! å¤ä¼‘ã¿
            start = '2024-08-12'
            end = '2024-08-16'
            #! æ—¥ä»˜ç¯„å›²ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦å‰Šé™¤
            lagged_features= lagged_features[~((lagged_features['æ—¥æ™‚'] >= start) & (lagged_features['æ—¥æ™‚'] <= end))]

            #! GW
            start = '2024-05-06'
            end = '2024-05-10'
            #! æ—¥ä»˜ç¯„å›²ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦å‰Šé™¤
            lagged_features= lagged_features[~((lagged_features['æ—¥æ™‚'] >= start) & (lagged_features['æ—¥æ™‚'] <= end))]

            return lagged_features

        #todo é•·æœŸä¼‘æš‡åˆ†å‰Šé™¤
        lagged_features = delete_holiday(lagged_features)

        #!é…ã‚Œåˆ†å‰Šé™¤
        data = lagged_features.iloc[300:]

        data['å®šæœŸä¾¿å‡ºç™ºçŠ¶æ³ï¼ˆt-4~t-6ï¼‰']=data['è·å½¹æ™‚é–“(t-4)']/50+data['è·å½¹æ™‚é–“(t-5)']/50+data['è·å½¹æ™‚é–“(t-6)']/50

        # å®Ÿè¡Œçµæœç¢ºèª
        display_message(f"**å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚**")
        st.dataframe(lagged_features)

        #todo ã“ã“ã¾ã§ã§åœŸæ—¥ã¯æ¶ˆãˆã¦ã„ã‚‹

        temp_data = data

        # ãƒ¢ãƒ‡ãƒ«ã‚’æ ¼ç´ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        rf_models = []

        # 3ã¤ã®RFãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹
        for i in range(3):

            if i == 0:
                # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨
                data = temp_data
            elif i == 1:
                #one_and_half_months_ago = pd.to_datetime(end_date) - pd.Timedelta(days=45)
                # 1ã‹æœˆåŠå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                #data = temp_data[temp_data['æ—¥æ™‚'] >= one_and_half_months_ago]
                data = temp_data
            elif i == 2:
                #three_and_half_months_ago_manual = pd.to_datetime(end_date) - pd.Timedelta(days=105)
                # 3ã‹æœˆåŠå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                #data = temp_data[temp_data['æ—¥æ™‚'] >= three_and_half_months_ago_manual]
                data = temp_data

            #! ç•ªå·ã‚’å‰²ã‚Šå½“ã¦ã‚‹
            # delay_No1 = best_range_order
            # timelag_No1 = timelag
            # data[f'No1_ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No1}~t-{delay_No1+timelag_No1}ï¼‰'] = data[f'ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No1}~t-{delay_No1+timelag_No1}ï¼‰']

            # delay_No2 = end_hours_ago
            # timelag_No2 = timelag
            # data[f'No2_è¨ˆç”»çµ„ç«‹ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡ï¼ˆt-{delay_No2}~t-{delay_No2+timelag_No2}ï¼‰'] = data[f'è¨ˆç”»çµ„ç«‹ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡ï¼ˆt-{delay_No2}~t-{delay_No2+timelag_No2}ï¼‰']
            
            # delay_No3 = end_hours_ago
            # timelag_No3 = timelag
            # data[f'No3_è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡ï¼ˆt-{delay_No3}~t-{delay_No3+timelag_No3}ï¼‰'] = data[f'è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡ï¼ˆt-{delay_No3}~t-{delay_No3+timelag_No3}ï¼‰']
            
            # #delay_No4 = best_range_reception
            # #timelag_No4 = timelag
            # #data[f'No4_ç´å…¥ãƒ•ãƒ¬ï¼ˆt-{delay_No4}~t-{delay_No4+timelag_No4}ï¼‰'] = data[f'ç´å…¥ãƒ•ãƒ¬ï¼ˆt-{delay_No4}~t-{delay_No4+timelag_No4}ï¼‰']
            
            # delay_No5 = best_range_reception
            # timelag_No5 = 2
            # data[f'No5_ä»•å…¥å…ˆä¾¿åˆ°ç€çŠ¶æ³ï¼ˆt-{delay_No5}~t-{delay_No5+timelag_No5}ï¼‰'] = data[f'ä»•å…¥å…ˆä¾¿åˆ°ç€çŠ¶æ³ï¼ˆt-{delay_No5}~t-{delay_No5+timelag_No5}ï¼‰']
            
            # #data['No6_å®šæœŸä¾¿å‡ºç™ºçŠ¶æ³ï¼ˆt-4~t-6ï¼‰'] = data['å®šæœŸä¾¿å‡ºç™ºçŠ¶æ³ï¼ˆt-4~t-6ï¼‰']
            
            # delay_No7 = end_hours_ago
            # timelag_No7 = timelag
            # data[f'No7_é–“å£ã®å¹³å‡å……è¶³ç‡ï¼ˆt-{delay_No7}~t-{delay_No7+timelag_No7}ï¼‰'] = data[f'é–“å£ã®å¹³å‡å……è¶³ç‡ï¼ˆt-{delay_No7}~t-{delay_No7+timelag_No7}ï¼‰']
            # # å……è¶³ç‡ãŒ1ã‚ˆã‚Šå°ã•ã„å ´åˆã€0ã«æ›´æ–°
            # data.loc[data[f'No7_é–“å£ã®å¹³å‡å……è¶³ç‡ï¼ˆt-{delay_No7}~t-{delay_No7+timelag_No7}ï¼‰'] < 1, f'No7_é–“å£ã®å¹³å‡å……è¶³ç‡ï¼ˆt-{delay_No7}~t-{delay_No7+timelag_No7}ï¼‰'] = 0
            
            # delay_No8 = end_hours_ago
            # timelag_No8 = timelag
            # data[f'No8_éƒ¨å“ç½®ãå ´ã®å…¥åº«æ»ç•™çŠ¶æ³ï¼ˆt-{delay_No8}~t-{delay_No8+timelag_No8}ï¼‰'] = data[f'éƒ¨å“ç½®ãå ´ã®å…¥åº«æ»ç•™çŠ¶æ³ï¼ˆt-{delay_No8}~t-{delay_No8+timelag_No8}ï¼‰']
            
            #delay_No9 = end_hours_ago
            #timelag_No9 = timelag
            #data[f'No9_å®šæœŸä¾¿ã«ãƒ¢ãƒç„¡ã—ï¼ˆt-{delay_No9}~t-{delay_No9+timelag_No9}ï¼‰'] = data[f'å®šæœŸä¾¿ã«ãƒ¢ãƒç„¡ã—ï¼ˆt-{delay_No9}~t-{delay_No9+timelag_No9}ï¼‰']


            #! ç‰¹å¾´é‡é¸æŠ-----------------------------------------------------------------------------------------------------------------------------------------------
            
            #! ----------------------------
            #! ä»Šã®ã‚‚ã®
            #! ----------------------------

            # ç¬é–“è¦å› ã¯ãƒ©ã‚°0
            delay_No12 = 0
            timelag_No12 = 0
            data[f'No12_ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No12}~t-{delay_No12+timelag_No12}ï¼‰'] = data['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ']

            delay_No13 = 0
            timelag_No13 = 0
            data[f'No13_è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No13}~t-{delay_No13+timelag_No13}ï¼‰'] = data["è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®"]

            delay_No14 = 0
            timelag_No14 = 0
            data[f'No14_å…¥åº«é…ã‚Œãªã©ã«ã‚ˆã‚‹äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No14}~t-{delay_No14+timelag_No14}ï¼‰'] = data['å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰']

            delay_No15 = 0
            timelag_No15 = 0
            data[f'No15_é–“å£ã®å¹³å‡å……è¶³ç‡ï¼ˆt-{delay_No15}~t-{delay_No15+timelag_No15}ï¼‰'] = data['æŠ•å…¥é–“å£ã®æ¸‹æ»åˆ¤å®šãƒ•ãƒ©ã‚°']

            #ä»•å…¥å…ˆä¾¿otu
            delay_No16 = 0
            timelag_No16 = 0
            data[f'No16_ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œï¼ˆt-{delay_No16}~t-{delay_No16+timelag_No16}ï¼‰'] = data['ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œ_è£œæ­£_æ™‚é–“é…ã‚Œ']

            #è¨ˆç”»ç”Ÿç”£å°æ•°
            #lag_past_count_value = 24*5*2
            #lag_future_count_value =24*5
            delay_No17 = lag_past_count_value - lag_future_count_value
            timelag_No17 = lag_past_count_value - delay_No17
            data[f'No17_è¨ˆç”»ç”Ÿç”£å°æ•°ï¼ˆt-{delay_No17}~t-{delay_No17+timelag_No17}ï¼‰'] = data['è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_é•·æœŸéå»è¦å› ']

            #ç´å…¥ãƒ•ãƒ¬

            #todo-------------------------------------------------------------------------------------------------------------

            #! old

            # ç™ºæ³¨ãƒ•ãƒ©ã‚°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰ã‚’è¨­å®š
            # data[f"No10_ç™ºæ³¨ãƒ•ãƒ©ã‚°_æ™‚é–“é…ã‚Œï¼ˆt-{delay_No1}~t-{delay_No1+timelag_No1}ï¼‰"] = data["ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰"].apply(lambda x: 1 if x > 0 else 0)

            # data['ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰'] = data['ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰'] #- data['ä¾¿Ave']#todo ä¾¿Aveã©ã†ã™ã‚‹ï¼Ÿ
            # # ç™ºæ³¨ãƒ•ãƒ©ã‚°ãŒ0ã®è¡Œã«å¯¾ã—ã¦ã€ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰ã‚’0ã«æ›´æ–°
            # data.loc[data[f"No10_ç™ºæ³¨ãƒ•ãƒ©ã‚°_æ™‚é–“é…ã‚Œï¼ˆt-{delay_No1}~t-{delay_No1+timelag_No1}ï¼‰"] == 0, 'ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°_æ™‚é–“é…ã‚Œï¼ˆtï¼‰'] = 0
            # data[f'No1_ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No1}~t-{delay_No1+timelag_No1}ï¼‰'] = data['å…¥åº«äºˆå®šã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_è£œæ­£æ¸ˆ']

            # data[f'No2_è¨ˆç”»çµ„ç«‹ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡ï¼ˆt-{delay_No2}~t-{delay_No2+timelag_No2}ï¼‰'] = data["è¨ˆç”»ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡æ¸ˆ_å‡ºåº«æ•°è€ƒæ…®"]

            # data["è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡æ¸ˆ"] = data["è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡æ¸ˆ"].replace([np.inf, -np.inf], 1.5, inplace=True)
            # data[f'No3_è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡ï¼ˆt-{delay_No3}~t-{delay_No3+timelag_No3}ï¼‰'] = data["è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡æ¸ˆ"]

            # data[f'No8_éƒ¨å“ç½®ãå ´ã®å…¥åº«æ»ç•™çŠ¶æ³ï¼ˆt-{delay_No8}~t-{delay_No8+timelag_No8}ï¼‰'] =data["è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰_æ™‚é–“å¤‰åŒ–è€ƒæ…®"]

            # data[f"No11_äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°"] = data['å·¥å ´åˆ°ç€å¾Œã®å…¥åº«ä½œæ¥­ãªã©ã§ã¯ãªã„äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆtï¼‰']

            display_message(f"**èª¬æ˜å¤‰æ•°å€™è£œã®è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚**")
            st.dataframe(data)
            
            data.fillna(0,inplace=True)
            

            #todo-------------------------------------------------------------------------------------------------------------

            #! èª¬æ˜å¤‰æ•°ã®è¨­å®š
            # X = data[[f'No1_ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No1}~t-{delay_No1+timelag_No1}ï¼‰',
            #         f'No2_è¨ˆç”»çµ„ç«‹ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡ï¼ˆt-{delay_No2}~t-{delay_No2+timelag_No2}ï¼‰',
            #         f'No3_è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡ï¼ˆt-{delay_No3}~t-{delay_No3+timelag_No3}ï¼‰',
            #         #f'No4_ç´å…¥ãƒ•ãƒ¬ï¼ˆt-{delay_No4}~t-{delay_No4+timelag_No4}ï¼‰',
            #         f'No5_ä»•å…¥å…ˆä¾¿åˆ°ç€çŠ¶æ³ï¼ˆt-{delay_No5}~t-{delay_No5+timelag_No5}ï¼‰',
            #         #'No6_å®šæœŸä¾¿å‡ºç™ºçŠ¶æ³ï¼ˆt-4~t-6ï¼‰',#'è·å½¹æ™‚é–“(t-4)','è·å½¹æ™‚é–“(t-5)','è·å½¹æ™‚é–“(t-6)',
            #         f'No7_é–“å£ã®å¹³å‡å……è¶³ç‡ï¼ˆt-{delay_No7}~t-{delay_No7+timelag_No7}ï¼‰',#f'é–“å£_A1ã®å……è¶³ç‡ï¼ˆt-{end_hours_ago}~t-{best_range_order}ï¼‰',f'é–“å£_A2ã®å……è¶³ç‡ï¼ˆt-{end_hours_ago}~t-{best_range_order}ï¼‰', f'é–“å£_B1ã®å……è¶³ç‡ï¼ˆt-{end_hours_ago}~t-{best_range_order}ï¼‰', f'é–“å£_B2ã®å……è¶³ç‡ï¼ˆt-{end_hours_ago}~t-{best_range_order}ï¼‰',f'é–“å£_B3ã®å……è¶³ç‡ï¼ˆt-{end_hours_ago}~t-{best_range_order}ï¼‰', f'é–“å£_B4ã®å……è¶³ç‡ï¼ˆt-{end_hours_ago}~t-{best_range_order}ï¼‰',
            #         f'No8_éƒ¨å“ç½®ãå ´ã®å…¥åº«æ»ç•™çŠ¶æ³ï¼ˆt-{delay_No8}~t-{delay_No8+timelag_No8}ï¼‰',#f'éƒ¨å“ç½®ãå ´ã‹ã‚‰ã®å…¥åº«ï¼ˆt-{end_hours_ago}~t-{best_range_order}ï¼‰',f'éƒ¨å“ç½®ãå ´ã§æ»ç•™ï¼ˆt-{end_hours_ago}~t-{best_range_order}ï¼‰',
            #         #f'No9_å®šæœŸä¾¿ã«ãƒ¢ãƒç„¡ã—ï¼ˆt-{delay_No9}~t-{delay_No9+timelag_No9}ï¼‰']
            #         f"No10_ç™ºæ³¨ãƒ•ãƒ©ã‚°_æ™‚é–“é…ã‚Œï¼ˆt-{delay_No1}~t-{delay_No1+timelag_No1}ï¼‰",
            #         f"No11_äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°"
            #         ]]
            
            #! èª¬æ˜å¤‰æ•°ã®è¨­å®š
            X = data[[f'No12_ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No12}~t-{delay_No12+timelag_No12}ï¼‰',
                      f'No13_è¥¿å°¾æ±ç‰©æµã‚»ãƒ³ã‚¿ãƒ¼oréƒ¨å“ç½®ãå ´ã§ã®æ»ç•™ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No13}~t-{delay_No13+timelag_No13}ï¼‰',
                      f'No14_å…¥åº«é…ã‚Œãªã©ã«ã‚ˆã‚‹äºˆå®šå¤–ã®å…¥åº«ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-{delay_No14}~t-{delay_No14+timelag_No14}ï¼‰',
                      f'No15_é–“å£ã®å¹³å‡å……è¶³ç‡ï¼ˆt-{delay_No15}~t-{delay_No15+timelag_No15}ï¼‰',
                      f'No16_ä»•å…¥å…ˆåˆ°ç€oræ¤œåä¹±ã‚Œï¼ˆt-{delay_No16}~t-{delay_No16+timelag_No16}ï¼‰',
                      f'No17_è¨ˆç”»ç”Ÿç”£å°æ•°ï¼ˆt-{delay_No17}~t-{delay_No17+timelag_No17}ï¼‰'
                    ]]
                      
            
            #ç¢ºèªï¼šå®Ÿè¡Œçµæœ
            display_message(f"**ç›®çš„å¤‰æ•°ã¨èª¬æ˜å¤‰æ•°ã®è¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸã€‚**")
            st.dataframe(X.head(300))

            #! ç›®çš„å¤‰æ•°ã®å®šç¾©
            #! ä¸­å¤®å€¤ã‚ºãƒ¬ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨
            y = data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰_ä¸­å¤®å€¤ã‹ã‚‰ã®ã‚ºãƒ¬']

            #! ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
            #todo å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)

            #! Lassoå›å¸°ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
            ridge = Ridge(alpha=0.1)
            # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
            ridge.fit(X_train, y_train)
            # äºˆæ¸¬
            y_pred_train = ridge.predict(X_train)
            y_pred_test = ridge.predict(X_test)
            # è©•ä¾¡
            mse_train = mean_squared_error(y_train, y_pred_train)
            mse_test = mean_squared_error(y_test, y_pred_test)
            max_error_train = max_error(y_train, y_pred_train)
            max_error_test = max_error(y_test, y_pred_test)
            # ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®ã‚’è¨ˆç®—
            min_error_train = np.min(y_train - y_pred_train)
            min_error_test = np.min(y_test - y_pred_test)

            #print(f'Ridgeå›å¸° - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®MSE: {mse_train}')
            #print(f'Ridgeå›å¸° - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®MSE: {mse_test}')
            #print(f'Ridgeå›å¸° - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§èª¤å·®: {max_error_train}')
            #print(f'Ridgeå›å¸° - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§èª¤å·®: {max_error_test}')
            #print(f'Ridgeå›å¸° - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®: {min_error_train}')
            #print(f'Ridgeå›å¸° - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®: {min_error_test}')
            # å¹³å‡èª¤å·®ã‚’è¨ˆç®—
            mae = mean_absolute_error(y_test, y_pred_test)
            #print(f'Ridgeå›å¸° - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å¹³å‡èª¤å·®: {mae}')

            #! ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
            if i == 2:
                rf_model = RandomForestRegressor(n_estimators=10, max_depth=30, random_state=42)
                rf_model.fit(X_train, y_train)
            elif i == 1:
                rf_model2 = RandomForestRegressor(n_estimators=10, max_depth=30, random_state=42)
                rf_model2.fit(X_train, y_train)
            elif i == 0:
                rf_model3 = RandomForestRegressor(n_estimators=10, max_depth=30, random_state=42)
                rf_model3.fit(X_train, y_train)

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã—ã€MSEã‚’è¨ˆç®—
            #y_pred = rf_model.predict(X_test)
            #mse = mean_squared_error(y_test, y_pred)
            #print(f'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®MSE: {mse}')
            # æœ€å¤§èª¤å·®ã‚’è¨ˆç®—
            #max_err = max_error(y_test, y_pred)
            #print(f'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§èª¤å·®: {max_err}')
            # ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®ã‚’è¨ˆç®—
            #min_err = np.min(y_test - y_pred)
            #print(f'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®: {min_err}')
            # å¹³å‡èª¤å·®ã‚’è¨ˆç®—
            #mae2 = mean_absolute_error(y_test, y_pred)
            #st.header(mae2)
            #print(f'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å¹³å‡èª¤å·®: {mae2}')
            #--------------------------------------------------------------------------------------------------------
            
            unique_hinban_list = lagged_features['ä»•å…¥å…ˆå'].unique()
            supply = str(unique_hinban_list[0])
            zaikozaiko = lagged_features['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].mean()
            
            #appendãƒ¡ã‚½ãƒƒãƒ‰ã¯pandasã®æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯å»ƒæ­¢
            # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ 
            #results_df = results_df.append({'å“ç•ª': part_number,'ä»•å…¥å…ˆå':supply,'å¹³å‡åœ¨åº«':zaikozaiko,'Ridgeå›å¸°ã®å¹³å‡èª¤å·®': mae, 'Ridgeå›å¸°ã®ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®': min_error_test, 'Ridgeå›å¸°ã®ãƒ—ãƒ©ã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®': max_error_test,
                                            #'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®å¹³å‡èª¤å·®': mae2, 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®': min_err, 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ãƒ—ãƒ©ã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®': max_err}, ignore_index=True)

            #! å®Ÿè¡Œçµæœåé›†
            new_row = pd.DataFrame([{'å“ç•ª': part_number,'ä»•å…¥å…ˆå':supply,'å¹³å‡åœ¨åº«':zaikozaiko,'Ridgeå›å¸°ã®å¹³å‡èª¤å·®': mae, 'Ridgeå›å¸°ã®ãƒã‚¤ãƒŠã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®': min_error_test, 'Ridgeå›å¸°ã®ãƒ—ãƒ©ã‚¹æ–¹å‘ã®æœ€å¤§èª¤å·®': max_error_test}])
            results_df = pd.concat([results_df, new_row], ignore_index=True)

            #! çµ‚äº†é€šçŸ¥
            print("çµ‚äº†")
            
            #! CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open("temp/ä¸€æ™‚ä¿å­˜ãƒ‡ãƒ¼ã‚¿.csv", mode='w',newline='', encoding='shift_jis',errors='ignore') as f:
                data.to_csv(f)

            #! CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open("temp/å…¨å“ç•ªãƒ†ã‚¹ãƒˆçµæœ.csv", mode='w',newline='', encoding='shift_jis',errors='ignore') as f:
                results_df.to_csv(f)
        
    return data, rf_model, rf_model2, rf_model3, X

        ###å…¨éƒ¨çµ‚ã‚ã£ãŸå¾Œã«éç¨¼å‹•æ—¥æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã€‚ä¸Šã¾ã§é…ã‚Œè¨ˆç®—ã§åœŸæ—¥ãªã©ã‚’é™¤å¤–ã—ã¦ã„ã‚‹ã®ã§ã€‚
        ## è£œå®Œã™ã‚‹æ™‚é–“ç¯„å›²ã‚’æ±ºå®š
        #full_range = pd.date_range(start=start_date, end=end_date, freq='H')
        ## full_rangeã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
        #full_df = pd.DataFrame(full_range, columns=['æ—¥æ™‚'])
        ## å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ãƒãƒ¼ã‚¸ã—ã¦æ¬ æå€¤ã‚’è£œå®Œ
        #lagged_features = pd.merge(full_df, lagged_features, on='æ—¥æ™‚', how='left')
        ## æ¬ æå€¤ã‚’0ã§è£œå®Œ
        #lagged_features.fillna(0, inplace=True)
        ##
        #lagged_features = lagged_features.drop(columns=['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'])
        #lagged_features['å“ç•ª']=part_number
        #lagged_features = pd.merge(lagged_features, df2[['æ—¥æ™‚', 'å“ç•ª','åœ¨åº«æ•°ï¼ˆç®±ï¼‰']], on=['å“ç•ª', 'æ—¥æ™‚'], how='left')#è‡ªå‹•ãƒ©ãƒƒã‚¯åœ¨åº«çµåˆ

#! ã‚¹ãƒ†ãƒƒãƒ—ï¼’ã®å‡¦ç†
def step2(data, rf_model, X, start_index, end_index, step3_flag, highlight_time=None):

    #Todo å“ç•ªåã‚’å–ã‚Šå‡ºã™ãŸã‚ã«å®Ÿè¡Œã€ãã‚Œã„ã˜ã‚ƒãªã„ã‹ã‚‰è¦ä¿®æ­£
    with open('temp/model_and_data.pkl', 'rb') as file:
        rf_model, rf_model2, rf_model3, X, data, product = pickle.load(file)

    #! Activeãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    #start_date2 = '202405'
    #end_date2 = '202408'
    #ver = '00'
    #Activedata = read_activedata_from_IBMDB2(start_date2, end_date2, ver)#process_Activedata()
    #st.header(product)
    file_path = 'temp/activedata.csv'
    Activedata = pd.read_csv(file_path, encoding='shift_jis')
    # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
    Activedata['æ—¥ä»˜'] = pd.to_datetime(Activedata['æ—¥ä»˜'], errors='coerce')
    #! å“ç•ªã€æ•´å‚™å®¤æƒ…å ±èª­ã¿è¾¼ã¿
    seibishitsu = product.split('_')[1]#æ•´å‚™å®¤ã®ã¿
    product = product.split('_')[0]#å“ç•ªã®ã¿
    #! åŒå“ç•ªã€åŒæ•´å‚™å®¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    Activedata = Activedata[(Activedata['å“ç•ª'] == product) & (Activedata['æ•´å‚™å®¤'] == seibishitsu)]

    #å®Ÿè¡Œçµæœã®ç¢ºèª
    #st.header(start_index)
    #st.header(end_index)

    # åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦æ™‚é–“ç²’åº¦ã‚’1æ™‚é–“ã”ã¨ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    # å†…ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’æ—¥ä»˜ã”ã¨ã«é›†ç´„ã—ã¦é‡è¤‡ã‚’æ’é™¤
    #Activedata = Activedata.groupby('æ—¥ä»˜').mean(numeric_only=True).reset_index()
    #st.dataframe(Activedata)
    Activedata = Activedata.set_index('æ—¥ä»˜').resample('H').ffill().reset_index()

    #st.dataframe(Activedata.head(300))

    #æŠ˜ã‚Šè¿”ã—ç·šã‚’è¿½åŠ 
    st.markdown("---")

    #ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒ300ã‚¹ã‚¿ãƒ¼ãƒˆãªã®ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
    #é…ã‚Œæ™‚é–“ã®è¨ˆç®—ã®ãŸã‚
    data = data.reset_index(drop=True)
    #st.dataframe(data.head(300))

    # SHAPè¨ˆç®—
    #before
    #explainer = shap.TreeExplainer(rf_model, feature_dependence='tree_path_dependent', model_output='margin')

    #after
    explainer = shap.TreeExplainer(rf_model, model_output='raw')
    shap_values = explainer.shap_values(X)

    explainer = shap.TreeExplainer(rf_model2, model_output='raw')
    shap_values2 = explainer.shap_values(X)

    explainer = shap.TreeExplainer(rf_model3, model_output='raw')
    shap_values3 = explainer.shap_values(X)

    #ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©¦é¨“
    shap_values = shap_values# + shap_values2 + shap_values3
    #shap_values = shap_values
    #shap_values = shap_values2
    #shap_values = shap_values3

    #first_datetime_df = data['æ—¥æ™‚'].iloc[0]
    #print(f"dataã®æ—¥æ™‚åˆ—ã®æœ€åˆã®å€¤: {first_datetime_df}")

    # ãƒªã‚¹ãƒˆã‹ã‚‰æ•´æ•°ã«å¤‰æ›
    start_index_int = start_index[0]#-300
    end_index_int = end_index[0]+1#-300

    #åœ¨åº«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    df = data.iloc[start_index_int:end_index_int]
    #st.dataframe(df)

    #st.dataframe(df.head(300))

    #first_datetime_df = df.iloc[0]
    #print(f"dfã®æ—¥æ™‚åˆ—ã®æœ€åˆã®å€¤: {first_datetime_df}")


    #! -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*
    #! ï¼œç›®çš„é–¢æ•°ã«åœ¨åº«å¢—æ¸›æ•°ã‚’è¨­å®šã™ã‚‹å ´åˆï¼
    #! Resultsï¼šstart_index_intã€end_index_intã€y_pred_subsetã€y_base_subset
    
    # #! 16æ™‚æ™‚ç‚¹ã®åœ¨åº«æ•°ã¯ã€15æ™‚æ™‚ç‚¹ã®åœ¨åº«æ•°ã¨15æ™‚ã®åœ¨åº«å¢—æ¸›æ•°ã§æ±ºå®šã•ã‚Œã‚‹ãŸã‚ã€æ™‚åˆ»ã‚’1ã¤å‰ã«å‚ç…§ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
    # start_index_int = start_index_int - 1
    # end_index_int = end_index_int -1 
    # X_subset = X.iloc[start_index_int:end_index_int]

    # #! å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ã€X_subsetã‹ã‚‰äºˆæ¸¬å€¤ã‚’è¨ˆç®—
    # #! y_pred_subsetã¯åœ¨åº«å¢—æ¸›æ•°ã®äºˆæ¸¬å€¤ã‚’è¡¨ã™
    # y_pred_subset = rf_model.predict(X_subset)

    # #! åœ¨åº«ãƒ‡ãƒ¼ã‚¿æº–å‚™
    df['æ—¥æ™‚'] = pd.to_datetime(df['æ—¥æ™‚'])
    df.set_index('æ—¥æ™‚', inplace=True)
    #df2 = df['åœ¨åº«å¢—æ¸›æ•°ï¼ˆt-52~t-0ï¼‰']
    df2 = df['åœ¨åº«æ•°ï¼ˆç®±ï¼‰']

    # #! 1ã¤å‰ã®åœ¨åº«æ•°ãƒ‡ãƒ¼ã‚¿ãŒæ¬²ã—ã„
    # #? æ˜”ã®ã‚„ã¤
    # #best_range_order = find_columns_with_word_in_name(df, 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰ï¼ˆt-')
    # #yyyy = df[f'{best_range_order}']
    # # yyyyã‚’1æ™‚é–“å‰ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰ã«è¨­å®š
    # #yyyy = df2.shift(1)
    # #? ä»Šã®ã‚„ã¤
    # y_base_subset = data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].iloc[start_index_int:end_index_int]
    # #st.dataframe(y_base_subset)

    # # æ¯”è¼ƒ
    # #st.write(x.equals(y))  # Trueã§ã‚ã‚Œã°ä¸€è‡´

    #! ï¼œç›®çš„é–¢æ•°ã«åœ¨åº«æ•°_ä¸­å¤®å€¤ã‚ºãƒ¬ã‚’è¨­å®šã™ã‚‹å ´åˆï¼
    start_index_int = start_index_int-1
    end_index_int = end_index_int-1
    X_subset = X.iloc[start_index_int:end_index_int]

    #! å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ã€X_subsetã‹ã‚‰äºˆæ¸¬å€¤ã‚’è¨ˆç®—
    #! y_pred_subsetã¯åœ¨åº«å¢—æ¸›æ•°ã®äºˆæ¸¬å€¤ã‚’è¡¨ã™
    y_pred_subset = rf_model.predict(X_subset)

    # æ™‚åˆ»ã‚’æŠ½å‡º
    data['æ™‚åˆ»'] = pd.to_datetime(data['æ—¥æ™‚']).dt.hour

    # æ™‚åˆ»ã”ã¨ã®åœ¨åº«æ•°ä¸­å¤®å€¤ã‚’è¨ˆç®—
    median_by_hour = data.groupby('æ™‚åˆ»')['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].transform('median')

    # æ–°ã—ã„åˆ—ã‚’ä½œæˆ
    data['åœ¨åº«æ•°_ä¸­å¤®å€¤'] = median_by_hour

    y_base_subset = data['åœ¨åº«æ•°_ä¸­å¤®å€¤'].iloc[start_index_int:end_index_int]

    #å®Ÿè¡Œçµæœã®ç¢ºèª
    #st.dataframe(y_pred_subset)
    #st.dataframe(y_base_subset)

    #! -*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*

    #st.dataframe(y_base_subset.head(300))

    #åœ¨åº«å¢—æ¸›æ•°ã®å¹³å‡å€¤ã‚’ç¢ºèªç”¨
    #mean_value = y.mean()

    # SHAPå€¤ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    shap_df = pd.DataFrame(shap_values, columns=X.columns)

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¹³å‡SHAPå€¤ã«åŸºã¥ã„ã¦ç‰¹å¾´é‡ã‚’ä¸¦ã³æ›¿ãˆ
    shap_df_mean = shap_df.abs().mean().sort_values(ascending=False)
    sorted_columns = shap_df_mean.index

    shap_df_sorted = shap_df[sorted_columns]

    dfdf = shap_df_sorted.iloc[start_index_int:end_index_int].T

    # ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’ã‚¹ãƒ©ã‚¤ã‚¹
    dfdf_subset = dfdf#.iloc[:, start_idx:end_idx]

    dfdf_subset2 = dfdf_subset

    # å‰ã®å€¤ã¨ã®å·®åˆ†ã‚’è¨ˆç®—
    # å·®åˆ†ã¨å·®åˆ†åˆ¤å®šã‚’foræ–‡ã§è¨ˆç®—
    #difference = [None]  # æœ€åˆã®å·®åˆ†ã¯ãªã—
    #for i in range(1,len(df2_subset)):
    #    diff = df2_subset.iloc[i] - df2_subset.iloc[i-1]
    #    difference.append(diff)
    #    if i < len(dfdf_subset2):
    #        if diff > 0:
    #            dfdf_subset2.iloc[i] = dfdf_subset2.iloc[i]
    #        elif diff < 0:
    #            dfdf_subset2.iloc[i] = -1*dfdf_subset2.iloc[i]

    #--------------------------------------------------------------------------------------------

    df = dfdf_subset2

    # dfã®åˆ—æ•°ã¨df2_subsetã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•°ã‚’ç¢ºèª
    print(f"data index: {len(data)}")
    print(f"df columns: {len(df.columns)}")
    #print(f"df2_subset index: {len(df2_subset.index)}")
    print(f"shap_df_sorted index: {len(shap_df_sorted)}")
    print(f"dfdf index: {len(dfdf)}")
    print(f"dfdf_subset2 index: {len(dfdf_subset2)}")


    # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã®é¸æŠ
    #cmap = 'RdBu_r'  # é’ã‹ã‚‰èµ¤ã«å¤‰åŒ–ã™ã‚‹ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—

    #df2_subset.index = df2_subset.index.strftime('%Y-%m-%d-%H')
    df.columns = df2.index.strftime('%Y-%m-%d-%H')

    #è¡Œã®ä¸¦ã³ã‚’åè»¢
    #df_reversed = df.iloc[::-1]

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
    df2_subset_df = df2.to_frame().reset_index()

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®è¡Œã¨åˆ—ã‚’å…¥ã‚Œæ›¿ãˆ
    df_transposed = df.transpose()
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦æ—¥æ™‚åˆ—ã‚’ä½œæˆ
    df_transposed.reset_index(inplace=True)
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã®åå‰ã‚’ 'æ—¥æ™‚' ã«å¤‰æ›´
    df_transposed.rename(columns={'index': 'æ—¥æ™‚'}, inplace=True)

    #èª¬æ˜å¤‰æ•°
    #todo-------------------------------------------------------------------------
    #èª¬æ˜å¤‰æ•°ã‚‚ãšã‚‰ã™
    zzz = X.iloc[start_index_int:end_index_int]#[start_idx:end_idx]
    #todo-------------------------------------------------------------------------
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
    zzz = zzz.reset_index(drop=True)
    #æ—¥æ™‚åˆ—
    temp_time = df_transposed.reset_index(drop=True)

    #ç¢ºèªç”¨
    #first_datetime_df1 = data['æ—¥æ™‚'].iloc[0]
    #first_datetime_df2 = temp_time['æ—¥æ™‚'].iloc[0]
    #first_datetime_df3 = df_transposed['æ—¥æ™‚'].iloc[0]
    #print(f"dataã®æ—¥æ™‚åˆ—ã®æœ€åˆã®å€¤: {first_datetime_df1}")
    #print(f"df_transposedã®æ—¥æ™‚åˆ—ã®æœ€åˆã®å€¤: {first_datetime_df3}")
    #print(f"temp_timeã®æ—¥æ™‚åˆ—ã®æœ€åˆã®å€¤: {first_datetime_df2}")

    #! æ—¥æ™‚åˆ—ã¨èª¬æ˜å¤‰æ•°ã‚’çµåˆ
    merged_df = pd.concat([temp_time[['æ—¥æ™‚']], zzz], axis=1)
    
    #! å¤‰æ•°åã‚’å¤‰æ›´ã™ã‚‹
    line_data = df2_subset_df #åœ¨åº«ãƒ‡ãƒ¼ã‚¿
    bar_data = df_transposed #SHAPå€¤
    df2 = merged_df #å…ƒãƒ‡ãƒ¼ã‚¿
    
    #! åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    line_df = pd.DataFrame(line_data)
    line_df['æ—¥æ™‚'] = pd.to_datetime(line_df['æ—¥æ™‚'], format='%Y%m%d%H')

    #! SHAPå€¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    bar_df = pd.DataFrame(bar_data)
    bar_df['æ—¥æ™‚'] = pd.to_datetime(bar_df['æ—¥æ™‚'])
    
    #! å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    df2 = pd.DataFrame(df2)
    df2['æ—¥æ™‚'] = pd.to_datetime(df2['æ—¥æ™‚'])

    #ç¢ºèª
    #st.dataframe(line_df.head(300))
    #print("å¢—æ¸›")
    #print(y_pred_subset)
    #st.dataframe(y_pred_subset)
    #print("ãƒ™ãƒ¼ã‚¹")
    #print(y_base_subset)
    #st.dataframe(y_base_subset)

    #! é–‹ç¤ºæ™‚é–“ã¨çµ‚äº†æ™‚é–“ã‚’è¨ˆç®—
    #start_datetime = bar_df['æ—¥æ™‚'].min().to_pydatetime()
    #end_datetime = bar_df['æ—¥æ™‚'].max().to_pydatetime()

    #Activedata = Activedata[(Activedata['æ—¥ä»˜'] >= start_datetime) & 
                                     # (Activedata['æ—¥ä»˜'] <= end_datetime)]
    
    # bar_dfã®æ™‚é–“å¸¯ã‚’æŠ½å‡º
    bar_times = bar_df['æ—¥æ™‚']
    
    #st.dataframe(bar_times)
    #st.dataframe(bar_df['æ—¥æ™‚'])
    #st.dataframe(Activedata['æ—¥ä»˜'])

    # Activedataã®æ™‚é–“å¸¯ã‚’æŠ½å‡ºã—ã€bar_dfã®æ™‚é–“å¸¯ã¨ä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    Activedata = Activedata[Activedata['æ—¥ä»˜'].isin(bar_times)]

    #! ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤º
    st.header('åœ¨åº«æƒ…å ±')

    #! çµæœã‚’å¯è¦–åŒ–
    if step3_flag == 0:
        plot_inventory_graph(line_df, y_pred_subset, y_base_subset, Activedata)
    elif step3_flag == 1:
        plot_inventory_graph2(line_df, y_pred_subset, y_base_subset, Activedata, highlight_time)

    #å®Ÿè¡Œçµæœã®ç¢ºèª
    #st.dataframe(line_df)
    
    #å®Ÿè¡Œçµæœã®ç¢ºèªï¼›é–‹å§‹æ™‚åˆ»ã¨çµ‚äº†æ™‚åˆ»
    #print(strat_datetime,end_datetime)

    #!å®Ÿè¡Œçµæœã®ç¢ºèªï¼šå…¨ä½“SHAPãƒ—ãƒ­ãƒƒãƒˆã®ç”Ÿæˆ
    # fig, ax = plt.subplots()
    # shap.summary_plot(shap_values, X, feature_names=X.columns, show=False)
    # #ãƒ—ãƒ­ãƒƒãƒˆã‚’Streamlitã§è¡¨ç¤º
    # st.pyplot(fig)
    
    #! STEP3ã®è¦å› åˆ†æçµæœã®å¯è¦–åŒ–ã®ãŸã‚ã«ã€é–‹å§‹æ—¥æ™‚ï¼ˆstrat_datetimeï¼‰ã¨çµ‚äº†æ—¥æ™‚ï¼ˆend_datetimeï¼‰ã€
    #! SHAPå€¤ï¼ˆbar_dfï¼‰ã€å…ƒãƒ‡ãƒ¼ã‚¿å€¤ï¼ˆdf2ï¼‰ã‚’å‡ºåŠ›ã™ã‚‹
    return bar_df, df2, line_df

#! ã‚¹ãƒ†ãƒƒãƒ—ï¼“ã®å‡¦ç†
def step3(bar_df, df2, selected_datetime, line_df):

    #st.dataframe(df2)
    #st.dataframe(line_df)
    #st.dataframe(bar_df)

    #! æŠ˜ã‚Šè¿”ã—ç·šã‚’è¿½åŠ 
    st.markdown("---")

    #! ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    st.header('è¦å› åˆ†æ')

    #! Activeãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    #Todo å“ç•ªåã‚’å–ã‚Šå‡ºã™ãŸã‚ã«å®Ÿè¡Œã€ãã‚Œã„ã˜ã‚ƒãªã„ã‹ã‚‰è¦ä¿®æ­£
    with open('temp/model_and_data.pkl', 'rb') as file:
        rf_model,rf_model2,rf_model3, X, data, product = pickle.load(file)
    #ã€€Activeãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    #start_date2 = '202405'
    #end_date2 = '202408'
    #ver = '00'
    file_path = 'temp/activedata.csv'
    Activedata = pd.read_csv(file_path, encoding='shift_jis')
    # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
    Activedata['æ—¥ä»˜'] = pd.to_datetime(Activedata['æ—¥ä»˜'], errors='coerce')
    #ã€€å“ç•ªã€æ•´å‚™å®¤æƒ…å ±èª­ã¿è¾¼ã¿
    seibishitsu = product.split('_')[1]#æ•´å‚™å®¤ã®ã¿
    product = product.split('_')[0]#å“ç•ªã®ã¿
    #ã€€åŒå“ç•ªã€åŒæ•´å‚™å®¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    Activedata = Activedata[(Activedata['å“ç•ª'] == product) & (Activedata['æ•´å‚™å®¤'] == seibishitsu)]
    #ã€€1æ™‚é–“å˜ä½ã«å¤‰æ›
    Activedata = Activedata.set_index('æ—¥ä»˜').resample('H').ffill().reset_index()

    #! SHAPå€¤ï¼ˆbar_dfï¼‰ã€å…ƒãƒ‡ãƒ¼ã‚¿å€¤ï¼ˆdf2ï¼‰ã®æ—¥æ™‚ã‚’datetimeå‹ã«ã™ã‚‹ã€€
    bar_df['æ—¥æ™‚'] = pd.to_datetime(bar_df['æ—¥æ™‚'])
    df2['æ—¥æ™‚'] = pd.to_datetime(df2['æ—¥æ™‚'])
    #st.dataframe(bar_df)

    #! selected_datetime ã‚’1æ™‚é–“å‰ã«å¤‰æ›´
    #selected_datetime = pd.Timestamp(selected_datetime) - pd.Timedelta(hours=1)

    #! é¸æŠã•ã‚ŒãŸæ—¥æ™‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    filtered_df1 = bar_df[bar_df['æ—¥æ™‚'] == pd.Timestamp(selected_datetime)]
    filtered_df2 = df2[df2['æ—¥æ™‚'] == pd.Timestamp(selected_datetime)]

    #todo----------------------------------------------------------------------------------------

    #! åœ¨åº«å¢—æ¸›ã®ã‚„ã¤

    # # selected_datetime2ã‚’è¨ˆç®—
    # selected_datetime2 = pd.Timestamp(selected_datetime) - pd.Timedelta(hours=15)

    # # æŒ‡å®šã—ãŸæ™‚é–“ç¯„å›²ã§ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    # filtered_df1_width = bar_df[(bar_df['æ—¥æ™‚'] >= pd.Timestamp(selected_datetime2)) & 
    #                     (bar_df['æ—¥æ™‚'] <= pd.Timestamp(selected_datetime))]
    
    # filtered_df2_width = df2[(df2['æ—¥æ™‚'] >= pd.Timestamp(selected_datetime2)) & 
    #                     (df2['æ—¥æ™‚'] <= pd.Timestamp(selected_datetime))]
    
    # #st.dataframe(filtered_df1_width)
    # #st.dataframe(filtered_df2_width)

    # # 'æ—¥æ™‚'åˆ—ã¯é™¤å¤–ã—ãŸä¸Šã§å„åˆ—ã®åˆè¨ˆã‚’è¨ˆç®—
    # filtered_df1 = filtered_df1_width.drop(columns=['æ—¥æ™‚']).sum().to_frame().T
    # # 'æ—¥æ™‚'åˆ—ã¯é™¤å¤–ã—ãŸä¸Šã§å„åˆ—ã®åˆè¨ˆã‚’è¨ˆç®—
    # filtered_df2 = filtered_df2_width.drop(columns=['æ—¥æ™‚']).mean().to_frame().T

    # #st.dataframe(filtered_df1)

    # #æ—¥æ™‚åˆ—ã¯æœ€å¾Œã®å€¤ã‚’ä½¿ç”¨
    # filtered_df1['æ—¥æ™‚'] = filtered_df1_width['æ—¥æ™‚'].iloc[-1]
    # filtered_df2['æ—¥æ™‚'] = filtered_df2_width['æ—¥æ™‚'].iloc[-1]

    # #st.dataframe(filtered_df1)

    #todo------------------------------------------------------------------------------------------

    # #st.dataframe(df2)
    # st.dataframe(filtered_df1)

    #! selected_datetime ã‚’1æ™‚é–“å‰ã«å¤‰æ›´
    #filtered_df1 = bar_df[bar_df['æ—¥æ™‚'] == (pd.Timestamp(selected_datetime) - pd.Timedelta(hours=1))]
    #filtered_df2 = df2[df2['æ—¥æ™‚'] == (pd.Timestamp(selected_datetime) - pd.Timedelta(hours=1))]
    
    #! 
    if not filtered_df1.empty:

        zaikosu = line_df.loc[line_df['æ—¥æ™‚'] == selected_datetime, 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].values[0]

        #! ã„ã¤ã‚‚ã®å€¤ã®æ¨ç§»ã‚’è¿½åŠ 
        file_path = 'temp/ã„ã¤ã‚‚ã®åœ¨åº«æ•°.csv'
        basezaiko_df = pd.read_csv(file_path, encoding='shift_jis')
        basezaiko_df['æ—¥æ™‚'] = pd.to_datetime(basezaiko_df['æ—¥æ™‚'])
        # line_df ã®æ—¥æ™‚ç¯„å›²ã«åˆã‚ã›ã‚‹
        basezaiko_df = basezaiko_df[basezaiko_df['æ—¥æ™‚'].isin(line_df['æ—¥æ™‚'])]
        basezaiko = basezaiko_df.loc[basezaiko_df['æ—¥æ™‚'] == selected_datetime, 'ã„ã¤ã‚‚ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].values[0]

        #! 2ã¤ã®metricã‚’ä½œæˆ
        col1, col2, col3 = st.columns(3)
        col1.metric(label="é¸æŠã•ã‚ŒãŸæ—¥æ™‚", value=selected_datetime)#, delta="1 mph")
        col2.metric(label="ã„ã¤ã‚‚ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰", value=int(basezaiko))
        col3.metric(label="åœ¨åº«æ•°ï¼ˆç®±ï¼‰", value=int(zaikosu), delta=f"{int(zaikosu)-int(basezaiko)} ç®±ï¼ˆã„ã¤ã‚‚ã®åœ¨åº«æ•°ã¨ã®å·®åˆ†ï¼‰")

        #! ãƒ‡ãƒ¼ã‚¿ã‚’é•·ã„å½¢å¼ã«å¤‰æ›
        df1_long = filtered_df1.melt(id_vars=['æ—¥æ™‚'], var_name='å¤‰æ•°', value_name='å¯„ä¸åº¦ï¼ˆSHAPå€¤ï¼‰')
        #! ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å€¤ã®é™é †ã«ã‚½ãƒ¼ãƒˆ
        df1_long = df1_long.sort_values(by='å¯„ä¸åº¦ï¼ˆSHAPå€¤ï¼‰', ascending=True)

        # ãƒ›ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã®æƒ…å ±ã‚’å«ã‚ã‚‹
        hover_data = {}
        for i, row in filtered_df2.iterrows():
            for idx, value in row.items():#iteritemsã¯ã€pandasã®Seriesã§ã¯itemsã«åç§°ãŒå¤‰æ›´
            #for idx, value in row.iteritems():
                if idx != 'æ—¥æ™‚':
                    hover_data[idx] = f"<b>æ—¥æ™‚:</b> {row['æ—¥æ™‚']}<br><b>{idx}:</b> {value:.2f}<br>"

        # æ¨ªæ£’ã‚°ãƒ©ãƒ•
        fig_bar = px.bar(df1_long,
                         x='å¯„ä¸åº¦ï¼ˆSHAPå€¤ï¼‰', y='å¤‰æ•°',
                         orientation='h',
                         labels={'å¯„ä¸åº¦ï¼ˆSHAPå€¤ï¼‰': 'å¯„ä¸åº¦ï¼ˆSHAPå€¤ï¼‰', 'å¤‰æ•°': 'å¤‰æ•°', 'æ—¥æ™‚': 'æ—¥æ™‚'},
                         title=f"{selected_datetime}ã®ãƒ‡ãƒ¼ã‚¿")

        
        # è‰²ã®è¨­å®š
        colors = ['red' if v >= 0 else 'blue' for v in df1_long['å¯„ä¸åº¦ï¼ˆSHAPå€¤ï¼‰']]
        # ãƒ›ãƒãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®š
        # SHAPå€¤ã§ã¯ãªã„ã‚‚ã®ã‚’è¡¨ç¤ºç”¨
        fig_bar.update_traces(
            marker_color=colors,
            hovertemplate=[hover_data[v] for v in df1_long['å¤‰æ•°']]
        )

        fig_bar.update_layout(
            #title="è¦å› åˆ†æ",
            height=500,  # é«˜ã•ã‚’èª¿æ•´
            width=100,   # å¹…ã‚’èª¿æ•´
            margin=dict(l=0, r=0, t=30, b=0)
        )

        #! ã‚¿ãƒ–ã®ä½œæˆ
        tab1, tab2 = st.tabs(["ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º", "æ£’ã‚°ãƒ©ãƒ•è¡¨ç¤º"])

        #! ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
        with tab1:

            #! ã‚‚ã— 'Unnamed: 0' ã‚„ 'æ—¥æ™‚' ãŒå­˜åœ¨ã™ã‚‹å ´åˆã«ã®ã¿å‰Šé™¤ã™ã‚‹ã‚ˆã†å¤‰æ•°ã‚’ä½œæˆ
            columns_to_drop = []
            if 'Unnamed: 0' in df2.columns:
                columns_to_drop.append('Unnamed: 0')
            if 'æ—¥æ™‚' in df2.columns:
                columns_to_drop.append('æ—¥æ™‚')
            #!  'Unnamed: 0' ã‚„ 'æ—¥æ™‚' ã‚’å‰Šé™¤ã™ã‚‹
            df2_cleaned = df2.drop(columns=columns_to_drop)

            #! å„è¦å› ã®å€¤ã®å¹³å‡å€¤ã¨ä¸­å¤®å€¤ã‚’è¨ˆç®—
            average_values = df2_cleaned.mean()
            median_values = df2_cleaned.median()

            # å®Ÿè¡Œçµæœã®ç¢ºèª
            #st.dataframe(median_values)
            #st.header(type(median_values))
            #st.header(median_values.index)

            #! "ç™ºæ³¨ã‹ã‚“ã°ã‚“"ã¨åå‰ãŒä»˜ãè¦å› ã®é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ã‚’æŠ½å‡º
            def extract_kanban_t_values_from_index(df):

                # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³: ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•° + t-X~t-Y
                pattern = r'ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°.*\ï¼ˆt-(\d+)~t-(\d+)\ï¼‰'
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èµ°æŸ»
                for index in df.index:
                    index_value = str(index)  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å€¤ã‚’æ–‡å­—åˆ—ã¨ã—ã¦å–å¾—
                    match = re.search(pattern, index_value)  # æ­£è¦è¡¨ç¾ã§ãƒãƒƒãƒãƒ³ã‚°
                    if match:
                        X = match.group(1)  # Xã®å€¤
                        Y = match.group(2)  # Yã®å€¤
                        return X, Y  # ä¸€ã¤ã®ã‚»ãƒ«ãŒè¦‹ã¤ã‹ã‚Œã°çµ‚äº†
                return None, None
            
            #! "ç™ºæ³¨ã‹ã‚“ã°ã‚“"ã¨åå‰ãŒä»˜ãè¦å› ã®é–‹å§‹é…ã‚Œæ™‚é–“ã¨çµ‚äº†é…ã‚Œæ™‚é–“ã‚’æŠ½å‡º
            hacchu_start, hacchu_end = extract_kanban_t_values_from_index(median_values)
            # å®Ÿè¡Œçµæœã®ç¢ºèª
            #st.write(hacchu_start, hacchu_end)

            #! æŠ½å‡ºã—ãŸé–‹å§‹é…ã‚Œæ™‚é–“ã¨çµ‚äº†é…ã‚Œæ™‚é–“ã‚‚ã¨ã«é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ã‚’è¨ˆç®—
            def calculate_hacchu_times(hacchu_start, hacchu_end, time_str):
                # hacchu_startã¨hacchu_endãŒæ–‡å­—åˆ—ã®å ´åˆã€æ•´æ•°ã«å¤‰æ›
                hacchu_start = int(hacchu_start)
                hacchu_end = int(hacchu_end)

                #hacchu_start = 2
                #hacchu_end = 24

                # æ™‚é–“ã®æ–‡å­—åˆ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
                base_time = datetime.strptime(time_str, "%Y-%m-%d %H:%M")
                
                # hacchu_startæ™‚é–“ã¨hacchu_endæ™‚é–“ã‚’å¼•ã
                time_start = base_time - timedelta(hours=hacchu_start)
                time_end = base_time - timedelta(hours=hacchu_end)
                
                # çµæœã‚’è¡¨ç¤º
                #st.write(f"{time_str} - {hacchu_start} æ™‚é–“ = {time_start}")
                #st.write(f"{time_str} - {hacchu_end} æ™‚é–“ = {time_end}")

                return time_start, time_end

            #! é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ã‚’è¨ˆ
            hacchu_start_time, hacchu_end_time = calculate_hacchu_times(hacchu_start, hacchu_end, selected_datetime)

            #! ç‰¹å®šã®æ™‚é–“å¸¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            filtered_data = Activedata[(Activedata['æ—¥ä»˜'] >= hacchu_end_time) & (Activedata['æ—¥ä»˜'] <= hacchu_start_time)]

            # å®Ÿè¡Œçµæœã®ç¢ºèª
            #st.dataframe(filtered_data)

            #å¢—æ¸›ã®ã¨ã
            #total_ave = filtered_data['ä¾¿Ave'].sum()/24*filtered_data['ã‚µã‚¤ã‚¯ãƒ«å›æ•°'].median()
            total_ave = filtered_data['ä¾¿Ave'].iloc[0]

            # å®Ÿè¡Œçµæœã®ç¢ºèª
            #st.write(total_ave)

            # DataFrameã«å¤‰æ›
            average_df = pd.DataFrame(average_values, columns=["å¹³å‡å€¤"])
            average_df.index.name = 'å¤‰æ•°'
            median_df = pd.DataFrame(median_values, columns=["åŸºæº–å€¤"])
            median_df.index.name = 'å¤‰æ•°'

            def update_values_for_kanban(df,total_ave):
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èµ°æŸ»
                for index in df.index:
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã€Œç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã€ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯
                    if "ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°" in str(index):
                        # è©²å½“ã™ã‚‹è¡Œã®ã™ã¹ã¦ã®å€¤ã‚’ 10 ã«è¨­å®š
                        df.loc[index] = total_ave
                return df

            #! ä¸­å¤®å€¤ã‚’æ›´æ–°
            median_df = update_values_for_kanban(median_df,total_ave)

            #! å¹³å‡å€¤ã‚’çµ±åˆ
            df1_long = pd.merge(df1_long, average_df, left_on="å¤‰æ•°", right_on="å¤‰æ•°", how="left")
            #! ä¸­å¤®å€¤ã‚’çµ±åˆ
            df1_long = pd.merge(df1_long, median_df, left_on="å¤‰æ•°", right_on="å¤‰æ•°", how="left")

            #! SHAPãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç¹°ã‚Šè¿”ã—å‡¦ç†ã—ã€å¯¾å¿œã™ã‚‹å…ƒè¦å› ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å€¤ã‚’è¿½åŠ 
            for index, row in df1_long.iterrows():
                variable = row['å¤‰æ•°']  # SHAPãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã€Œå¤‰æ•°ã€åˆ—ã‚’å–å¾—
                if variable in filtered_df2.columns:  # å¤‰æ•°åãŒå…ƒè¦å› ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ—åã«å­˜åœ¨ã™ã‚‹å ´åˆ
                    # SHAPãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç¾åœ¨ã®è¡Œã«å…ƒè¦å› ã®å€¤ã‚’è¿½åŠ 
                    df1_long.at[index, 'è¦å› ã®å€¤'] = filtered_df2.loc[filtered_df2['æ—¥æ™‚'] == row['æ—¥æ™‚'], variable].values[0]

            #st.dataframe(df1_long)

            #! é †ä½è¡¨ã‚’è¡¨ç¤º
            #* df1_longä¸€ä¾‹
            #*ã€€	æ—¥æ™‚	å¤‰æ•°	å¯„ä¸åº¦ï¼ˆSHAPå€¤ï¼‰	å¹³å‡å€¤	åŸºæº–å€¤	è¦å› ã®å€¤
            #*    0	2024-08-23T04:00:00.000	No1_ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ï¼ˆt-40~t-88ï¼‰	-0.091102726	0.083333333	8.166666667	0
            #*    1	2024-08-23T04:00:00.000	No8_éƒ¨å“ç½®ãå ´ã®å…¥åº«æ»ç•™çŠ¶æ³ï¼ˆt-0~t-48ï¼‰	-0.025413021	3.166666667	3	5
            #*    2	2024-08-23T04:00:00.000	No7_é–“å£ã®å¹³å‡å……è¶³ç‡ï¼ˆt-0~t-48ï¼‰	-0.018948366	0.563765326	0.564081148	0.570461665
            #*    3	2024-08-23T04:00:00.000	No6_å®šæœŸä¾¿å‡ºç™ºçŠ¶æ³ï¼ˆt-4~t-6ï¼‰	-0.009560572	0.514873722	0.7467865	0.780578667
            #*    4	2024-08-23T04:00:00.000	No5_ä»•å…¥å…ˆä¾¿åˆ°ç€çŠ¶æ³ï¼ˆt-3~t-5ï¼‰	-0.006888544	3.375	4	1
            #*    5	2024-08-23T04:00:00.000	No3_è¨ˆç”»é”æˆç‡_åŠ é‡å¹³å‡ï¼ˆt-0~t-48ï¼‰	0	0	0	0
            #*    6	2024-08-23T04:00:00.000	No2_è¨ˆç”»çµ„ç«‹ç”Ÿç”£å°æ•°_åŠ é‡å¹³å‡ï¼ˆt-0~t-48ï¼‰	0.150128654	96.35416667	97.25	125
            display_shap_contributions(df1_long)
          
            # èƒŒæ™¯ã‚’é’ãã—ã¦ã€æƒ…å ±ãƒœãƒƒã‚¯ã‚¹ã®ã‚ˆã†ã«è¦‹ã›ã‚‹
            st.markdown("""
            <div style="background-color: #ffffff; padding: 10px; border-radius: 5px;">
            ğŸ“Œ <strong>åŸºæº–å€¤ã«ã¤ã„ã¦ã®èª¬æ˜ï¼ˆè¦å› ã®å€¤ãŒå¤§ãã„ã‹å°ã•ã„ã‹ã€æ­£å¸¸ãªã®ã‹ç•°å¸¸ãªã®ã‹ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®æŒ‡æ¨™ï¼‰</strong><br>
            <ul>
            <li><strong>ç™ºæ³¨ãƒ•ãƒ©ã‚°</strong>ï¼šActiveã®æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰Ã— å¯¾è±¡æœŸé–“</li>
            <li><strong>ç™ºæ³¨ã‹ã‚“ã°ã‚“æ•°ã®åŸºæº–å€¤</strong>ï¼šActiveã®æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰Ã— å¯¾è±¡æœŸé–“</li>
            <li><strong>è¨ˆç”»çµ„ç«‹ç”Ÿç”£å°æ•°ã®åŸºæº–å€¤</strong>ï¼šéå»åŠå¹´ã®ä¸­å¤®å€¤</li>
            <li><strong>çµ„ç«‹ãƒ©ã‚¤ãƒ³ã®ç¨¼åƒç‡ã®åŸºæº–å€¤</strong>ï¼šéå»åŠå¹´ã®ä¸­å¤®å€¤</li>
            <li><strong>é–“å£ã®å……è¶³ç‡ã®åŸºæº–å€¤</strong>ï¼šéå»åŠå¹´ã®ä¸­å¤®å€¤</li>
            <li><strong>è¥¿å°¾æ±ã‹éƒ¨å“ç½®ãå ´ã§æ»ç•™ã—ã¦ã„ã‚‹ã®åŸºæº–å€¤</strong>ï¼šéå»åŠå¹´ã®ä¸­å¤®å€¤</li>
            <li><strong>ä»•å…¥å…ˆä¾¿ã®åˆ°ç€ãƒ•ãƒ©ã‚°ã®åŸºæº–å€¤</strong>ï¼šéå»åŠå¹´ã®ä¸­å¤®å€¤</li>
            <li><strong>å®šæœŸä¾¿ã®å‡ºç™ºãƒ•ãƒ©ã‚°ã®åŸºæº–å€¤</strong>ï¼šéå»åŠå¹´ã®ä¸­å¤®å€¤</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

            memo_text = st.text_area("ãƒ¡ãƒ¢ï¼ˆæ°—ã¥ã„ãŸã“ã¨ã‚’ã”è¨˜å…¥ãã ã•ã„ï¼‰", height=200)
            # æå‡ºãƒœã‚¿ãƒ³
            if st.button("ç™»éŒ²å†…å®¹"):
                if memo_text.strip():
                    st.success("æå‡ºãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    st.write("ç™»éŒ²å†…å®¹ï¼š")
                    st.write(memo_text)
                else:
                    st.warning("ãƒ¡ãƒ¢å†…å®¹ãŒç©ºã§ã™ã€‚å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

        with tab2:

            #! æ£’ã‚°ãƒ©ãƒ•è¡¨ç¤º
            st.plotly_chart(fig_bar, use_container_width=True)


    else:
        st.write("åœ¨åº«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
