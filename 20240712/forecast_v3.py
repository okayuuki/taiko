#äºˆæ¸¬ç”¨

#! ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®import
import os
import pandas as pd
import warnings
import numpy as np
import pandas as pd
#%matplotlib inline#Jupyter Notebook å°‚ç”¨ã®ãƒžã‚¸ãƒƒã‚¯ã‚³ãƒžãƒ³ãƒ‰ã€‚ãƒ¡ãƒ³ãƒ†ç”¨ã§åˆ©ç”¨
import matplotlib.pyplot as plt
import shap
import seaborn as sns
import matplotlib as mpl
from dateutil.relativedelta import relativedelta
from IPython.display import display, clear_output
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from matplotlib.gridspec import GridSpec
from datetime import datetime
from datetime import timedelta
from PIL import Image
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, max_error, mean_absolute_error
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, date, time
import pickle
from sklearn.preprocessing import StandardScaler

#! è‡ªä½œãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®import
from read_v3 import read_data, process_Activedata, read_syozailt_by_using_archive_data, read_activedata_by_using_archive_data,read_zaiko__by_using_archive_data

def show_forecast( unique_product, start_datetime, selected_zaiko):

    start_date = '2024-05-01-00'
    end_date = '2024-08-31-00'

    #! å“ç•ªã€æ•´å‚™å®¤ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    product = unique_product.split('_')[0]
    seibishitsu = unique_product.split('_')[1]

    #! ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    prediction_hours = 24#ä½•æ™‚é–“å…ˆã¾ã§äºˆæ¸¬ã™ã‚‹ã®ã‹
    past_hours = 5
    lookback_hours = past_hours+2

    # ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
    st.header('äºˆæ¸¬çµæžœ')

    #!----------------------------------------------------------------------- 
    #! è‡ªå‹•ãƒ©ãƒƒã‚¯ã®åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‡¦ç†
    #!-----------------------------------------------------------------------
    zaiko_df = read_zaiko__by_using_archive_data(start_date, end_date)
    # å“ç•ªåˆ—ã®ç©ºç™½ã‚’å‰Šé™¤
    zaiko_df['å“ç•ª'] = zaiko_df['å“ç•ª'].str.strip()
    # 'è¨ˆæ¸¬æ—¥æ™‚'ã‚’datetimeåž‹ã«å¤‰æ›
    #zaiko_df['è¨ˆæ¸¬æ—¥æ™‚'] = pd.to_datetime(zaiko_df['è¨ˆæ¸¬æ—¥æ™‚'], errors='coerce')
    # åˆ—å 'è¨ˆæ¸¬æ—¥æ™‚' ã‚’ 'æ—¥æ™‚' ã«å¤‰æ›´
    #zaiko_df = zaiko_df.rename(columns={'è¨ˆæ¸¬æ—¥æ™‚': 'æ—¥æ™‚'})
    # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    zaiko_df = zaiko_df[zaiko_df['å“ç•ª'] == product]
    # ç‰¹å®šã®æ—¥æ™‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    zaiko_df = zaiko_df[zaiko_df['æ—¥æ™‚'] == start_datetime]
    # æ—¥æ™‚ã‚’å†åº¦datetimeåž‹ã«å¤‰æ›ï¼ˆå¿µã®ãŸã‚ï¼‰
    zaiko_df['æ—¥æ™‚'] = pd.to_datetime(zaiko_df['æ—¥æ™‚'])
    # 'æ—¥æ™‚' ã¨ 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
    zaiko_extracted = zaiko_df[['æ—¥æ™‚', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰']]

    #!-----------------------------------------------------------------------
    #! æ‰€åœ¨ç®¡ç†ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã®ãƒ‡ãƒ¼ã‚¿
    #!-----------------------------------------------------------------------
    #file_path = 'ä¸­é–“æˆæžœç‰©/æ‰€åœ¨ç®¡ç†MBãƒ†ã‚™ãƒ¼ã‚¿_çµ±åˆæ¸ˆ&ç‰¹å®šæ—¥æ™‚æŠ½å‡ºæ¸ˆ.csv'
    Timestamp_df = read_syozailt_by_using_archive_data(start_date, end_date)
    # 'æ›´æ–°æ—¥æ™‚'åˆ—ã«ç„¡åŠ¹ãªæ—¥æ™‚ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹è¡Œã‚’å‰Šé™¤ã™ã‚‹
    data_cleaned = Timestamp_df.dropna(subset=['æ¤œåŽæ—¥æ™‚'])
    # æ™‚é–“ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€å„æ™‚é–“ã§ã®ã‹ã‚“ã°ã‚“æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹
    data_cleaned['æ—¥æ™‚'] = data_cleaned['æ¤œåŽæ—¥æ™‚'].dt.floor('H')  # æ™‚é–“å˜ä½ã«ä¸¸ã‚ã‚‹
    hourly_kanban_count = data_cleaned.groupby('æ—¥æ™‚').size().reset_index(name='ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°')

    # æ™‚é–“ã®ç¯„å›²ã‚’æ±ºå®šã—ã€æ¬ ææ™‚é–“å¸¯ã‚’è£œå®Œã™ã‚‹
    full_time_range = pd.date_range(start=hourly_kanban_count['æ—¥æ™‚'].min(),end=hourly_kanban_count['æ—¥æ™‚'].max(),freq='H')

    # å…¨ã¦ã®æ™‚é–“ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã€æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹
    hourly_kanban_count_full = pd.DataFrame(full_time_range, columns=['æ—¥æ™‚']).merge(hourly_kanban_count, on='æ—¥æ™‚', how='left').fillna(0)

    # ã‹ã‚“ã°ã‚“æ•°ã‚’æ•´æ•°ã«æˆ»ã™
    hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'].astype(int)

    # 'äºˆæ¸¬å…¥åº«æ™‚é–“'åˆ—ã¨ã—ã¦ã€5æ™‚é–“å‰ã®ã‹ã‚“ã°ã‚“æ•°ã‚’è¿½åŠ ã™ã‚‹
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°'].shift(past_hours)

    # æ¬ æå€¤ï¼ˆæœ€åˆã®5æ™‚é–“åˆ†ï¼‰ã‚’0ã§åŸ‹ã‚ã‚‹
    hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'] = hourly_kanban_count_full['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].fillna(0).astype(int)

    #!-----------------------------------------------------------------------
    #! Activedataã®å‡¦ç†
    #!-----------------------------------------------------------------------
    activedata = read_activedata_by_using_archive_data(start_date, end_date,0)
    # ç‰¹å®šã®å“ç•ªã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    activedata = activedata[activedata['å“ç•ª'] == product]
    st.dataframe(activedata)
    #! ç¨¼åƒæ™‚é–“ã§å‰²ã‚‹å‡¦ç† (ä¼‘æ†©æ™‚é–“ã®è€ƒæ…®ãŒå¿…è¦ã‹ï¼Ÿ)
    activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] = activedata['æ—¥é‡æ•°']/activedata['åŽå®¹æ•°']
    activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“'] = activedata['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰'] / 16.5
    activedata['æ—¥ä»˜'] = pd.to_datetime(activedata['æ—¥ä»˜'])#ã“ã‚Œã—ãªã„ã¨æ¬¡ã®.resample('H')ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹
    # æ—¥ä»˜ã‚’åŸºæº–ã«1æ™‚é–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    activedata = activedata.set_index('æ—¥ä»˜').resample('H').ffill().reset_index()
    # 'æ—¥ä»˜' ã‚’datetimeåž‹ã«å¤‰æ›
    activedata['æ—¥ä»˜'] = pd.to_datetime(activedata['æ—¥ä»˜'])
    activedata = activedata.rename(columns={'æ—¥ä»˜': 'æ—¥æ™‚'})
    # 'æ—¥ä»˜' ã¨ 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰' ã®åˆ—ã®ã¿ã‚’æŠ½å‡º
    activedata_extracted = activedata[['æ—¥æ™‚', 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“']]

    # åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã®é–‹å§‹æ™‚åˆ»ã‚’å–å¾—
    start_time = zaiko_extracted.iloc[0]['æ—¥æ™‚']
    # é–‹å§‹æ™‚åˆ»ã‹ã‚‰20æ™‚é–“å¾Œã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    end_time = start_time + pd.Timedelta(hours=prediction_hours)
    filtered_activedata = activedata_extracted[(activedata_extracted['æ—¥æ™‚'] >= start_time) & (activedata_extracted['æ—¥æ™‚'] < end_time)]

    # å„æ™‚é–“å¾Œã®æ¶ˆè²»é‡ãŠã‚ˆã³å…¥åº«é‡ã‚’è€ƒæ…®ã—ãŸåœ¨åº«æ•°ã‚’è¨ˆç®—
    inventory_after_adjustments = []
    # ç¾åœ¨ã®åœ¨åº«æ•°ã‚’åˆæœŸå€¤ã¨ã—ã¦è¨­å®š
    current_inventory = selected_zaiko#zaiko_extracted.iloc[0]['åœ¨åº«æ•°ï¼ˆç®±ï¼‰']

    # 3ã¤ã®åˆ—ã‚’ä½œæˆ
    col1, col2 = st.columns(2)
    col1.metric(label="é¸æŠžã•ã‚ŒãŸæ—¥æ™‚", value=str(start_datetime))#, delta="1 mph")
    col2.metric(label="å…¥åŠ›ã•ã‚ŒãŸçµ„ç«‹ãƒ©ã‚¤ãƒ³ã®åœ¨åº«æ•°ï¼ˆç®±ï¼‰", value=int(current_inventory))

    # æ™‚é–“ã”ã¨ã®åœ¨åº«æ•°ã‚’æ›´æ–°ã—ãªãŒã‚‰ãƒªã‚¹ãƒˆã«è¿½åŠ 
    for i, row in filtered_activedata.iterrows():
        kanban_row = hourly_kanban_count_full[hourly_kanban_count_full['æ—¥æ™‚'] == row['æ—¥æ™‚']]
        incoming_kanban = kanban_row['å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°'].values[0] if not kanban_row.empty else 0
        inventory_after_adjustments.append({
            'æ—¥æ™‚': row['æ—¥æ™‚'],
            'åœ¨åº«æ•°ï¼ˆç®±ï¼‰': current_inventory
        })
        # æœ€åˆã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã¯æ¶ˆè²»ã‚’å¼•ã‹ãªã„ãŒã€ä»¥é™ã¯æ¶ˆè²»é‡ã¨å…¥åº«é‡ã‚’èª¿æ•´
        if i != 0:
            current_inventory = current_inventory - row['æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“']  # æ¶ˆè²»é‡ã‚’å¼•ã
            current_inventory = current_inventory + incoming_kanban  # å…¥åº«é‡ã‚’è¶³ã™
            

    # è¨ˆç®—çµæžœã‚’DataFrameã«å¤‰æ›
    inventory_df_adjusted = pd.DataFrame(inventory_after_adjustments)

    # æœ€åˆã®æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨ãã‚Œä»¥é™ã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    actual_data = inventory_df_adjusted.iloc[0:1]  # æœ€åˆã®1æ™‚é–“åˆ†ã¯å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
    forecast_data = inventory_df_adjusted.iloc[1:]  # ãã‚Œä»¥é™ã¯äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿

    # æ™‚é–“è»¸ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã€å…¨æ™‚é–“ã®ç¯„å›²ã‚’ä½œæˆ
    #full_time_range = pd.date_range(start=actual_data['æ—¥æ™‚'].min(), end=forecast_data['æ—¥æ™‚'].max(), freq='H')

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãã‚Œãžã‚Œã“ã®æ™‚é–“è»¸ã«åˆã‚ã›ã¦å†æ§‹ç¯‰ã—ã€æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹
    #actual_data = actual_data.set_index('æ—¥æ™‚').reindex(full_time_range).reset_index().rename(columns={'index': 'æ—¥æ™‚'})
    #forecast_data = forecast_data.set_index('æ—¥æ™‚').reindex(full_time_range).reset_index().rename(columns={'index': 'æ—¥æ™‚'})

    # æ¬ æå€¤ã¯ãã‚Œãžã‚Œ0ã«ç½®ãæ›ãˆã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    #actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].fillna(0, inplace=True)
    #forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'].fillna(0, inplace=True)

    # ã‚°ãƒ©ãƒ•ã®ä½œæˆ
    fig = go.Figure()

    # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’é’è‰²ã§æç”»
    fig.add_trace(go.Bar(
        x=actual_data['æ—¥æ™‚'], 
        y=actual_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
        name='å®Ÿç¸¾', 
        marker_color='blue', 
        opacity=0.3
    ))

    # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã§è¿½åŠ æç”»
    fig.add_trace(go.Bar(
        x=forecast_data['æ—¥æ™‚'], 
        y=forecast_data['åœ¨åº«æ•°ï¼ˆç®±ï¼‰'], 
        name='äºˆæ¸¬', 
        marker_color='orange', 
        opacity=0.3
    ))

    # xè»¸ã‚’1æ™‚é–“ã”ã¨ã«è¡¨ç¤ºã™ã‚‹è¨­å®š
    fig.update_layout(
        title='äºˆæ¸¬çµæžœ',  # ã“ã“ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
        xaxis_title='æ—¥æ™‚',  # xè»¸ã‚¿ã‚¤ãƒˆãƒ«
        yaxis_title='åœ¨åº«æ•°ï¼ˆç®±ï¼‰',  # yè»¸ã‚¿ã‚¤ãƒˆãƒ«
        xaxis=dict(
            tickformat="%Y-%m-%d %H:%M",  # æ—¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã‚’æŒ‡å®š
            dtick=3600000  # 1æ™‚é–“ã”ã¨ã«è¡¨ç¤º (3600000ãƒŸãƒªç§’ = 1æ™‚é–“)
        ),
        barmode='group'  # è¤‡æ•°ã®ãƒãƒ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    )

    # ã‚°ãƒ©ãƒ•ã‚’Streamlitã§è¡¨ç¤º
    st.plotly_chart(fig)

    # 5æ™‚é–“å‰ã®æ—¥æ™‚ã‚’è¨ˆç®—
    hours_before = start_time - pd.Timedelta(hours=lookback_hours)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«çµæžœã‚’è¡¨ç¤ºã™ã‚‹
    hourly_kanban_count_full = hourly_kanban_count_full[(hourly_kanban_count_full['æ—¥æ™‚'] >= hours_before) & (hourly_kanban_count_full['æ—¥æ™‚'] < end_time)]

    # æ–°ã—ã„åˆ—ã€Œå‚™è€ƒã€ã‚’è¿½åŠ ã—ã€start_timeã«åŸºã¥ã„ã¦ã€ŒéŽåŽ»ã€ã€Œæœªæ¥ã€ã¨è¡¨ç¤º
    hourly_kanban_count_full['â€»æ³¨é‡ˆ                                                                               '] = hourly_kanban_count_full['æ—¥æ™‚'].apply(
        lambda x: 'ã‚ãªãŸã¯ã“ã®æ™‚é–“ã‚’é¸æŠžã—ã¾ã—ãŸ' if x == start_time else ('éŽåŽ»' if x < start_time else 'æœªæ¥')
    )

    # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    def highlight_start_time(row):
        return ['background-color: yellow' if row['æ—¥æ™‚'] == start_time else '' for _ in row]
    
    st.code(f"ðŸ“ è¨ˆç®—å¼ï¼šæœªæ¥ã®åœ¨åº«æ•° = åœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

    # æ³¨é‡ˆã‚’è¿½åŠ ï¼ˆä¾‹ã¨ã—ã¦start_timeã‚’è¡¨ç¤ºï¼‰
    st.markdown(f"")
    st.markdown(f"")
    st.markdown(f"**ä¸‹ã®è¡¨ã§äºˆæ¸¬ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã™ã€‚**")
    #st.code(f"è¨ˆç®—å¼ï¼šåœ¨åº«æ•° + å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•° - æ—¥é‡ç®±æ•°/ç¨¼åƒæ™‚é–“")

    # 'hourly_kanban_count_full' ã¨ 'inventory_df_adjusted' ã‚’ 'æ—¥æ™‚' ã‚’ã‚­ãƒ¼ã«çµåˆ
    merged_df = pd.merge(hourly_kanban_count_full, inventory_df_adjusted, on='æ—¥æ™‚', how='outer')
    activedata_extracted = activedata_extracted[(activedata_extracted['æ—¥æ™‚'] >= hours_before) & (activedata_extracted['æ—¥æ™‚'] < end_time)]
    merged_df = pd.merge(merged_df, activedata_extracted, on='æ—¥æ™‚', how='outer')

    # å¿…è¦ã«å¿œã˜ã¦NaNã‚’0ã«ç½®ãæ›ãˆã‚‹ï¼ˆåœ¨åº«æ•°ã‚„ã‹ã‚“ã°ã‚“æ•°ã«é–¢ã—ã¦ï¼‰
    merged_df.fillna(0, inplace=True)

    # Streamlitã§è¡¨ç¤º
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ—ã®é †ç•ªã‚’æŒ‡å®š
    new_column_order = ['æ—¥æ™‚', 'ç´å…¥äºˆå®šã‹ã‚“ã°ã‚“æ•°', 'å·¥å ´åˆ°ç€äºˆå®šã‹ã‚“ã°ã‚“æ•°', 'æ—¥é‡æ•°ï¼ˆç®±æ•°ï¼‰/ç¨¼åƒæ™‚é–“', 'åœ¨åº«æ•°ï¼ˆç®±ï¼‰','â€»æ³¨é‡ˆ                                                                               ']
    # åˆ—ã®é †ç•ªã‚’å¤‰æ›´
    merged_df = merged_df[new_column_order]

    # æ¡ä»¶ã«è©²å½“ã™ã‚‹è¡Œã®åœ¨åº«æ•°ã‚’ "-" ã«ã™ã‚‹
    merged_df.loc[
        (merged_df['æ—¥æ™‚'] >= hours_before) & 
        (merged_df['æ—¥æ™‚'] < start_time), 
        'åœ¨åº«æ•°ï¼ˆç®±ï¼‰'
    ] = "-"

    # 'æ—¥æ™‚'åˆ—ã§start_timeã«ä¸€è‡´ã™ã‚‹è¡Œã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦è¡¨ç¤º
    st.dataframe(merged_df.style.apply(highlight_start_time, axis=1))







